[
  {
    "objectID": "supporting-materials/sam-lfs-data-request.html",
    "href": "supporting-materials/sam-lfs-data-request.html",
    "title": "SAM Labor Force Survey Data Request",
    "section": "",
    "text": "For this data request, we summarize labor factor payments, by sex, occupation, employment status, and economic activity, according to a structure needed for the macroeconomic modeling.\n\n\n\nAggregate labor cost data according to the following dimensions:\n\nEmployment status.\nSex.\nOccupation (according to ISCO-08).\nEconomic activity.\n\nAdditional data nodes:\n\nNumber of workers.\nLabor cost.\nNumber of hours (labor volume).\n\nOutput to Excel.\n\n\n\n\n\n# Clean workspace\nrm(list = ls())\n\n# Georgia country ISO code\niso &lt;- \"GEO\"\n\n# Survey year\nsurvey_year &lt;- 2023\n\n# Exchange rate USD per GEL\ner &lt;- 0.37\n\n# Quarter of interest\nquarter &lt;- 106\n\n# Years of interest for our macroeconomic scenario analysis\n# analysis_years &lt;- c(2030, 2050)\n\nWe will use the following libraries for this exercise.\n\nlibrary(tidyverse)\nlibrary(haven)\nlibrary(readxl)\nlibrary(openxlsx)\nlibrary(gt)\n\n\n\n\nWe use data from the 2022 Labor Force Survey and focus on quarter 4 (106).\n\n# Labor\npp_labor &lt;- read_sav(\"data/lfs_2022/LFS_ECSTAT_ENG_2022.sav\")\npp_labor_demographic &lt;- read_sav(\"data/lfs_2022/LFS_Demographic_ENG_2022.sav\")\n\n# Equivalence table\nsam_activities &lt;- read_excel(\n    \"data/sam/classifications.xlsx\",\n    sheet = \"SAM-REV2\",\n    col_names = T,\n    col_types = \"text\",\n  )\n\nsam_factors &lt;- read_excel(\n    \"data/sam/classifications.xlsx\",\n    sheet = \"SAM factors\",\n    col_names = T,\n    col_types = \"text\",\n  )",
    "crumbs": [
      "Home",
      "Supporting materials",
      "SAM Labor Force Survey Data Request"
    ]
  },
  {
    "objectID": "supporting-materials/sam-lfs-data-request.html#objectives",
    "href": "supporting-materials/sam-lfs-data-request.html#objectives",
    "title": "SAM Labor Force Survey Data Request",
    "section": "",
    "text": "Aggregate labor cost data according to the following dimensions:\n\nEmployment status.\nSex.\nOccupation (according to ISCO-08).\nEconomic activity.\n\nAdditional data nodes:\n\nNumber of workers.\nLabor cost.\nNumber of hours (labor volume).\n\nOutput to Excel.",
    "crumbs": [
      "Home",
      "Supporting materials",
      "SAM Labor Force Survey Data Request"
    ]
  },
  {
    "objectID": "supporting-materials/sam-lfs-data-request.html#preliminaries",
    "href": "supporting-materials/sam-lfs-data-request.html#preliminaries",
    "title": "SAM Labor Force Survey Data Request",
    "section": "",
    "text": "# Clean workspace\nrm(list = ls())\n\n# Georgia country ISO code\niso &lt;- \"GEO\"\n\n# Survey year\nsurvey_year &lt;- 2023\n\n# Exchange rate USD per GEL\ner &lt;- 0.37\n\n# Quarter of interest\nquarter &lt;- 106\n\n# Years of interest for our macroeconomic scenario analysis\n# analysis_years &lt;- c(2030, 2050)\n\nWe will use the following libraries for this exercise.\n\nlibrary(tidyverse)\nlibrary(haven)\nlibrary(readxl)\nlibrary(openxlsx)\nlibrary(gt)",
    "crumbs": [
      "Home",
      "Supporting materials",
      "SAM Labor Force Survey Data Request"
    ]
  },
  {
    "objectID": "supporting-materials/sam-lfs-data-request.html#datasets-and-correspondence-tables",
    "href": "supporting-materials/sam-lfs-data-request.html#datasets-and-correspondence-tables",
    "title": "SAM Labor Force Survey Data Request",
    "section": "",
    "text": "We use data from the 2022 Labor Force Survey and focus on quarter 4 (106).\n\n# Labor\npp_labor &lt;- read_sav(\"data/lfs_2022/LFS_ECSTAT_ENG_2022.sav\")\npp_labor_demographic &lt;- read_sav(\"data/lfs_2022/LFS_Demographic_ENG_2022.sav\")\n\n# Equivalence table\nsam_activities &lt;- read_excel(\n    \"data/sam/classifications.xlsx\",\n    sheet = \"SAM-REV2\",\n    col_names = T,\n    col_types = \"text\",\n  )\n\nsam_factors &lt;- read_excel(\n    \"data/sam/classifications.xlsx\",\n    sheet = \"SAM factors\",\n    col_names = T,\n    col_types = \"text\",\n  )",
    "crumbs": [
      "Home",
      "Supporting materials",
      "SAM Labor Force Survey Data Request"
    ]
  },
  {
    "objectID": "supporting-materials/sam-lfs-data-request.html#demographics",
    "href": "supporting-materials/sam-lfs-data-request.html#demographics",
    "title": "SAM Labor Force Survey Data Request",
    "section": "Demographics",
    "text": "Demographics\n\ndemographics &lt;- pp_labor_demographic |&gt; \n  mutate(\n    MemberId = \n      paste0(sprintf(\"%06d\", UID), sprintf(\"%02d\", MemberNo))) |&gt;\n  mutate(Sex = factor(\n    Sex,\n    levels = c(1, 2),\n    labels = c(\"Female\", \"Male\")\n  )) |&gt; \n    select(MemberId, Sex, Age)",
    "crumbs": [
      "Home",
      "Supporting materials",
      "SAM Labor Force Survey Data Request"
    ]
  },
  {
    "objectID": "supporting-materials/sam-lfs-data-request.html#match-nace-codes-to-sam-economic-activities",
    "href": "supporting-materials/sam-lfs-data-request.html#match-nace-codes-to-sam-economic-activities",
    "title": "SAM Labor Force Survey Data Request",
    "section": "Match NACE codes to SAM economic activities",
    "text": "Match NACE codes to SAM economic activities\nWe work with labor status . Since, upon import NACE 2 codes are converted to numbers, we need to convert them back to text, so that we can keep zeros to the left for proper order. We then extract the first two digits and match with 2-digit NACE Rev.Â 2 and find the correspondence to SAM using the look-up table sam_activities. For proper ordering, we convert the SAM activities columns for job 1 and job 2 to factor, using the order from the dataset sam_factors.\n\npp_labor &lt;- pp_labor |&gt;\n  mutate(\n    # Member ID\n    MemberId = \n      paste0(sprintf(\"%06d\", UID), sprintf(\"%02d\", MemberNo)),\n    # Job 1 NACE Rev 2 code. \n    Brunch  = if_else(\n      !is.na(Brunch),\n      sprintf(\"%04d\", Brunch), \n      NA_character_),\n    # Job 2 NACE Rev 2 code.\n    Second_Brunch = if_else(\n      !is.na(Second_Brunch),\n      sprintf(\"%04d\", Second_Brunch), NA_character_)) |&gt;\n  mutate(\n    Brunch2d = if_else(!is.na(Brunch),substr(Brunch, 1, 2), NA_character_),\n    Second_Brunch2d = if_else(!is.na(Second_Brunch),substr(Second_Brunch, 1, 2), NA_character_),\n    # Is employer or self employed?\n    employer = if_else(\n      !is.na(Status) & B10_Business_with_regular_salaried_workers == 1,\n      1,NA)) |&gt;\n  # We match to Rev 2 and SAM classifications (for job 1 and job 2)\n  left_join(\n    sam_activities[,c(1,3)], \n    join_by(Brunch2d == rev2_2d)) |&gt; \n  left_join(\n    sam_activities[,c(1,3)],\n    join_by(Second_Brunch2d == rev2_2d),\n    suffix = \n      c(\"_job1\", \"_job2\")) |&gt; \n  # And convert to factors for proper order\n  mutate(\n    SAM_job1 = factor(\n      SAM_job1, \n      levels = sam_factors$SAM,\n      # labels = sam_factors$SAM_description\n      ),\n    SAM_job2 = factor(\n      SAM_job2, \n      levels = sam_factors$SAM,\n      # labels = sam_factors$SAM_description\n      )\n  )",
    "crumbs": [
      "Home",
      "Supporting materials",
      "SAM Labor Force Survey Data Request"
    ]
  },
  {
    "objectID": "supporting-materials/sam-lfs-data-request.html#rename-variables-for-convenience",
    "href": "supporting-materials/sam-lfs-data-request.html#rename-variables-for-convenience",
    "title": "SAM Labor Force Survey Data Request",
    "section": "Rename variables for convenience",
    "text": "Rename variables for convenience\n\npp_labor &lt;- pp_labor |&gt; \n  rename(\n    # Job 1\n    job1_status     = Status,\n    job1_occupation = Occupation_converted,\n    job1_activity   = SAM_job1,\n    \n    # Job 2\n    job2_status     = Second_Status,\n    job2_occupation = Second_Ocupation_converted,\n    job2_activity   = SAM_job2,\n    \n    # Other\n    sex = Sex,\n    age = Age\n    ) |&gt; \n  mutate(\n    job1_q_hours    = 13 * M_Actually_worked, # A quarter has 13 weeks\n    job2_q_hours    = 13 * S_Actually_worked\n  )",
    "crumbs": [
      "Home",
      "Supporting materials",
      "SAM Labor Force Survey Data Request"
    ]
  },
  {
    "objectID": "supporting-materials/sam-lfs-data-request.html#number-of-workers",
    "href": "supporting-materials/sam-lfs-data-request.html#number-of-workers",
    "title": "SAM Labor Force Survey Data Request",
    "section": "Number of workers",
    "text": "Number of workers\n\nnumber_of_workers &lt;- flab |&gt; \n  filter(!is.na(activity)) |&gt; \n  group_by(\n    #as_factor(self_employed), \n    as_factor(status), \n    as_factor(sex), \n    as_factor(occupation), \n    activity) |&gt; \n  summarize(\n    Value = sum(P_Weights / 4, na.rm = T)\n  ) |&gt; \n  rename(\n    # `Self Employed` = `as_factor(self_employed)`,\n    Status = `as_factor(status)`,\n    Gender = `as_factor(sex)`,\n    Occupation = `as_factor(occupation)`,\n    Activity = activity\n  ) |&gt; \n  pivot_wider(\n    id_cols = c(\n      # `Self Employed`,\n      Status,\n      Gender,\n      Occupation\n    ),\n    names_from = Activity,\n    values_from = Value,\n    id_expand = T,\n    names_expand = T,\n    names_sort = T,\n  )",
    "crumbs": [
      "Home",
      "Supporting materials",
      "SAM Labor Force Survey Data Request"
    ]
  },
  {
    "objectID": "supporting-materials/sam-lfs-data-request.html#volume-of-hours",
    "href": "supporting-materials/sam-lfs-data-request.html#volume-of-hours",
    "title": "SAM Labor Force Survey Data Request",
    "section": "Volume of hours",
    "text": "Volume of hours\n\nhours &lt;- flab |&gt; \n  filter(!is.na(activity)) |&gt; \n  group_by(\n    #as_factor(self_employed), \n    as_factor(status), \n    as_factor(sex), \n    as_factor(occupation), \n    activity) |&gt; \n  summarize(\n    Value = sum(q_hours * P_Weights, na.rm = T)\n  ) |&gt; \n  rename(\n    # `Self Employed` = `as_factor(self_employed)`,\n    Status = `as_factor(status)`,\n    Gender = `as_factor(sex)`,\n    Occupation = `as_factor(occupation)`,\n    Activity = activity\n  ) |&gt; \n  pivot_wider(\n    id_cols = c(\n      # `Self Employed`,\n      Status,\n      Gender,\n      Occupation\n    ),\n    names_from = Activity,\n    values_from = Value,\n    id_expand = T,\n    names_expand = T,\n    names_sort = T,\n  )\n\n\nwb &lt;- loadWorkbook(\"data/sam/SAMshares_GEO_occupations.xlsx\")\nnames(wb)\n\n[1] \"SAM_2023\"               \"Accounts\"               \"nace-rev2-en-divisions\"\n[4] \"nace-rev1-en-divisions\" \"factor payments_split\"  \"factor income\"         \n\nwriteData(\n  wb, \n  \"factor payments_split\", \n  number_of_workers , \n  startRow = 292, \n  startCol = 3, \n  rowNames = F,\n  na.string = \"\")\nwriteData(\n  wb, \n  \"factor payments_split\", \n  hours , \n  startRow = 416, \n  startCol = 3, \n  rowNames = F,\n  na.string = \"\")\nsaveWorkbook(\n  wb,\n  \"data/sam/SAMshares_GEO_occupations.xlsx\",\n  overwrite = T)\n\n\n# test &lt;- pp_labor |&gt; \n#   select(job1_status, B10_Business_with_regular_salaried_workers, B11_Number_of_employees_in_the_establishment) |&gt; \n#   filter(B10_Business_with_regular_salaried_workers == 1)",
    "crumbs": [
      "Home",
      "Supporting materials",
      "SAM Labor Force Survey Data Request"
    ]
  },
  {
    "objectID": "supporting-materials/sam-shares-data-request.html",
    "href": "supporting-materials/sam-shares-data-request.html",
    "title": "SAM Shares Data Request",
    "section": "",
    "text": "In this data request, we estimate shares to disaggregate the Social Accounting Matrix for the Macroeconomic team.\n\n\n\nHH split: Split our representative household into income quintiles and rural/urban households.\nLabor split: Split labor into 6 types according to gender and skill level.\nEconomic activity split: Split wages and capital by economic activities.\nSplit household consumption by urban/rural, quintiles and economic activity.\n\n(Addendum)\n\nFill out the wages and the quantity per employment status (Paid employee, Employer, self-employed and non-paid employees) (cells in yellow in file: SAMshares_GEO_v03.xlsx).\nSplit transfers (this part from ILCS 2023).\n\n\n\n\n\n# Clean workspace\nrm(list = ls())\n\n# Georgia country ISO code\niso &lt;- \"GEO\"\n\n# Survey year\nsurvey_year &lt;- 2023\n\n# Exchange rate USD per GEL\ner &lt;- 0.37\n\n# Years of interest for our macroeconomic scenario analysis\n# analysis_years &lt;- c(2030, 2050)\n\nWe will use the following libraries for this exercise.\n\nlibrary(tidyverse)\nlibrary(haven)\nlibrary(readxl)\nlibrary(openxlsx)\nlibrary(gt)\n\n\n\n\nWe use data from the 2023 survey for the Labor Split and data from the 2022 survey for the household expenditure and capital shares in In mil. GEL per year per household type.\n\n# Household Unique ID, Weights, Location and other basic variables\nhh_basics &lt;- read_sav(\n  \"data/ilcs_2023/sysschedule.sav\") |&gt;\n  mutate(\n    UID = as.integer(UID))\n\n# Household size (includes no. of family members)\nhh_size &lt;- read_sav(\n  \"data/ilcs_2023/familysize.sav\")|&gt; \n  mutate(\n    UID = as.integer(UID))\n\n# Processed income at household level\nhh_income &lt;- read_sav(\n  \"data/ilcs_2023/tblincomes.sav\")|&gt; \n  mutate(\n    UID = as.integer(UID))\n\n# Consumption aggregate at household level \nhh_expenditure &lt;- read_sav(\n  \"data/ilcs_2023/tblexpenditures.sav\")|&gt; \n  rename(# rename total expenditure variables\n         total_expenditure = MTlianixarjebi_,\n         total_expenditure_aeq06 = MTlianimoxmareba_EqAdScale,\n         total_expenditure_aeq08 = Mtlianimoxmareba_EqAdScale_08) |&gt; \n  mutate(\n    UID = as.integer(UID))\n\n# Characteristics of the dwelling\nhh_chars &lt;- read_sav(\n  \"data/ilcs_2023/tblshinda01.sav\")|&gt;\n  mutate(\n    UID = as.integer(UID))\n\n# Persons (pp)\npp &lt;- read_sav(\n  \"data/ilcs_2023/tblshinda02.sav\") |&gt; \n  mutate(\n    UID = as.integer(UID),\n    MemberNo = as.integer(MemberNo))\n\n# Labor (pp)\npp_labor &lt;- read_sav(\n  \"data/ilcs_2023/tblshinda05_1.sav\") |&gt; \n  mutate(\n    UID = as.integer(UID),\n    MemberNo = as.integer(MemberNo),\n    Q5  = as.integer(Q5),\n    Q12 = as.integer(Q12)) \n\n# Poverty\npoverty &lt;- read_dta(\n  \"data/ilcs_2023/POVERTY_stata.dta\") |&gt; \n  mutate(\n    UID = as.integer(UID))\n\n# Ind. Poverty\nind_poverty &lt;- read_dta(\n  \"data/ilcs_2023/IND_POVERTY_stata.dta\") |&gt; \n  rename(MemberNo = memberno) |&gt; \n  mutate(\n    UID = as.integer(UID),\n    MemberNo = as.integer(MemberNo))\n\nWe also need look-up tables.\n\nsam_activities &lt;- read_excel(\n    \"data/sam/classifications.xlsx\",\n    sheet = \"SAM-REV2\",\n    col_names = T,\n    col_types = \"text\",\n  )\n\nsam_factors &lt;- read_excel(\n    \"data/sam/classifications.xlsx\",\n    sheet = \"SAM factors\",\n    col_names = T,\n    col_types = \"text\",\n  )\n\ncoicop &lt;- read_excel(\n    \"data/sam/classifications.xlsx\",\n    sheet = \"COICOP\",\n    col_names = T,\n    col_types = \"text\",\n  ) |&gt; \n  mutate(simple_code = as.integer(gsub(\"\\\\.\", \"\", Coicop)))\n\ncoicop_filtered &lt;- coicop |&gt; \n  filter( nchar(as.character(simple_code)) &gt;= 5)\n\n\n\n\nFirst we check that our dataset amounts to population totals.\n\nweights &lt;- hh_basics |&gt; \n  select(UID, QuartNo, Weights)\n\nhh_size |&gt; \n  left_join(weights, join_by(UID)) |&gt; \n#  filter(QuartNo == 110) |&gt; \n  summarize(\n    \"Population\" = sum(FamilySize * Weights, na.rm = T),\n    \"Households\" = sum(Weights, na.rm = T)) |&gt; \n  gt()\n\n\n\n\n\n\n\nPopulation\nHouseholds\n\n\n\n\n14861930\n4499690\n\n\n\n\n\n\n\nUpon first exploration, we see that the population amounts to 14,861,930 individuals, living in 4,499,690 households, when in reality we have a total population estimate of 3,702,130 individuals, living in 1,109,130 households. This is because the survey covers four quarters and households are interviewed four times in the year. So we need to drop households for our estimates and keep only those related to one quarter. Since we need information for 2022, but our dataset is for 2023, we will use the first quarter (Q1), which is closer to the required year.\n\npop_by_quarter &lt;- hh_size |&gt; \n  left_join(weights, join_by(UID)) |&gt; \n  group_by(QuartNo) |&gt; \n  summarize(\n    \"Population\" = sum(FamilySize * Weights, na.rm = T),\n    \"Households\" = sum(Weights, na.rm = T))\n\npop_by_quarter |&gt; \n  gt()\n\n\n\n\n\n\n\nQuarter ID\nPopulation\nHouseholds\n\n\n\n\n107\n3713876\n1122110\n\n\n108\n3654991\n1114584\n\n\n109\n3729558\n1130628\n\n\n110\n3763505\n1132368",
    "crumbs": [
      "Home",
      "Supporting materials",
      "SAM Shares Data Request"
    ]
  },
  {
    "objectID": "supporting-materials/sam-shares-data-request.html#objectives",
    "href": "supporting-materials/sam-shares-data-request.html#objectives",
    "title": "SAM Shares Data Request",
    "section": "",
    "text": "HH split: Split our representative household into income quintiles and rural/urban households.\nLabor split: Split labor into 6 types according to gender and skill level.\nEconomic activity split: Split wages and capital by economic activities.\nSplit household consumption by urban/rural, quintiles and economic activity.\n\n(Addendum)\n\nFill out the wages and the quantity per employment status (Paid employee, Employer, self-employed and non-paid employees) (cells in yellow in file: SAMshares_GEO_v03.xlsx).\nSplit transfers (this part from ILCS 2023).",
    "crumbs": [
      "Home",
      "Supporting materials",
      "SAM Shares Data Request"
    ]
  },
  {
    "objectID": "supporting-materials/sam-shares-data-request.html#preliminaries",
    "href": "supporting-materials/sam-shares-data-request.html#preliminaries",
    "title": "SAM Shares Data Request",
    "section": "",
    "text": "# Clean workspace\nrm(list = ls())\n\n# Georgia country ISO code\niso &lt;- \"GEO\"\n\n# Survey year\nsurvey_year &lt;- 2023\n\n# Exchange rate USD per GEL\ner &lt;- 0.37\n\n# Years of interest for our macroeconomic scenario analysis\n# analysis_years &lt;- c(2030, 2050)\n\nWe will use the following libraries for this exercise.\n\nlibrary(tidyverse)\nlibrary(haven)\nlibrary(readxl)\nlibrary(openxlsx)\nlibrary(gt)",
    "crumbs": [
      "Home",
      "Supporting materials",
      "SAM Shares Data Request"
    ]
  },
  {
    "objectID": "supporting-materials/sam-shares-data-request.html#datasets-and-correspondence-tables",
    "href": "supporting-materials/sam-shares-data-request.html#datasets-and-correspondence-tables",
    "title": "SAM Shares Data Request",
    "section": "",
    "text": "We use data from the 2023 survey for the Labor Split and data from the 2022 survey for the household expenditure and capital shares in In mil. GEL per year per household type.\n\n# Household Unique ID, Weights, Location and other basic variables\nhh_basics &lt;- read_sav(\n  \"data/ilcs_2023/sysschedule.sav\") |&gt;\n  mutate(\n    UID = as.integer(UID))\n\n# Household size (includes no. of family members)\nhh_size &lt;- read_sav(\n  \"data/ilcs_2023/familysize.sav\")|&gt; \n  mutate(\n    UID = as.integer(UID))\n\n# Processed income at household level\nhh_income &lt;- read_sav(\n  \"data/ilcs_2023/tblincomes.sav\")|&gt; \n  mutate(\n    UID = as.integer(UID))\n\n# Consumption aggregate at household level \nhh_expenditure &lt;- read_sav(\n  \"data/ilcs_2023/tblexpenditures.sav\")|&gt; \n  rename(# rename total expenditure variables\n         total_expenditure = MTlianixarjebi_,\n         total_expenditure_aeq06 = MTlianimoxmareba_EqAdScale,\n         total_expenditure_aeq08 = Mtlianimoxmareba_EqAdScale_08) |&gt; \n  mutate(\n    UID = as.integer(UID))\n\n# Characteristics of the dwelling\nhh_chars &lt;- read_sav(\n  \"data/ilcs_2023/tblshinda01.sav\")|&gt;\n  mutate(\n    UID = as.integer(UID))\n\n# Persons (pp)\npp &lt;- read_sav(\n  \"data/ilcs_2023/tblshinda02.sav\") |&gt; \n  mutate(\n    UID = as.integer(UID),\n    MemberNo = as.integer(MemberNo))\n\n# Labor (pp)\npp_labor &lt;- read_sav(\n  \"data/ilcs_2023/tblshinda05_1.sav\") |&gt; \n  mutate(\n    UID = as.integer(UID),\n    MemberNo = as.integer(MemberNo),\n    Q5  = as.integer(Q5),\n    Q12 = as.integer(Q12)) \n\n# Poverty\npoverty &lt;- read_dta(\n  \"data/ilcs_2023/POVERTY_stata.dta\") |&gt; \n  mutate(\n    UID = as.integer(UID))\n\n# Ind. Poverty\nind_poverty &lt;- read_dta(\n  \"data/ilcs_2023/IND_POVERTY_stata.dta\") |&gt; \n  rename(MemberNo = memberno) |&gt; \n  mutate(\n    UID = as.integer(UID),\n    MemberNo = as.integer(MemberNo))\n\nWe also need look-up tables.\n\nsam_activities &lt;- read_excel(\n    \"data/sam/classifications.xlsx\",\n    sheet = \"SAM-REV2\",\n    col_names = T,\n    col_types = \"text\",\n  )\n\nsam_factors &lt;- read_excel(\n    \"data/sam/classifications.xlsx\",\n    sheet = \"SAM factors\",\n    col_names = T,\n    col_types = \"text\",\n  )\n\ncoicop &lt;- read_excel(\n    \"data/sam/classifications.xlsx\",\n    sheet = \"COICOP\",\n    col_names = T,\n    col_types = \"text\",\n  ) |&gt; \n  mutate(simple_code = as.integer(gsub(\"\\\\.\", \"\", Coicop)))\n\ncoicop_filtered &lt;- coicop |&gt; \n  filter( nchar(as.character(simple_code)) &gt;= 5)",
    "crumbs": [
      "Home",
      "Supporting materials",
      "SAM Shares Data Request"
    ]
  },
  {
    "objectID": "supporting-materials/sam-shares-data-request.html#population-totals",
    "href": "supporting-materials/sam-shares-data-request.html#population-totals",
    "title": "SAM Shares Data Request",
    "section": "",
    "text": "First we check that our dataset amounts to population totals.\n\nweights &lt;- hh_basics |&gt; \n  select(UID, QuartNo, Weights)\n\nhh_size |&gt; \n  left_join(weights, join_by(UID)) |&gt; \n#  filter(QuartNo == 110) |&gt; \n  summarize(\n    \"Population\" = sum(FamilySize * Weights, na.rm = T),\n    \"Households\" = sum(Weights, na.rm = T)) |&gt; \n  gt()\n\n\n\n\n\n\n\nPopulation\nHouseholds\n\n\n\n\n14861930\n4499690\n\n\n\n\n\n\n\nUpon first exploration, we see that the population amounts to 14,861,930 individuals, living in 4,499,690 households, when in reality we have a total population estimate of 3,702,130 individuals, living in 1,109,130 households. This is because the survey covers four quarters and households are interviewed four times in the year. So we need to drop households for our estimates and keep only those related to one quarter. Since we need information for 2022, but our dataset is for 2023, we will use the first quarter (Q1), which is closer to the required year.\n\npop_by_quarter &lt;- hh_size |&gt; \n  left_join(weights, join_by(UID)) |&gt; \n  group_by(QuartNo) |&gt; \n  summarize(\n    \"Population\" = sum(FamilySize * Weights, na.rm = T),\n    \"Households\" = sum(Weights, na.rm = T))\n\npop_by_quarter |&gt; \n  gt()\n\n\n\n\n\n\n\nQuarter ID\nPopulation\nHouseholds\n\n\n\n\n107\n3713876\n1122110\n\n\n108\n3654991\n1114584\n\n\n109\n3729558\n1130628\n\n\n110\n3763505\n1132368",
    "crumbs": [
      "Home",
      "Supporting materials",
      "SAM Shares Data Request"
    ]
  },
  {
    "objectID": "supporting-materials/sam-shares-data-request.html#skill-level",
    "href": "supporting-materials/sam-shares-data-request.html#skill-level",
    "title": "SAM Shares Data Request",
    "section": "Skill level",
    "text": "Skill level\nFor skill level, we will use information on schooling from pp$Education (TblShinda02), which has the following levels:\n\nIlliterate\nDo not have primary education but can read and write\nPre-primary education\nPrimary education\nLower secondary education\nUpper secondary education\nVocational education without secondary general education\nVocational education on the base of lower secondary education with secondary general education certificate\nVocational education on the base of secondary general education (except higher professional education)\nHigher professional program\nBachelor or equivalent\nMaster or equivalent\nDoctor or equivalent\n\nWe need three skill levels for our SAM template, so we map these levels to:\nLow skill (1 - 5): Illiterate through lower secondary. Medium skill (6 - 9): Upper secondary through vocational education. High skill (10 - 13): Higher professional program through Doctor.\n\npp_factor_descriptors &lt;- pp |&gt;\n  select(UID, MemberNo, Gender, Age, Education) |&gt; \n  mutate(\n    MemberId = \n      paste0(sprintf(\"%06d\", UID), sprintf(\"%02d\", MemberNo))) |&gt;\n  mutate(Gender = factor(\n    Gender,\n    levels = c(1, 2),\n    labels = c(\"Female\", \"Male\")\n  )) |&gt; \n  mutate(\n    SkillLevel = case_when(\n      Education &gt;= 0 & Education &lt;= 5 ~ 1,\n      Education &gt; 5 & Education &lt;= 9 ~ 2,\n      Education &gt; 9 & Education &lt;= 13 ~ 3,\n      TRUE ~ NA ) ) |&gt; \n  mutate(\n    SkillLevel = factor(\n      SkillLevel, \n      levels = c( 1, 2, 3),\n      labels = c( \"Low Skill\", \"Medium Skill\", \"High Skill\"))\n  )\n\nNow that we have skill levels, we need to add information on urban/rural (from hh_basics) and quintile (from ind_poverty), and type of income earner (from pp_labor).\n\nurb_rur &lt;- hh_basics |&gt; \n  select(UID,QuartNo, UrbanOrRural, RegNo, Weights) |&gt; \n  mutate(\n    UrbanOrRural = factor(\n      UrbanOrRural,\n      levels = c(2,1),\n      labels = c(\"Rural\", \"Urban\")\n    )\n  )\n\nquintiles &lt;- poverty |&gt; \n  select(UID, quintilc) |&gt; \n  rename(Quintile = quintilc) |&gt; \n  mutate(\n    Quintile = factor(\n      Quintile,\n      levels = c(1:5),\n      labels = c(\"Q1\", \"Q2\", \"Q3\", \"Q4\", \"Q5\")\n    )\n  )\n\npp_factor_descriptors &lt;- pp_factor_descriptors |&gt; \n  left_join(urb_rur, join_by(UID)) |&gt; \n  left_join(quintiles, join_by(UID))",
    "crumbs": [
      "Home",
      "Supporting materials",
      "SAM Shares Data Request"
    ]
  },
  {
    "objectID": "supporting-materials/sam-shares-data-request.html#labor-status-and-economic-activities",
    "href": "supporting-materials/sam-shares-data-request.html#labor-status-and-economic-activities",
    "title": "SAM Shares Data Request",
    "section": "Labor status and Economic Activities",
    "text": "Labor status and Economic Activities\nWe work with labor status from Shinda05_1. Since, upon import NACE 2 codes are converted to numbers, we need to convert them back to text, so that we can keep zeros to the left for proper order. We then extract the first two digits and find the correspondence to Rev.Â 2 from the SAM using the look-up table sam_activities. For proper order, we convert the SAM activities columns for job 1 and job 2 to factor, using the order from the dataset sam_factors.\n\npp_emstatus &lt;- pp_labor |&gt; \n  mutate(\n    MemberId = \n      paste0(sprintf(\"%06d\", UID), sprintf(\"%02d\", MemberNo))) |&gt;\n  mutate(\n    # Job 1 NACE Rev 2 code. \n    Q5  = if_else(!is.na(Q5),paste0(sprintf(\"%04d\", Q5)), NA),\n    # Job 2 NACE Rev 2 code.\n    Q12 = if_else(!is.na(Q12),paste0(sprintf(\"%04d\", Q12)), NA)) |&gt; \n  mutate(\n    job1 = if_else(!is.na(Q5),substr(Q5, 1, 2), NA),\n    job2 = if_else(!is.na(Q12),substr(Q12, 1, 2), NA)\n  ) |&gt; \n  # We match to Rev 2 and SAM classifications (for job 1 and job 2)\n  left_join(\n    sam_activities[,c(1,3)], \n    join_by(job1 == rev2_2d)) |&gt; \n  left_join(\n    sam_activities[,c(1,3)],\n    join_by(job2 == rev2_2d),\n    suffix = \n      c(\"_job1\", \"_job2\")) |&gt; \n  # And convert to factors for proper order\n  mutate(\n    SAM_job1 = factor(\n      SAM_job1, \n      levels = sam_factors$SAM,\n      # labels = sam_factors$SAM_description\n      ),\n    SAM_job2 = factor(\n      SAM_job2, \n      levels = sam_factors$SAM,\n      # labels = sam_factors$SAM_description\n      )\n  )\n\nhead(\n  pp_emstatus[c(18, 34, 40, 41, 67),\n  c(\"UID\", \"MemberNo\", \"SAM_job1\", \"SAM_job2\")]) |&gt; \n  gt()\n\n\n\n\n\n\n\nUID\nMemberNo\nSAM_job1\nSAM_job2\n\n\n\n\n386848\n1\na-trd\na-agri\n\n\n386855\n1\na-agri\na-agri\n\n\n386856\n1\na-food\na-agri\n\n\n386856\n2\na-agri\na-agri\n\n\n386866\n2\na-educ\na-educ",
    "crumbs": [
      "Home",
      "Supporting materials",
      "SAM Shares Data Request"
    ]
  },
  {
    "objectID": "supporting-materials/sam-shares-data-request.html#types-of-income",
    "href": "supporting-materials/sam-shares-data-request.html#types-of-income",
    "title": "SAM Shares Data Request",
    "section": "Types of income",
    "text": "Types of income\nBefore making our multi-dimensional tables, we need to identify different types of income. f-lab (wages) and f-surp (capital income). The instruction is that f-surp needs to be split into wages to entrepreneurs/self employed and capital income.\n\npp_emstatus &lt;- pp_emstatus |&gt; \n  mutate(\n    # We add accross three months for each source (and coalesce the NAs to 0)\n    flab_job1 = \n      rowSums(\n        across(starts_with(\"Q8_faqti_\"), \\(x) coalesce(x, 0))),\n    flab_job2 = \n      rowSums(\n        across(starts_with(\"Q14_faqti_\"), \\(x) coalesce(x, 0))),\n    fsurp = \n      rowSums(\n        across(starts_with(\"Q10_faqti_\"), \\(x) coalesce(x, 0)))\n  ) |&gt; \n  # We also add factor labels to Employment Status\n  mutate(\n    Q7 = factor(\n      Q7,\n      levels = c(1:6),\n      labels = c(\n        \"Employee\", \"Employer\", \"Own Account (Non-Ag.)\", \n        \"Own Account (Ag.)\", \"Unpaid Worker\", \"Other\"))\n    ) |&gt; \n  mutate(\n    Q13 = factor(\n      Q13,\n      levels = c(1:6),\n      labels = c(\n        \"Employee\", \"Employer\", \"Own Account (Non-Ag.)\", \n        \"Own Account (Ag.)\", \"Unpaid Worker\", \"Other\"))\n    )\n\nAnd we add our labor market variables to our pp_factor_descriptors dataset.\n\npp_emstatus &lt;- pp_emstatus |&gt;\n  select(-UID,-MemberNo) |&gt; \n  left_join(pp_factor_descriptors, join_by(MemberId)) |&gt; \n  relocate(c(UID, MemberNo, MemberId, QuartNo), .before = 1)",
    "crumbs": [
      "Home",
      "Supporting materials",
      "SAM Shares Data Request"
    ]
  },
  {
    "objectID": "supporting-materials/sam-shares-data-request.html#wages-and-surplus-income",
    "href": "supporting-materials/sam-shares-data-request.html#wages-and-surplus-income",
    "title": "SAM Shares Data Request",
    "section": "Wages and Surplus income",
    "text": "Wages and Surplus income\n\nflab1 &lt;- pp_emstatus |&gt; \n  select(\n    QuartNo,\n    Q7, \n    UrbanOrRural, \n    Quintile, \n    SkillLevel,\n    Gender, \n    flab_job1, \n    SAM_job1, \n    Weights) |&gt;\n  filter(!is.na(flab_job1) & flab_job1 &gt; 0) |&gt; \n  rename(\n    EmStatus = Q7,\n    FLab = flab_job1,\n    SAM = SAM_job1\n  ) |&gt; \n  mutate(\n    FLab = coalesce(FLab, 0) * Weights,\n    FactorType = \"f-lab\"\n  )\n\nflab2 &lt;- pp_emstatus |&gt; \n  select(\n    QuartNo,\n    Q13, \n    UrbanOrRural, \n    Quintile, \n    SkillLevel,\n    Gender, \n    flab_job2, \n    SAM_job2, \n    Weights) |&gt; \n  filter(!is.na(flab_job2) & flab_job2 &gt; 0) |&gt;\n  rename(\n    EmStatus = Q13,\n    FLab = flab_job2,\n    SAM = SAM_job2\n  ) |&gt; \n  mutate(\n    FLab = coalesce(FLab, 0) * Weights,\n    FactorType = \"f-lab\"\n  )\n\nfsurp &lt;- pp_emstatus |&gt; \n  select(\n    QuartNo,\n    Q7, \n    UrbanOrRural, \n    Quintile, \n    SkillLevel,\n    Gender, \n    fsurp, \n    SAM_job1, \n    Weights) |&gt;\n  filter(!is.na(fsurp)) |&gt; \n  rename(\n    EmStatus = Q7,\n    FLab = fsurp,\n    SAM = SAM_job1\n  ) |&gt; \n  mutate(\n    FLab = coalesce(FLab, 0) * Weights,\n    FactorType = \"f-surp\"\n  )\n\nflab &lt;- rbind(flab1, flab2, fsurp)\nis.na(flab$FLab) &lt;- 0",
    "crumbs": [
      "Home",
      "Supporting materials",
      "SAM Shares Data Request"
    ]
  },
  {
    "objectID": "supporting-materials/sam-shares-data-request.html#filling-out-the-templates",
    "href": "supporting-materials/sam-shares-data-request.html#filling-out-the-templates",
    "title": "SAM Shares Data Request",
    "section": "Filling out the templates",
    "text": "Filling out the templates\nWe first get a table with all the possible combinations, so we can make sure f-lab and f-surp have the data that we need.\n\nfactor_income &lt;- flab |&gt;\n  filter(\n    as.numeric(EmStatus) &lt; 6\n  ) |&gt; \n  group_by(\n    FactorType,\n    EmStatus, \n    UrbanOrRural, \n    Quintile, \n    SkillLevel,\n    Gender) |&gt; \n  summarize(FLab = sum(FLab, na.rm = T)) |&gt; \n  ungroup() |&gt; \n  pivot_wider(\n    id_cols = c(FactorType, EmStatus, UrbanOrRural, Quintile, SkillLevel),\n    names_from = c(Gender),\n    values_from = FLab ) |&gt;\n  pivot_wider(\n    id_cols = c(FactorType, EmStatus, UrbanOrRural, Quintile),\n    names_from = c(SkillLevel),\n    values_from = c(Female, Male) ) |&gt;\n  mutate(across(5:10, ~replace_na(., 0)))\n\n\nSalaries and mixed income\nSalaries from employees, salaries paid to business owners, and own account workers (mixed income).\n\nfactor_income_comprehensive &lt;- flab |&gt;\n  filter(\n    as.numeric(EmStatus) &lt; 6\n  ) |&gt; \n  group_by(\n    FactorType,\n    EmStatus, \n    UrbanOrRural, \n    Quintile, \n    SkillLevel,\n    Gender) |&gt; \n  summarize(FLab = sum(FLab, na.rm = T)) |&gt; \n  ungroup() |&gt; \n  pivot_wider(\n    id_cols = c(FactorType, EmStatus, UrbanOrRural, Quintile, SkillLevel),\n    names_from = c(Gender),\n    values_from = FLab ) |&gt;\n  pivot_wider(\n    id_cols = c(FactorType, EmStatus, UrbanOrRural, Quintile),\n    names_from = c(SkillLevel),\n    values_from = c(Female, Male) ) |&gt;\n  mutate(across(5:10, ~replace_na(., 0)))\n\n# Sneak peak\nhead(factor_income_comprehensive[,c(3:7)]) |&gt; \n  gt()\n\n\n\n\n\n\n\nUrbanOrRural\nQuintile\nFemale_Low Skill\nFemale_Medium Skill\nFemale_High Skill\n\n\n\n\nRural\nQ1\n6570741\n73766574\n40787523\n\n\nRural\nQ2\n3136840\n68728533\n61977982\n\n\nRural\nQ3\n3384631\n66745137\n62812282\n\n\nRural\nQ4\n2903820\n89122463\n101713498\n\n\nRural\nQ5\n3978437\n66745042\n211525604\n\n\nUrban\nQ1\n10106489\n140823577\n74910641\n\n\n\n\n\n\n\n\n\nWages\nNow we single out wages.\n\nfactor_income_wages &lt;- flab |&gt;\n  filter(\n    as.numeric(EmStatus) &lt; 6,\n    FactorType == \"f-lab\"\n  ) |&gt; \n  group_by( \n    UrbanOrRural, \n    Quintile, \n    SkillLevel,\n    Gender) |&gt; \n  summarize(FLab = sum(FLab, na.rm = T)) |&gt; \n  ungroup() |&gt; \n  pivot_wider(\n    id_cols = c(UrbanOrRural, Quintile, SkillLevel),\n    names_from = c(Gender),\n    values_from = FLab ) |&gt;\n  pivot_wider(\n    id_cols = c(UrbanOrRural, Quintile),\n    names_from = c(SkillLevel),\n    values_from = c(Female, Male) ) |&gt;\n  mutate(across(3:8, ~replace_na(., 0)))\n\nfactor_income_wages |&gt; \n  gt()\n\n\n\n\n\n\n\nUrbanOrRural\nQuintile\nFemale_Low Skill\nFemale_Medium Skill\nFemale_High Skill\nMale_Low Skill\nMale_Medium Skill\nMale_High Skill\n\n\n\n\nRural\nQ1\n7071449\n73976896\n40873369\n13240854\n149888608\n35772884\n\n\nRural\nQ2\n3136840\n69199593\n62840081\n21365570\n185579382\n43775774\n\n\nRural\nQ3\n3384631\n68131258\n62812282\n9797217\n181840370\n53134918\n\n\nRural\nQ4\n2903820\n89812175\n101771027\n9141381\n243339688\n104186022\n\n\nRural\nQ5\n3978437\n67394473\n213109248\n6026684\n192906975\n206728152\n\n\nUrban\nQ1\n10106489\n140832561\n74981955\n9820052\n166174929\n50228610\n\n\nUrban\nQ2\n14984587\n143794440\n180076456\n23640281\n270874403\n171555924\n\n\nUrban\nQ3\n3875826\n251290586\n353147864\n5550498\n361493523\n395323768\n\n\nUrban\nQ4\n3120367\n236333189\n531182422\n2986762\n454390332\n583664654\n\n\nUrban\nQ5\n10523005\n215233168\n1088737655\n10546093\n386107080\n1244785293\n\n\n\n\n\n\n\n\n\nCapital\nAnd Capital.\n\nfactor_income_capital &lt;- flab |&gt;\n  filter(\n    as.numeric(EmStatus) &lt; 6,\n    FactorType == \"f-surp\"\n  ) |&gt; \n  group_by( \n    UrbanOrRural, \n    Quintile, \n    ) |&gt; \n  summarize(Capital = sum(FLab, na.rm = T)) |&gt; \n  ungroup()\n\nfactor_income_capital |&gt; \n  gt()\n\n\n\n\n\n\n\nUrbanOrRural\nQuintile\nCapital\n\n\n\n\nRural\nQ1\n57510741\n\n\nRural\nQ2\n77436983\n\n\nRural\nQ3\n104578879\n\n\nRural\nQ4\n124723382\n\n\nRural\nQ5\n203923504\n\n\nUrban\nQ1\n91338334\n\n\nUrban\nQ2\n172982396\n\n\nUrban\nQ3\n303575257\n\n\nUrban\nQ4\n397204825\n\n\nUrban\nQ5\n762309667\n\n\n\n\n\n\n\nAnd now, differentiated by economic activity.\n\nfactor_income_wages_activity &lt;- flab |&gt;\n  filter(\n    as.numeric(EmStatus) &lt; 6,\n    FactorType == \"f-lab\"\n  ) |&gt; \n  group_by( \n    Gender,\n    SkillLevel,\n    SAM) |&gt; \n  summarize(FLab = sum(FLab, na.rm = T)) |&gt; \n  ungroup() |&gt; \n  pivot_wider(\n    #id_cols = c(Gender, SkillLevel),\n    names_from = c(SAM),\n    names_expand = T,\n    names_sort = T,\n    values_from = FLab ) |&gt; \n  mutate(across(3:39, ~replace_na(., 0)))\n\n# factor_income_wages_activity |&gt; \n#   gt()\n\nAnd Capital.\n\nfactor_income_capital_activity &lt;- flab |&gt;\n  filter(\n    as.numeric(EmStatus) &lt; 6,\n    FactorType == \"f-surp\"\n  ) |&gt; \n  group_by( \n    SAM) |&gt; \n  summarize(\n    Capital = \"Capital\",\n    FLab = sum(FLab, na.rm = T)) |&gt; \n  ungroup() |&gt; \n  pivot_wider(\n    id_cols = c(Capital),\n    names_from = c(SAM),\n    names_expand = T,\n    names_sort = T,\n    values_from = FLab ) |&gt; \n  mutate(across(2:38, ~replace_na(., 0)))\n\n# factor_income_capital_activity |&gt; \n#   gt()\n\n\n\nAddendum: wages and quantity per employment status.\n\nfactor_income_wages_emStatus_activity &lt;- flab |&gt;\n  filter(\n    as.numeric(EmStatus) &lt; 5,\n    # FactorType == \"f-lab\"\n  ) |&gt;\n  group_by(\n    FactorType,\n    EmStatus,\n    Gender,\n    SkillLevel,\n    SAM) |&gt; \n  summarize(FLab = sum(FLab, na.rm = T),\n            .groups = \"keep\") |&gt; \n  ungroup() |&gt; \n  pivot_wider(\n    #id_cols = c(Gender, SkillLevel),\n    names_from = c(SAM),\n    names_expand = T,\n    names_sort = T,\n    values_fill = 0,\n    values_from = FLab ) |&gt; \n  complete(\n    FactorType,\n    EmStatus,\n    Gender,\n    SkillLevel\n  ) |&gt; \n  mutate(across(5:41, ~replace_na(., 0)))\n\nNumber of people.\n\nnoppl1 &lt;- pp_emstatus |&gt; \n  select(\n    QuartNo,\n    Q7, \n    UrbanOrRural, \n    Quintile, \n    SkillLevel,\n    Gender, \n    flab_job1, \n    SAM_job1, \n    Weights) |&gt;\n  filter(!is.na(flab_job1) & !is.na(Q7)) |&gt;\n  rename(\n    EmStatus = Q7,\n    FLab = flab_job1,\n    SAM = SAM_job1\n  ) |&gt; \n  mutate(\n    FLab = coalesce(FLab, 0) * Weights,\n    FactorType = \"f-lab\"\n  )\n\nnoppl2 &lt;- pp_emstatus |&gt; \n  select(\n    QuartNo,\n    Q13, \n    UrbanOrRural, \n    Quintile, \n    SkillLevel,\n    Gender, \n    flab_job2, \n    SAM_job2, \n    Weights) |&gt; \n  filter(!is.na(flab_job2 & !is.na(Q13))) |&gt;\n  rename(\n    EmStatus = Q13,\n    FLab = flab_job2,\n    SAM = SAM_job2\n  ) |&gt; \n  mutate(\n    FLab = coalesce(FLab, 0) * Weights,\n    FactorType = \"f-lab\"\n  )\n\nnopplsurp &lt;- pp_emstatus |&gt; \n  select(\n    QuartNo,\n    Q7, \n    UrbanOrRural, \n    Quintile, \n    SkillLevel,\n    Gender, \n    fsurp, \n    SAM_job1, \n    Weights) |&gt;\n  filter(!is.na(fsurp) & !is.na(Q7)) |&gt;\n  rename(\n    EmStatus = Q7,\n    FLab = fsurp,\n    SAM = SAM_job1\n  ) |&gt; \n  mutate(\n    FLab = coalesce(FLab, 0) * Weights,\n    FactorType = \"f-surp\"\n  )\n\nnoppl &lt;- rbind(noppl1, noppl2, nopplsurp)\nis.na(noppl$FLab) &lt;- 0\n\n\nno_people &lt;- noppl |&gt;\n  filter(\n    # as.numeric(EmStatus) &lt; 5,\n    QuartNo == 110,\n    !is.na(EmStatus)\n    # FactorType == \"f-lab\"\n  ) |&gt;\n  group_by(\n    FactorType,\n    EmStatus,\n    Gender,\n    SkillLevel,\n    SAM) |&gt; \n  summarize(No_People = sum(Weights, na.rm = T),\n            .groups = \"keep\") |&gt; \n  ungroup() |&gt; \n  pivot_wider(\n    #id_cols = c(Gender, SkillLevel),\n    names_from = c(SAM),\n    names_expand = T,\n    names_sort = T,\n    values_fill = 0,\n    values_from = No_People ) |&gt; \n  complete(\n    FactorType,\n    EmStatus,\n    Gender,\n    SkillLevel\n  ) |&gt; \n  mutate(across(5:41, ~replace_na(., 0)))",
    "crumbs": [
      "Home",
      "Supporting materials",
      "SAM Shares Data Request"
    ]
  },
  {
    "objectID": "supporting-materials/sam-shares-data-request.html#datasets-ilcs-2022",
    "href": "supporting-materials/sam-shares-data-request.html#datasets-ilcs-2022",
    "title": "SAM Shares Data Request",
    "section": "Datasets (ILCS 2022)",
    "text": "Datasets (ILCS 2022)\n\n# Household Unique ID, Weights, Location and other basic variables\nhh_basics_22 &lt;- read_dta(\n  \"data/ilcs_2022/sysschedule.dta\") |&gt;\n  mutate(\n    UID = as.integer(UID))\n\n# Household size (includes no. of family members)\nhh_size_22 &lt;- read_dta(\n  \"data/ilcs_2022/familysize.dta\")|&gt; \n  mutate(\n    UID = as.integer(UID))\n\n# Processed income at household level\nhh_income_22 &lt;- read_dta(\n  \"data/ilcs_2022/tblincomes.dta\")|&gt; \n  mutate(\n    UID = as.integer(UID))\n\n# Consumption aggregate at household level \nhh_expenditure_22 &lt;- read_dta(\n  \"data/ilcs_2022/tblexpenditures.dta\")|&gt; \n  rename(# rename total expenditure variables\n         total_expenditure = MTlianixarjebi_,\n         total_expenditure_aeq06 = MTlianimoxmareba_EqAdScale,\n         total_expenditure_aeq08 = Mtlianimoxmareba_EqAdScale_08) |&gt; \n  mutate(\n    UID = as.integer(UID))\n\n# Characteristics of the dwelling\nhh_chars_22 &lt;- read_dta(\n  \"data/ilcs_2022/tblshinda01.dta\")|&gt;\n  mutate(\n    UID = as.integer(UID))\n\n# Persons (pp)\npp_22 &lt;- read_dta(\n  \"data/ilcs_2022/tblshinda02.dta\") |&gt; \n  mutate(\n    UID = as.integer(UID),\n    MemberNo = as.integer(MemberNo))\n\n\n# Poverty\npoverty_22 &lt;- read_dta(\n  \"data/ilcs_2022/POVERTY.dta\") |&gt; \n  mutate(\n    UID = as.integer(UID))\n\nHere we have the issue that for Household Expenditures the documentation claims to use COICOP, but we have a simple 5 digit structure that doesnât match any of the forms of COICOP. Thereâs a processed dataset that summarizes the following:\nTotal cash consumption expenditure - On food, beverages, tobacco - On clothing and footwear - On household goods - On health care - On fuel and electricity - On transport - On education\nOther consumption expenditure - Non-consumption cash expenditure - On agricultural activity - On transfers - On saving and lending - On property acquisition\nWe will create pivot tables out of that with the 2022 Household Survey. ## Descriptors\nTransfers out\n\nurb_rur_22 &lt;- hh_basics_22 |&gt; \n  select(UID, UrbanOrRural, RegNo, Weights) |&gt; \n  mutate(\n    UrbanOrRural = factor(\n      UrbanOrRural,\n      levels = c(2,1),\n      labels = c(\"Rural\", \"Urban\")\n    )\n  )\n\nquintiles_22 &lt;- poverty_22 |&gt; \n  select(UID, quintilc) |&gt; \n  rename(Quintile = quintilc) |&gt; \n  mutate(\n    Quintile = factor(\n      Quintile,\n      levels = c(1:5),\n      labels = c(\"Q1\", \"Q2\", \"Q3\", \"Q4\", \"Q5\")\n    )\n  )\n\nhh_consumption_22 &lt;- hh_expenditure_22 |&gt; \n  left_join(urb_rur_22, join_by(UID)) |&gt; \n  left_join(quintiles_22, join_by(UID)) |&gt; \n  rename(\n    \"CE. Food, beverages, and tobacco\" = sursati__sasmeli__Tambaqo,\n    \"CE. Clothing and footwear\" = tansacmeli,\n    \"CE. Household goods\" = saojaxo,\n    \"CE. Health care\" = samedicino,\n    \"CE. Fuel and electricity\" = energia,\n    \"CE. Transport\" = transporti,\n    \"CE. Education\" = ganatleba,\n    \"CE. Other consumption expenditure\" = sxva,\n    \"Total cash consumption expenditure\" = samomxmXarjebi,\n    \"NC. Agricultural activity\" = sasoflo,\n    \"NC. Transfers\" = transferti,\n    \"NC. Saving and lending\" = DazogvaAnCasesxeba,\n    \"NC. Property acquisition\" = qonebis_seZena,\n    \"Non-consumption cash expenditure\" = SxvaGasavlebi,\n    \"Non-cash expenditure\" = Arafuladi_moxm_,\n    \"Cash expenditure, total\" = fuladixarjebi,\n    \"Consumption expenditure, total\" = MTlianimoxmareba_,\n  )\n\nTransfers In\n\nurb_rur_22 &lt;- hh_basics_22 |&gt; \n  select(UID, UrbanOrRural, RegNo, Weights) |&gt; \n  mutate(\n    UrbanOrRural = factor(\n      UrbanOrRural,\n      levels = c(2,1),\n      labels = c(\"Rural\", \"Urban\")\n    )\n  )\n\nquintiles_22 &lt;- poverty_22 |&gt; \n  select(UID, quintilc) |&gt; \n  rename(Quintile = quintilc) |&gt; \n  mutate(\n    Quintile = factor(\n      Quintile,\n      levels = c(1:5),\n      labels = c(\"Q1\", \"Q2\", \"Q3\", \"Q4\", \"Q5\")\n    )\n  )\n\nhh_incomes_22 &lt;- hh_income_22 |&gt; \n  left_join(urb_rur_22, join_by(UID)) |&gt; \n  left_join(quintiles_22, join_by(UID)) |&gt; \n  rename(\n    \"CI. From hired employment\" = ShemDaq,\n    \"CI. From self employment\" = ShemTviTdasaqm,\n    \"CI. From selling agricultural production\" = Shem_Sof,\n    \"CI. Property income (leasing, interest etc.)\" = Qonebidan,\n    \"CI. Pensions, scholarships, assistances\" = PensStipDaxm,\n    \"CI. Remittances from abroad\" = Ucxoetidan,\n    \"CI. Money received as a gift\" = Axloblebisagan,\n    \"CI. Property disposal\" = QonebisGayidvit,\n    \"CI. Income from borrowing and savings\" = SesxAnDanazog,\n  )",
    "crumbs": [
      "Home",
      "Supporting materials",
      "SAM Shares Data Request"
    ]
  },
  {
    "objectID": "supporting-materials/sam-shares-data-request.html#template",
    "href": "supporting-materials/sam-shares-data-request.html#template",
    "title": "SAM Shares Data Request",
    "section": "Template",
    "text": "Template\nFirst we pivot our expenditures longer.\n\nhh_consumption_22 &lt;- hh_consumption_22 |&gt;\n  select(\n    -c(\n      `Total cash consumption expenditure`, \n      `Non-consumption cash expenditure`, \n      `Non-cash expenditure`, \n      `Cash expenditure, total`, \n      `Consumption expenditure, total`,\n      total_expenditure,\n      total_expenditure_aeq06, \n      total_expenditure_aeq08)) |&gt; \n  pivot_longer(\n    cols = c(\n    \"CE. Food, beverages, and tobacco\",\n    \"CE. Clothing and footwear\",\n    \"CE. Household goods\",\n    \"CE. Health care\",\n    \"CE. Fuel and electricity\",\n    \"CE. Transport\",\n    \"CE. Education\",\n    \"CE. Other consumption expenditure\",\n    \"NC. Agricultural activity\",\n    \"NC. Transfers\",\n    \"NC. Saving and lending\",\n    \"NC. Property acquisition\"\n    ),\n    names_to = \"ConsumptionCategory\", \n    values_to = \"Consumption\"\n  ) |&gt; \n  mutate(\n    ConsumptionCategory = factor(\n      ConsumptionCategory,\n      levels = c(\n        \"CE. Food, beverages, and tobacco\",\n        \"CE. Clothing and footwear\",\n        \"CE. Household goods\",\n        \"CE. Fuel and electricity\",\n        \"CE. Transport\",\n        \"CE. Education\",\n        \"CE. Health care\",\n        \"CE. Other consumption expenditure\",\n        \"NC. Agricultural activity\",\n        \"NC. Transfers\",\n        \"NC. Saving and lending\",\n        \"NC. Property acquisition\"\n      )\n    )\n  )\n\nAnd now we can fill our template.\n\nhh_consumption_pivot &lt;- hh_consumption_22 |&gt;\n  group_by( \n    ConsumptionCategory,\n    UrbanOrRural, \n    Quintile) |&gt; \n  summarize(\n    Consumption = sum((coalesce(Consumption, 0) * Weights), na.rm = T)) |&gt; \n  ungroup() |&gt; \n  pivot_wider(\n    #id_cols = c(Capital),\n    names_from = c(UrbanOrRural, Quintile),\n    names_expand = T,\n    names_sort = T,\n    values_from = Consumption )\n\nAnd now we pivot our incomes longer.\n\nhh_incomes_22 &lt;- hh_incomes_22 |&gt;\n  select(\n    -c(\n      ShemosavaliDaTransf,\n      SxvaFuladiSaxsrebi,\n      ArafuladiMoxmareba,\n      Shemosavalisul,\n      Fuladisaxsrebi,\n      Saxsrebi_Sul)) |&gt; \n  pivot_longer(\n    cols = c(\n    \"CI. From hired employment\",\n    \"CI. From self employment\",\n    \"CI. From selling agricultural production\", \n    \"CI. Property income (leasing, interest etc.)\",\n    \"CI. Pensions, scholarships, assistances\",\n    \"CI. Remittances from abroad\",\n    \"CI. Money received as a gift\",\n    \"CI. Property disposal\",\n    \"CI. Income from borrowing and savings\"\n    ),\n    names_to = \"IncomeCategory\", \n    values_to = \"Income\"\n  ) |&gt; \n  mutate(\n    IncomeCategory = factor(\n      IncomeCategory,\n      levels = c(\n        \"CI. From hired employment\",\n    \"CI. From self employment\",\n    \"CI. From selling agricultural production\", \n    \"CI. Property income (leasing, interest etc.)\",\n    \"CI. Pensions, scholarships, assistances\",\n    \"CI. Remittances from abroad\",\n    \"CI. Money received as a gift\",\n    \"CI. Property disposal\",\n    \"CI. Income from borrowing and savings\"\n      )\n    )\n  )\n\nAnd we fill our template\n\nhh_incomes_pivot &lt;- hh_incomes_22 |&gt;\n  group_by( \n    IncomeCategory,\n    UrbanOrRural, \n    Quintile) |&gt; \n  summarize(\n    Income = sum((coalesce(Income, 0) * Weights), na.rm = T)) |&gt; \n  ungroup() |&gt; \n  pivot_wider(\n    #id_cols = c(Capital),\n    names_from = c(UrbanOrRural, Quintile),\n    names_expand = T,\n    names_sort = T,\n    values_from = Income )",
    "crumbs": [
      "Home",
      "Supporting materials",
      "SAM Shares Data Request"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This site was created for reproducibility purposes by World Bank consultant Renato Vargas.\nContact information:\n\nE-mail: hvargasaldana [at] worldbank [dot] org\nLinkedIn: https://www.linkedin.com/in/revargas/\nWebsite: renatovargas.com"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Georgia Country Climate and Development Report",
    "section": "",
    "text": "This website contains background documents and guides created for Georgiaâs World Bank Country Climate and Development Report. Authorship is indicated in each document.\n\n\n\n\n\n\n\n\nFigureÂ 1: Map of Georgia at administrative level 1 (ADM1)"
  },
  {
    "objectID": "supporting-materials/geo-microsimulation.html",
    "href": "supporting-materials/geo-microsimulation.html",
    "title": "Georgia CCDR Microsimulation",
    "section": "",
    "text": "In this calculation file, we âageâ the Georgian household survey according to demographic projections and different macroeconomic scenarios to explore the impact of climate-related risks and policy measures on the consumption expenditure distribution. It is part of a larger project with all background contributions to Georgiaâs CCDR, available in this repository.\nUsing RStudio project makes it possible to not use setwd() to establish the root directory and refer to subdirectories in a relative manner, making interoperability easier within teams and not hard coding a particular computerâs file structure into the code. If you are using Positron or Visual Studio Code (and the Quarto extension) just âopen folderâ at the root of the repository. If you are using R directly, just add setwd(r'(C:\\My\\path\\to\\project\\root)') at the beginning of your coding session.\n\n\nWe start with a clean environment, making sure that any objects from a previous session are not present. We keep our country ISO code in a variable iso in case we need it later.\n\n# Clean workspace\nrm(list = ls())\n\n# Georgia country ISO code\niso &lt;- \"GEO\"\n\n# Survey year\nsurvey_year &lt;- 2023\n\n# # Exchange rate USD per GEL (Multiply by this to show results in USD)\n# er &lt;- 0.37\n\n# Exchange rate 2017 (PPP) 2.6280 GEL per 1 US$ \n\n# Poverty lines\npline0 &lt;- 212.8149 # Official USD3.60/Person/Day\n# Using Georgia CPI, the 6.85 line would be (2023) GEL 355.10/person/month\n# Using $3.60 in email, the 6.85 line would be (2023) GEL 404.9395\npline61 &lt;- 355.10 # Intl. Poverty line of USD6.85/Person/Day\npline62 &lt;- 404.9395 # Intl. Poverty line of USD6.85/Person/Day\n\n# Poverty line used in the script below\npline &lt;- pline0\n\n# Years of interest for our macroeconomic scenario analysis\nanalysis_years &lt;- c(2030, 2050)\n\nWe call the appropriate libraries.\nRather than calling our libraries as we go, we will make sure we have everything we need from the beginning.\n\nlibrary(tidyverse) # includes dplyr, ggplot2, purr...\nlibrary(haven)     # to read SPSS and Stata datasets\nlibrary(readxl)    # to read from MS-Excel\nlibrary(openxlsx)  # to write to MS-Excel.\nlibrary(gt)        # pretty tables\nlibrary(car)       # companion to applied regression\nlibrary(modelr)    # regression models\n#library(anesrake)  \n# Raking reweighting but we don't load it, because \n# it changes the meaning of summarize from dplyr, \n# so we use the form anesrake::anesrake() when using it.\nlibrary(janitor)   # pretty subtotals\nlibrary(broom)     # More regressions\nlibrary(zoo)       # Calculate moving window average and max value\n# library(Hmisc)     # Estimates deciles, quintiles but use :: version too\n# library(ineq) # Inequality measures\n# library(acid) # Inequality measures we use acid::weighted.gini()\n\n# Geopackages\nlibrary(sf)        # to read and write shapefile maps\nlibrary(terra)     # to perform geocalculations\nlibrary(tmap)      # for static and interactive maps\n\n\n\n\nWe then load the datasets that we need for this study. These are based on Georgiaâs Integrated Living Conditions Survey 2022 (GEOSTAT, 2023). We make a note that the household identification variable is UID.\n\n## Household Unique ID, Weights, Location and other basic variables\nhh_basics &lt;- read_sav(\n  \"data/ilcs_2023/sysschedule.sav\") |&gt;\n  mutate(\n    UID = as.integer(UID))\n\n# Household size (includes no. of family members)\nhh_size &lt;- read_sav(\n  \"data/ilcs_2023/familysize.sav\")|&gt; \n  mutate(\n    UID = as.integer(UID))\n\n# Processed income at household level\nhh_income &lt;- read_sav(\n  \"data/ilcs_2023/tblincomes.sav\")|&gt; \n  mutate(\n    UID = as.integer(UID))\n\n# Consumption aggregate at household level \nhh_expenditure &lt;- read_sav(\n  \"data/ilcs_2023/tblexpenditures.sav\")|&gt; \n  rename(# rename total expenditure variables\n         total_expenditure = MTlianixarjebi_,\n         total_expenditure_aeq06 = MTlianimoxmareba_EqAdScale,\n         total_expenditure_aeq08 = Mtlianimoxmareba_EqAdScale_08) |&gt; \n  mutate(\n    UID = as.integer(UID))\n\n# Characteristics of the dwelling\nhh_chars &lt;- read_sav(\n  \"data/ilcs_2023/tblshinda01.sav\")|&gt;\n  mutate(\n    UID = as.integer(UID))\n\n# Persons (pp)\npp &lt;- read_sav(\n  \"data/ilcs_2023/tblshinda02.sav\") |&gt; \n  mutate(\n    UID = as.integer(UID),\n    MemberNo = as.integer(MemberNo))\n\n# Labor (pp)\npp_labor &lt;- read_sav(\n  \"data/ilcs_2023/tblshinda05_1.sav\") |&gt; \n  mutate(\n    UID = as.integer(UID),\n    MemberNo = as.integer(MemberNo),\n    Q5  = as.integer(Q5),\n    Q12 = as.integer(Q12)) \n\n# Poverty\npoverty &lt;- read_dta(\n  \"data/ilcs_2023/POVERTY_stata.dta\") |&gt; \n  rename(official_pline = pline) |&gt; \n  mutate(\n    UID = as.integer(UID),\n    poor_2023 = if_else(aecons &lt; pline, 1, 0))\n\n# Ind. Poverty\nind_poverty &lt;- read_dta(\n  \"data/ilcs_2023/IND_POVERTY_stata.dta\") |&gt; \n  rename(MemberNo = memberno) |&gt; \n  mutate(\n    UID = as.integer(UID),\n    MemberNo = as.integer(MemberNo))\n\n# Food diary\nfood_q &lt;- read_sav(\n  \"data/ilcs_2023/tblconsumption.sav\") |&gt; \n  rename(UID = UID)\n\nfood_price &lt;- read_sav( \n  \"data/ilcs_2023/tblavgprices.sav\")\n\n# Maps\nadm1 &lt;- sf::read_sf(\"data/gis/geo-adm1.shp\") |&gt;\n  dplyr::select(RegNo, region, ADM1_PCODE, ADM1_EN, ADM1_KA, geometry) |&gt;\n  dplyr::arrange(ADM1_PCODE)\n\nregions &lt;- as.data.frame(adm1) |&gt; \n  select(-geometry)\n\nWe also need look-up tables.\n\nsam_activities &lt;- read_excel(\n    \"data/sam/classifications.xlsx\",\n    sheet = \"SAM-REV2\",\n    col_names = T,\n    col_types = c(\"text\", \"text\", \"text\",\"text\", \"numeric\")\n  )\n\nsam_factors &lt;- read_excel(\n    \"data/sam/classifications.xlsx\",\n    sheet = \"SAM factors\",\n    col_names = T,\n    col_types = \"text\",\n  )\n\ncoicop &lt;- read_excel(\n    \"data/sam/classifications.xlsx\",\n    sheet = \"COICOP\",\n    col_names = T,\n    col_types = \"text\",\n  ) |&gt; \n  mutate(simple_code = as.integer(gsub(\"\\\\.\", \"\", Coicop)))\n\ncoicop_filtered &lt;- coicop |&gt; \n  filter( nchar(as.character(simple_code)) &gt;= 5)\n\nWe also have Continuous Labor Survey data at the individual level, which will come in handy if we do not get access to the labor part of the ILCS. See data folder for documents describing the datasets.\n\n# Labor Force Survey\nlfs_2023 &lt;- read_sav(\n  \"data/lfs_2023/LFS_ECSTAT_ENG_2023.sav\") |&gt; \n  rename(UID = UID)\n\n# Labor Force Survey Demographic Characteristics\nlfs_2023_dem &lt;- read_sav(\n  \"data/lfs_2023/LFS_Demographic_ENG_2023.sav\") |&gt; \n  rename(UID = UID)\n\nWe will work non-destructively, meaning we will not rewrite these data sets and we will only create intermediate data frame objects from them to perform transformations, selections and other data management tasks. For example, we will keep household assignment to poverty status and consumption deciles handy by creating a subset of our hh_expenditure data with only our household identifiers, deciles, and poverty if available.\n\n# We will estimate deciles from consumption\ndeciles &lt;- hh_expenditure |&gt; \n  select( \n    # Keep household id and expenditure variables\n    UID, \n    total_expenditure,\n    total_expenditure_aeq06, # Adult equivalent * 0.6\n    total_expenditure_aeq08) # Adult equivalent * 0.8\n\nOur population data comes from UNâs projections.\n\npopulation_projections &lt;- read_dta(\"data/population/UN2022_population.dta\") |&gt; \n  filter(country == iso) # we filter for Georgia\n\nThe macro scenario dataset is an input provided by the Macroeconomic CGE simulation team, with yearly information on GDP, working age population, employment by economic activity (for an aggregation of three sectors: agriculture, manufacturing, and services), wages by economic activity, value added by economic activity, remittances, consumer price index, food price index and energy price index (for a bundle of gas, oil, coal, electricity) by decile (10 representative households in the macro model), and carbon tax revenue transfers to household deciles.\n\nscenario_file &lt;- \"data/sam/MacroScenarioInformation_GEO.xlsx\"\nscenario_varlist &lt;- read_xlsx(\"data/sam/GEO_Macro_varlist.xlsx\") |&gt; \n  select(-category)\n# prices_2030 &lt;-\n#   read.csv(\"data/ARM-Microsimulation/prices2030.csv\")\n\nEconomic Activities in the Survey are in Georgian. The following dataset is a lookup table with the English names.\n\n# Equivalence table\nsectors &lt;- read_excel(\n    \"data/sam/classifications.xlsx\",\n    sheet = \"SAM-REV2\",\n    col_names = T,\n    col_types = \"text\",\n  )\n\nWe also have an Excel file with changes to labor productivity due to climate variability, by sector. Also, we have livestock productivity changes.\n\nlabor_productivity &lt;-\n  read.csv(\n    \"data/climate_productivity/GEO_labour_REF_shock_admin1_bySector.csv\")\n\nagriculture_productivity &lt;-\n  read.csv(\n    \"data/climate_productivity/GEO_agriculture_revenue_impact_GCM-Historical.csv\"\n  )\n\nlivestock_productivity &lt;-\n  read.csv(\n    \"data/climate_productivity/GEO_livestock_REF_shock_admin1_high_prop_holstein.csv\"\n  )\n\nAnd finally, direct effects on consumption of Macro scenarios.\n\n# HH Consumption Macro Effect\nhh_consumption_effects &lt;- read_excel(\n    \"data/sam/MacroconsumptionEffect_HH_GEO.xlsx\",\n    sheet = \"HH_consumption_value\",\n    col_names = F,\n    range = \"A90:AD119\"\n  )\n\nNew names:\nâ¢ `` -&gt; `...1`\nâ¢ `` -&gt; `...2`\nâ¢ `` -&gt; `...3`\nâ¢ `` -&gt; `...4`\nâ¢ `` -&gt; `...5`\nâ¢ `` -&gt; `...6`\nâ¢ `` -&gt; `...7`\nâ¢ `` -&gt; `...8`\nâ¢ `` -&gt; `...9`\nâ¢ `` -&gt; `...10`\nâ¢ `` -&gt; `...11`\nâ¢ `` -&gt; `...12`\nâ¢ `` -&gt; `...13`\nâ¢ `` -&gt; `...14`\nâ¢ `` -&gt; `...15`\nâ¢ `` -&gt; `...16`\nâ¢ `` -&gt; `...17`\nâ¢ `` -&gt; `...18`\nâ¢ `` -&gt; `...19`\nâ¢ `` -&gt; `...20`\nâ¢ `` -&gt; `...21`\nâ¢ `` -&gt; `...22`\nâ¢ `` -&gt; `...23`\nâ¢ `` -&gt; `...24`\nâ¢ `` -&gt; `...25`\nâ¢ `` -&gt; `...26`\nâ¢ `` -&gt; `...27`\nâ¢ `` -&gt; `...28`\nâ¢ `` -&gt; `...29`\nâ¢ `` -&gt; `...30`\n\nnames(hh_consumption_effects) &lt;- c(\"scenario_id\", \"hh_type\",c(2023:2050))\nhh_consumption_effects &lt;- hh_consumption_effects |&gt; \n  mutate(\n    scenario_id = case_when(\n      scenario_id == \"ccdr_all_dry_hot\" ~ \"dryhot\",\n      scenario_id == \"ccdr_all_wet_warm\" ~ \"wetwarm\",\n      scenario_id == \"ccdr_NZS_10_10\" ~ \"nzs\",\n      .default = scenario_id\n    )) |&gt; \n  select(-3)",
    "crumbs": [
      "Home",
      "Supporting materials",
      "Georgia CCDR Microsimulation"
    ]
  },
  {
    "objectID": "supporting-materials/geo-microsimulation.html#preamble",
    "href": "supporting-materials/geo-microsimulation.html#preamble",
    "title": "Georgia CCDR Microsimulation",
    "section": "",
    "text": "We start with a clean environment, making sure that any objects from a previous session are not present. We keep our country ISO code in a variable iso in case we need it later.\n\n# Clean workspace\nrm(list = ls())\n\n# Georgia country ISO code\niso &lt;- \"GEO\"\n\n# Survey year\nsurvey_year &lt;- 2023\n\n# # Exchange rate USD per GEL (Multiply by this to show results in USD)\n# er &lt;- 0.37\n\n# Exchange rate 2017 (PPP) 2.6280 GEL per 1 US$ \n\n# Poverty lines\npline0 &lt;- 212.8149 # Official USD3.60/Person/Day\n# Using Georgia CPI, the 6.85 line would be (2023) GEL 355.10/person/month\n# Using $3.60 in email, the 6.85 line would be (2023) GEL 404.9395\npline61 &lt;- 355.10 # Intl. Poverty line of USD6.85/Person/Day\npline62 &lt;- 404.9395 # Intl. Poverty line of USD6.85/Person/Day\n\n# Poverty line used in the script below\npline &lt;- pline0\n\n# Years of interest for our macroeconomic scenario analysis\nanalysis_years &lt;- c(2030, 2050)\n\nWe call the appropriate libraries.\nRather than calling our libraries as we go, we will make sure we have everything we need from the beginning.\n\nlibrary(tidyverse) # includes dplyr, ggplot2, purr...\nlibrary(haven)     # to read SPSS and Stata datasets\nlibrary(readxl)    # to read from MS-Excel\nlibrary(openxlsx)  # to write to MS-Excel.\nlibrary(gt)        # pretty tables\nlibrary(car)       # companion to applied regression\nlibrary(modelr)    # regression models\n#library(anesrake)  \n# Raking reweighting but we don't load it, because \n# it changes the meaning of summarize from dplyr, \n# so we use the form anesrake::anesrake() when using it.\nlibrary(janitor)   # pretty subtotals\nlibrary(broom)     # More regressions\nlibrary(zoo)       # Calculate moving window average and max value\n# library(Hmisc)     # Estimates deciles, quintiles but use :: version too\n# library(ineq) # Inequality measures\n# library(acid) # Inequality measures we use acid::weighted.gini()\n\n# Geopackages\nlibrary(sf)        # to read and write shapefile maps\nlibrary(terra)     # to perform geocalculations\nlibrary(tmap)      # for static and interactive maps",
    "crumbs": [
      "Home",
      "Supporting materials",
      "Georgia CCDR Microsimulation"
    ]
  },
  {
    "objectID": "supporting-materials/geo-microsimulation.html#datasets",
    "href": "supporting-materials/geo-microsimulation.html#datasets",
    "title": "Georgia CCDR Microsimulation",
    "section": "",
    "text": "We then load the datasets that we need for this study. These are based on Georgiaâs Integrated Living Conditions Survey 2022 (GEOSTAT, 2023). We make a note that the household identification variable is UID.\n\n## Household Unique ID, Weights, Location and other basic variables\nhh_basics &lt;- read_sav(\n  \"data/ilcs_2023/sysschedule.sav\") |&gt;\n  mutate(\n    UID = as.integer(UID))\n\n# Household size (includes no. of family members)\nhh_size &lt;- read_sav(\n  \"data/ilcs_2023/familysize.sav\")|&gt; \n  mutate(\n    UID = as.integer(UID))\n\n# Processed income at household level\nhh_income &lt;- read_sav(\n  \"data/ilcs_2023/tblincomes.sav\")|&gt; \n  mutate(\n    UID = as.integer(UID))\n\n# Consumption aggregate at household level \nhh_expenditure &lt;- read_sav(\n  \"data/ilcs_2023/tblexpenditures.sav\")|&gt; \n  rename(# rename total expenditure variables\n         total_expenditure = MTlianixarjebi_,\n         total_expenditure_aeq06 = MTlianimoxmareba_EqAdScale,\n         total_expenditure_aeq08 = Mtlianimoxmareba_EqAdScale_08) |&gt; \n  mutate(\n    UID = as.integer(UID))\n\n# Characteristics of the dwelling\nhh_chars &lt;- read_sav(\n  \"data/ilcs_2023/tblshinda01.sav\")|&gt;\n  mutate(\n    UID = as.integer(UID))\n\n# Persons (pp)\npp &lt;- read_sav(\n  \"data/ilcs_2023/tblshinda02.sav\") |&gt; \n  mutate(\n    UID = as.integer(UID),\n    MemberNo = as.integer(MemberNo))\n\n# Labor (pp)\npp_labor &lt;- read_sav(\n  \"data/ilcs_2023/tblshinda05_1.sav\") |&gt; \n  mutate(\n    UID = as.integer(UID),\n    MemberNo = as.integer(MemberNo),\n    Q5  = as.integer(Q5),\n    Q12 = as.integer(Q12)) \n\n# Poverty\npoverty &lt;- read_dta(\n  \"data/ilcs_2023/POVERTY_stata.dta\") |&gt; \n  rename(official_pline = pline) |&gt; \n  mutate(\n    UID = as.integer(UID),\n    poor_2023 = if_else(aecons &lt; pline, 1, 0))\n\n# Ind. Poverty\nind_poverty &lt;- read_dta(\n  \"data/ilcs_2023/IND_POVERTY_stata.dta\") |&gt; \n  rename(MemberNo = memberno) |&gt; \n  mutate(\n    UID = as.integer(UID),\n    MemberNo = as.integer(MemberNo))\n\n# Food diary\nfood_q &lt;- read_sav(\n  \"data/ilcs_2023/tblconsumption.sav\") |&gt; \n  rename(UID = UID)\n\nfood_price &lt;- read_sav( \n  \"data/ilcs_2023/tblavgprices.sav\")\n\n# Maps\nadm1 &lt;- sf::read_sf(\"data/gis/geo-adm1.shp\") |&gt;\n  dplyr::select(RegNo, region, ADM1_PCODE, ADM1_EN, ADM1_KA, geometry) |&gt;\n  dplyr::arrange(ADM1_PCODE)\n\nregions &lt;- as.data.frame(adm1) |&gt; \n  select(-geometry)\n\nWe also need look-up tables.\n\nsam_activities &lt;- read_excel(\n    \"data/sam/classifications.xlsx\",\n    sheet = \"SAM-REV2\",\n    col_names = T,\n    col_types = c(\"text\", \"text\", \"text\",\"text\", \"numeric\")\n  )\n\nsam_factors &lt;- read_excel(\n    \"data/sam/classifications.xlsx\",\n    sheet = \"SAM factors\",\n    col_names = T,\n    col_types = \"text\",\n  )\n\ncoicop &lt;- read_excel(\n    \"data/sam/classifications.xlsx\",\n    sheet = \"COICOP\",\n    col_names = T,\n    col_types = \"text\",\n  ) |&gt; \n  mutate(simple_code = as.integer(gsub(\"\\\\.\", \"\", Coicop)))\n\ncoicop_filtered &lt;- coicop |&gt; \n  filter( nchar(as.character(simple_code)) &gt;= 5)\n\nWe also have Continuous Labor Survey data at the individual level, which will come in handy if we do not get access to the labor part of the ILCS. See data folder for documents describing the datasets.\n\n# Labor Force Survey\nlfs_2023 &lt;- read_sav(\n  \"data/lfs_2023/LFS_ECSTAT_ENG_2023.sav\") |&gt; \n  rename(UID = UID)\n\n# Labor Force Survey Demographic Characteristics\nlfs_2023_dem &lt;- read_sav(\n  \"data/lfs_2023/LFS_Demographic_ENG_2023.sav\") |&gt; \n  rename(UID = UID)\n\nWe will work non-destructively, meaning we will not rewrite these data sets and we will only create intermediate data frame objects from them to perform transformations, selections and other data management tasks. For example, we will keep household assignment to poverty status and consumption deciles handy by creating a subset of our hh_expenditure data with only our household identifiers, deciles, and poverty if available.\n\n# We will estimate deciles from consumption\ndeciles &lt;- hh_expenditure |&gt; \n  select( \n    # Keep household id and expenditure variables\n    UID, \n    total_expenditure,\n    total_expenditure_aeq06, # Adult equivalent * 0.6\n    total_expenditure_aeq08) # Adult equivalent * 0.8\n\nOur population data comes from UNâs projections.\n\npopulation_projections &lt;- read_dta(\"data/population/UN2022_population.dta\") |&gt; \n  filter(country == iso) # we filter for Georgia\n\nThe macro scenario dataset is an input provided by the Macroeconomic CGE simulation team, with yearly information on GDP, working age population, employment by economic activity (for an aggregation of three sectors: agriculture, manufacturing, and services), wages by economic activity, value added by economic activity, remittances, consumer price index, food price index and energy price index (for a bundle of gas, oil, coal, electricity) by decile (10 representative households in the macro model), and carbon tax revenue transfers to household deciles.\n\nscenario_file &lt;- \"data/sam/MacroScenarioInformation_GEO.xlsx\"\nscenario_varlist &lt;- read_xlsx(\"data/sam/GEO_Macro_varlist.xlsx\") |&gt; \n  select(-category)\n# prices_2030 &lt;-\n#   read.csv(\"data/ARM-Microsimulation/prices2030.csv\")\n\nEconomic Activities in the Survey are in Georgian. The following dataset is a lookup table with the English names.\n\n# Equivalence table\nsectors &lt;- read_excel(\n    \"data/sam/classifications.xlsx\",\n    sheet = \"SAM-REV2\",\n    col_names = T,\n    col_types = \"text\",\n  )\n\nWe also have an Excel file with changes to labor productivity due to climate variability, by sector. Also, we have livestock productivity changes.\n\nlabor_productivity &lt;-\n  read.csv(\n    \"data/climate_productivity/GEO_labour_REF_shock_admin1_bySector.csv\")\n\nagriculture_productivity &lt;-\n  read.csv(\n    \"data/climate_productivity/GEO_agriculture_revenue_impact_GCM-Historical.csv\"\n  )\n\nlivestock_productivity &lt;-\n  read.csv(\n    \"data/climate_productivity/GEO_livestock_REF_shock_admin1_high_prop_holstein.csv\"\n  )\n\nAnd finally, direct effects on consumption of Macro scenarios.\n\n# HH Consumption Macro Effect\nhh_consumption_effects &lt;- read_excel(\n    \"data/sam/MacroconsumptionEffect_HH_GEO.xlsx\",\n    sheet = \"HH_consumption_value\",\n    col_names = F,\n    range = \"A90:AD119\"\n  )\n\nNew names:\nâ¢ `` -&gt; `...1`\nâ¢ `` -&gt; `...2`\nâ¢ `` -&gt; `...3`\nâ¢ `` -&gt; `...4`\nâ¢ `` -&gt; `...5`\nâ¢ `` -&gt; `...6`\nâ¢ `` -&gt; `...7`\nâ¢ `` -&gt; `...8`\nâ¢ `` -&gt; `...9`\nâ¢ `` -&gt; `...10`\nâ¢ `` -&gt; `...11`\nâ¢ `` -&gt; `...12`\nâ¢ `` -&gt; `...13`\nâ¢ `` -&gt; `...14`\nâ¢ `` -&gt; `...15`\nâ¢ `` -&gt; `...16`\nâ¢ `` -&gt; `...17`\nâ¢ `` -&gt; `...18`\nâ¢ `` -&gt; `...19`\nâ¢ `` -&gt; `...20`\nâ¢ `` -&gt; `...21`\nâ¢ `` -&gt; `...22`\nâ¢ `` -&gt; `...23`\nâ¢ `` -&gt; `...24`\nâ¢ `` -&gt; `...25`\nâ¢ `` -&gt; `...26`\nâ¢ `` -&gt; `...27`\nâ¢ `` -&gt; `...28`\nâ¢ `` -&gt; `...29`\nâ¢ `` -&gt; `...30`\n\nnames(hh_consumption_effects) &lt;- c(\"scenario_id\", \"hh_type\",c(2023:2050))\nhh_consumption_effects &lt;- hh_consumption_effects |&gt; \n  mutate(\n    scenario_id = case_when(\n      scenario_id == \"ccdr_all_dry_hot\" ~ \"dryhot\",\n      scenario_id == \"ccdr_all_wet_warm\" ~ \"wetwarm\",\n      scenario_id == \"ccdr_NZS_10_10\" ~ \"nzs\",\n      .default = scenario_id\n    )) |&gt; \n  select(-3)",
    "crumbs": [
      "Home",
      "Supporting materials",
      "Georgia CCDR Microsimulation"
    ]
  },
  {
    "objectID": "supporting-materials/geo-microsimulation.html#skill-level",
    "href": "supporting-materials/geo-microsimulation.html#skill-level",
    "title": "Georgia CCDR Microsimulation",
    "section": "2.1 Skill level",
    "text": "2.1 Skill level\nFor skill level, we will use information on schooling from pp$Education (TblShinda02), which has the following levels:\n\nIlliterate\nDo not have primary education but can read and write\nPre-primary education\nPrimary education\nLower secondary education\nUpper secondary education\nVocational education without secondary general education\nVocational education on the base of lower secondary education with secondary general education certificate\nVocational education on the base of secondary general education (except higher professional education)\nHigher professional program\nBachelor or equivalent\nMaster or equivalent\nDoctor or equivalent\n\nWe need three skill levels for our SAM template, so we map these levels to:\nLow skill (1 - 5): Illiterate through lower secondary. Medium skill (6 - 9): Upper secondary through vocational education. High skill (10 - 13): Higher professional program through Doctor.\n\npp_factor_descriptors &lt;- pp |&gt;\n  select(UID, MemberNo, Gender, Age, Education) |&gt; \n  mutate(\n    MemberId = \n      paste0(sprintf(\"%06d\", UID), sprintf(\"%02d\", MemberNo))) |&gt;\n  mutate(Gender = factor(\n    Gender,\n    levels = c(1, 2),\n    labels = c(\"Female\", \"Male\")\n  )) |&gt; \n  mutate(\n    SkillLevel = case_when(\n      Education &gt;= 0 & Education &lt;= 5 ~ 1,\n      Education &gt; 5 & Education &lt;= 9 ~ 2,\n      Education &gt; 9 & Education &lt;= 13 ~ 3,\n      TRUE ~ NA ) ) |&gt; \n  mutate(\n    SkillLevel = factor(\n      SkillLevel, \n      levels = c( 1, 2, 3),\n      labels = c( \"Low Skill\", \"Medium Skill\", \"High Skill\"))\n  )\n\nNow that we have skill levels, we need to add information on urban/rural (from hh_basics) and quintile (from ind_poverty), and type of income earner (from pp_labor).\n\nurb_rur &lt;- hh_basics |&gt; \n  select(UID,QuartNo, UrbanOrRural, RegNo, Weights) |&gt; \n  mutate(\n    UrbanOrRural = factor(\n      UrbanOrRural,\n      levels = c(2,1),\n      labels = c(\"Rural\", \"Urban\")\n    )\n  )\n\nquintiles &lt;- poverty |&gt; \n  select(UID, quintilc, decilc, hhsize) |&gt; \n  rename(\n    Quintile = quintilc,\n    Decile = decilc) |&gt; \n  mutate(\n    Quintile = factor(\n      Quintile,\n      levels = c(1:5),\n      labels = c(\"Q1\", \"Q2\", \"Q3\", \"Q4\", \"Q5\")\n    ),\n    Decile = factor(\n      Decile,\n      levels = c(1:10),\n      labels = c(\n        \"D01\", \"D02\", \"D03\", \"D04\", \"D05\",\n        \"D06\", \"D07\", \"D08\", \"D09\", \"D10\")\n  ))\n\nis_employed &lt;- ind_poverty |&gt; \n  mutate(\n    MemberId = \n      paste0(sprintf(\"%06d\", UID), sprintf(\"%02d\", MemberNo))) |&gt; \n    mutate(\n      employed = case_when(\n        empl == 1 ~ T,\n        empl == 0 ~ F,\n        .default = NA\n      )\n    ) |&gt; \n    select(\n      MemberId, employed\n    )\n\npp_lmarket0 &lt;- pp_labor |&gt; \n  mutate(\n    MemberId = \n      paste0(sprintf(\"%06d\", UID), sprintf(\"%02d\", MemberNo))) |&gt; \n  select(-c(UID,MemberNo))\n\npp_lmarket1 &lt;- pp_factor_descriptors |&gt; \n  left_join(urb_rur, join_by(UID)) |&gt; \n  left_join(quintiles, join_by(UID)) |&gt; \n  left_join(pp_lmarket0, join_by(MemberId)) |&gt; \n  relocate(c(UID, MemberNo, MemberId, QuartNo), .before = 1)",
    "crumbs": [
      "Home",
      "Supporting materials",
      "Georgia CCDR Microsimulation"
    ]
  },
  {
    "objectID": "supporting-materials/geo-microsimulation.html#labor-status-and-economic-activities",
    "href": "supporting-materials/geo-microsimulation.html#labor-status-and-economic-activities",
    "title": "Georgia CCDR Microsimulation",
    "section": "2.2 Labor status and Economic Activities",
    "text": "2.2 Labor status and Economic Activities\nWe work with labor status from Shinda05_1. Since, upon import NACE 2 codes are converted to numbers, we need to convert them back to text, so that we can keep zeros to the left for proper order. We then extract the first two digits and find the correspondence to Rev.Â 2 from the SAM using the look-up table sam_activities. For proper order, we convert the SAM activities columns for job 1 and job 2 to factor, using the order from the dataset sam_factors.\n\npp_microsim01 &lt;- pp_lmarket1 |&gt; \n  mutate(\n    MemberId = \n      paste0(sprintf(\"%06d\", UID), sprintf(\"%02d\", MemberNo))) |&gt;\n  mutate(\n    # Job 1 NACE Rev 2 code. \n    Q5  = if_else(!is.na(Q5),paste0(sprintf(\"%04d\", Q5)), NA),\n    # Job 2 NACE Rev 2 code.\n    Q12 = if_else(!is.na(Q12),paste0(sprintf(\"%04d\", Q12)), NA)) |&gt; \n  mutate(\n    job1 = if_else(!is.na(Q5),substr(Q5, 1, 2), NA),\n    job2 = if_else(!is.na(Q12),substr(Q12, 1, 2), NA)\n  ) |&gt; \n  # Is employed?\n  left_join(\n    is_employed,\n    join_by(MemberId)\n  ) |&gt; \n  # We match to Rev 2 and SAM classifications (for job 1 and job 2)\n  left_join(\n    sam_activities[,c(1,5)], \n    join_by(job1 == rev2_2d)) |&gt; \n  left_join(\n    sam_activities[,c(1,5)],\n    join_by(job2 == rev2_2d),\n    suffix = \n      c(\"_job1\", \"_job2\")) |&gt; \n  # And convert to factors for proper order\n  mutate(\n    SAM3_job1 = factor(\n      SAM3_job1, \n      levels = c(1:3),\n      labels = c(\"Agriculture\", \"Manufactures\", \"Services\")\n      ),\n    SAM3_job2 = factor(\n      SAM3_job2, \n      levels = c(1:3),\n      labels = c(\"Agriculture\", \"Manufactures\", \"Services\")\n      )\n  )",
    "crumbs": [
      "Home",
      "Supporting materials",
      "Georgia CCDR Microsimulation"
    ]
  },
  {
    "objectID": "supporting-materials/geo-microsimulation.html#types-of-income",
    "href": "supporting-materials/geo-microsimulation.html#types-of-income",
    "title": "Georgia CCDR Microsimulation",
    "section": "2.3 Types of income",
    "text": "2.3 Types of income\nBefore making our multi-dimensional tables, we need to identify different types of income. f-lab (wages) and f-surp (capital income). The instruction is that f-surp needs to be split into wages to entrepreneurs/self employed and capital income.\n\npp_microsim02 &lt;- pp_microsim01 |&gt; \n  mutate(\n    # We add accross three months for each source (and coalesce the NAs to 0)\n    labor_income_job1 = \n      rowSums(\n        across(starts_with(\"Q8_faqti_\"), \\(x) coalesce(x, 0))),\n    labor_income_job2 = \n      rowSums(\n        across(starts_with(\"Q14_faqti_\"), \\(x) coalesce(x, 0))),\n    surplus_income = \n      rowSums(\n        across(starts_with(\"Q10_faqti_\"), \\(x) coalesce(x, 0)))\n  ) |&gt; \n  # We also add factor labels to Employment Status\n  mutate(\n    lstatus1 = factor(\n      Q7,\n      levels = c(1:6),\n      labels = c(\n        \"Employee\", \"Employer\", \"Own Account (Non-Ag.)\", \n        \"Own Account (Ag.)\", \"Unpaid Worker\", \"Other\"))\n    ) |&gt; \n  mutate(\n    lstatus2 = factor(\n      Q13,\n      levels = c(1:6),\n      labels = c(\n        \"Employee\", \"Employer\", \"Own Account (Non-Ag.)\", \n        \"Own Account (Ag.)\", \"Unpaid Worker\", \"Other\"))\n    )",
    "crumbs": [
      "Home",
      "Supporting materials",
      "Georgia CCDR Microsimulation"
    ]
  },
  {
    "objectID": "supporting-materials/geo-microsimulation.html#missing-and-outliers",
    "href": "supporting-materials/geo-microsimulation.html#missing-and-outliers",
    "title": "Georgia CCDR Microsimulation",
    "section": "2.4 Missing and outliers",
    "text": "2.4 Missing and outliers\nIn this section we will assign a labor income for job1 holders with !lstatus1 %in% c(2,5) & labor_income_job1 == 0 based on predicted income from everyone else who doesnât meet the condition. We will estimate annual_labor_total after predictions.\nLooking at the data we see that only those that report being an employee or âotherâ report having labor income 1 or 2; Employer and Own Account non-ag report having surplus; and own account ag and (of course) unpaid worker\nWe first identify who needs predictions for job1, job2, and surplus. We default to NA because we want to preserve the logic of those who donât have an income, because they arenât supposed to have one. However, this introduces an uncertainty element when predicting further down the line, because subsetting does not allow NAâs. Even if we want to match just TRUEs. So itâs a double-edged sword. The fix was using which() to find row numbers of those with TRUE.\n\npp_microsim03 &lt;- pp_microsim02 |&gt; \n  mutate(\n    fix_job1 = case_when(\n      (!is.na(Q7) & Q7 %in% c(2,3,4,5)) ~ F,\n      (!is.na(Q7) & Q7 %in% c(1,6) & labor_income_job1 &gt;  0) ~ F,\n      (!is.na(Q7) & Q7 %in% c(1,6) & labor_income_job1 == 0) ~ T,\n      .default = NA\n    ),\n    fix_job2 = case_when(\n      (!is.na(Q13) & Q13 %in% c(2,3,4,5)) ~ F,\n      (!is.na(Q13) & Q13 %in% c(1,6) & labor_income_job2 &gt;  0) ~ F,\n      (!is.na(Q13) & Q13 %in% c(1,6) & labor_income_job2 == 0) ~ T,\n      .default = NA\n    ),\n    fix_surplus = case_when(\n      (!is.na(Q7) & Q7 %in% c(1,4,5,6)) ~ F,\n      (!is.na(Q7) & Q7 %in% c(2,3) & surplus_income &gt;  0) ~ F,\n      (!is.na(Q7) & Q7 %in% c(2,3) & surplus_income == 0) ~ T,\n      .default = NA\n    ))\n\nOutliers and need to predict.\n\npp_microsim04 &lt;- pp_microsim03 |&gt; \n  mutate(\n    sd_job1    = sd(labor_income_job1, na.rm = T),\n    sd_job2    = sd(labor_income_job2, na.rm = T),\n    sd_surplus = sd(surplus_income   , na.rm = T),\n    d_job1 = labor_income_job1 / sd_job1,\n    d_job2 = labor_income_job2 / sd_job2,\n    d_job1 = surplus_income / sd_surplus,\n  )\n\nAssign sector to missings.\n\npp_microsim05 &lt;- pp_microsim04 |&gt;\n  group_by(UID) |&gt;\n  mutate(\n    # Create a temporary variable 'other_sector' as a factor\n    other_sector_job1 = case_when(\n      !is.na(Q7) & !is.na(SAM3_job1) & SAM3_job1 %in% levels(SAM3_job1) ~ SAM3_job1,\n      TRUE ~ NA_character_ # Keep as character NA for now\n    )\n  ) |&gt;\n  fill(other_sector_job1, .direction = \"downup\") |&gt;\n  mutate(\n    other_sector_job1 = if_else(is.na(Q7), NA_character_, other_sector_job1)\n  ) |&gt;\n  mutate(\n    # Impute missing 'sector' values based on 'other_sector'\n    SAM3_job1 = as.factor(if_else(\n      !is.na(Q7),\n      as.character(coalesce(as.character(SAM3_job1), other_sector_job1)),\n      as.character(SAM3_job1)\n    )),\n    SAM3_job2 = as.factor(if_else(\n      !is.na(Q13),\n      as.character(coalesce(as.character(SAM3_job2), other_sector_job1)),\n      as.character(SAM3_job2)\n    )),\n    # Re-establish levels and labels\n    SAM3_job1 = factor(SAM3_job1, levels = c(\"Agriculture\", \"Manufactures\", \"Services\")),\n    SAM3_job2 = factor(SAM3_job2, levels = c(\"Agriculture\", \"Manufactures\", \"Services\"))\n  ) |&gt;\n  ungroup()",
    "crumbs": [
      "Home",
      "Supporting materials",
      "Georgia CCDR Microsimulation"
    ]
  },
  {
    "objectID": "supporting-materials/geo-microsimulation.html#the-income-simulation-regression",
    "href": "supporting-materials/geo-microsimulation.html#the-income-simulation-regression",
    "title": "Georgia CCDR Microsimulation",
    "section": "2.5 The income simulation regression",
    "text": "2.5 The income simulation regression\nSince labor income was a key variable, which we needed to match with the future wage bill by economic activity, we first checked for missing values among employed individuals. We found that almost a third of respondents (28.6%) did not report income for either their primary or secondary job. To overcome this limitation, we used the available information from the remaining respondents to estimate an extended Mincer equation, as shown in EquationÂ 1, and implemented in ListingÂ 1. For the respondents with available information, we also identified outliers as those outside of five standard deviations from the mean labor income.\n\\[\n\\begin{equation}\n\\begin{split}\n\\ln(lab_i) = \\\\ \\beta_0 + \\beta_1 \\text{age}_i + \\\\\n\\beta_2 \\text{gender}_i + \\beta_3 \\text{education}_i + \\\\\n\\beta_4 \\text{age}^2_i + \\beta_5 \\text{marz}_i + \\\\\n\\beta_6 \\text{sector}_i + \\epsilon_i\n\\end{split}\n\\end{equation}\n\\tag{1}\\]\nWhere:\n\n\\(\\ln(lab_i)\\) is the natural logarithm of labor income for individual \\(i\\).\n\\(\\beta_0\\) is the intercept term.\n\\(\\beta_1, \\beta_2, \\beta_3, \\beta_4, \\beta_5, \\beta_6\\) are the coefficients for the respective independent variables.\n\\(\\text{age}_i\\) is the age of individual \\(i\\).\n\\(\\text{gender}_i\\) is a binary variable indicating the gender of individual \\(i\\) (1 for female, 2 for male).\n\\(\\text{education}_i\\) represents the level of education for individual \\(i\\) (ordered: 1) None to General, 2) Secondary to Vocational, 3) Higher education).\n\\(\\text{age}^2_i\\) is the square of the age of individual \\(i\\), included to capture non-linear effects of age on labor income.\n\\(\\text{marz}_i\\) represents the region where individual \\(i\\) resides.\n\\(\\text{sector}_i\\) represents the sector of employment for individual \\(i\\) (i.e., agriculture, manufacturing or services).\n\\(\\epsilon_i\\) is the error term for individual \\(i\\).\n\nWe first prepare our variables for the regression.\n\npp_microsim06 &lt;- pp_microsim05 |&gt;\n  rename(\n    education = Education,\n    age = Age,\n    gender = Gender,\n    region = RegNo) |&gt; \n  mutate(\n    education2 = education^2,\n    age2 = age^2,\n    male = case_when(\n      gender == 1 ~ 1,\n      gender == 2 ~ 0\n    ),\n    ln_lab1 = if_else(\n      !is.na(labor_income_job1) & labor_income_job1 != 0,\n      log(labor_income_job1),\n      NA),\n    ln_lab2 = if_else(\n      !is.na(labor_income_job2) & labor_income_job2 != 0,\n      log(labor_income_job2),\n      NA),\n    ln_surplus = if_else(\n      !is.na(surplus_income) & surplus_income != 0,\n      log(surplus_income),\n      NA),\n    sim_job1 = NA_real_,\n    sim_job2 = NA_real_,\n    sim_surplus = NA_real_\n  )|&gt;\n  # Labor Market Status \n  mutate(\n    lmarket = case_when(\n      !is.na(Q7) ~ as.numeric(SAM3_job1),\n      is.na(Q7) & age &gt;= 15 ~ 4, # Unemployed\n      is.na(Q7) & age &lt; 15 ~ 5,  # OLF\n      .default = NA_integer_\n  )\n)\n\nFilter the data for regression conditions.\n\nregression_data_job1 &lt;- pp_microsim06 |&gt;\n  filter(Q7 %in% c(1,6) & fix_job1 == F)\n\nregression_data_job2 &lt;- pp_microsim06 |&gt; \n  filter(Q13 %in% c(1,6) & fix_job2 == F)\n\nregression_data_surplus &lt;- pp_microsim06 |&gt; \n  filter(Q7 %in% c(2,3) & fix_surplus == F)\n\nRegression model.\n\n\n\n\nListingÂ 1: Income regression model\n\n\nmodel_job1 &lt;- lm(\n  ln_lab1 ~ \n    age + gender + education + \n    age2 + region + SAM3_job1,\n    data = regression_data_job1)\n\nmodel_job2 &lt;- lm(\n  ln_lab2 ~ \n    age + gender + education + \n    age2 + region + SAM3_job2,\n    data = regression_data_job2)\n\nmodel_surplus &lt;- lm(\n  ln_surplus ~ \n    age + gender + education + \n    age2 + region + SAM3_job1,\n    data = regression_data_surplus)\n\n\n\n\nApplying predictions to those who need it.\nNote: The âpredictâ function in R does not directly support conditions within the function call, so we handle this by filtering or subsetting the data as needed.\nNote: âtype = âresponseââ might be needed depending on model type.\n\n# rows to predict (this removes uncertainty NAs for predictions)\ntarget_rows_job1    &lt;- which(pp_microsim06$fix_job1    == TRUE)\ntarget_rows_job2    &lt;- which(pp_microsim06$fix_job2    == TRUE)\ntarget_rows_surplus &lt;- which(pp_microsim06$fix_surplus == TRUE)\n\n# predictions\npp_microsim06$sim_job1[target_rows_job1] &lt;- exp(\n  predict(\n    model_job1, \n    pp_microsim06[target_rows_job1, ], \n    type = \"response\")\n)\n\npp_microsim06$sim_job2[target_rows_job2] &lt;- exp(\n  predict(\n    model_job1, \n    pp_microsim06[target_rows_job2, ], \n    type = \"response\")\n)\n\npp_microsim06$sim_surplus[target_rows_surplus] &lt;- exp(\n  predict(\n    model_job1, \n    pp_microsim06[target_rows_surplus, ], \n    type = \"response\")\n)\n\nAt this point, if there were negative predictions, we would have to make them zero. There are none such cases in this exercise.\nAnd now, we replace simulated income for those who lack one.\n\npp_microsim07 &lt;- pp_microsim06 |&gt; \n  mutate(\n    labor_income_job1 = if_else(\n      fix_job1 == T,\n      sim_job1,\n      labor_income_job1\n    ),\n    labor_income_job2 = if_else(\n      fix_job2 == T,\n      sim_job2,\n      labor_income_job2\n    ),\n    surplus_income = if_else(\n      fix_surplus == T,\n      sim_surplus,\n      surplus_income\n    )\n  )\n\nFinally, we estimate total labor income.\n\npp_microsim08 &lt;- pp_microsim07 |&gt; \n  mutate(\n    # Annual income\n    annual_labor_income_job1 = labor_income_job1 * 4,\n    annual_labor_income_job2 = labor_income_job2 * 4,\n    annual_surplus_income = surplus_income * 4,\n    # Monthly income\n    monthly_labor_income_job1 = labor_income_job1 / 3,\n    monthly_labor_income_job2 = labor_income_job2 / 3,\n    monthly_surplus_income = surplus_income / 3\n  ) |&gt;\n  mutate(\n    # Annual labor income in GEL\n    annual_labor_total = if_else(\n      Q7 %in% c(1,2,3,6) | Q13 %in% c(1,2,3,6),\n      (coalesce(\n        annual_labor_income_job1, 0) +\n       coalesce(\n        annual_labor_income_job2, 0) +\n        coalesce(\n        annual_surplus_income, 0)\n      ),\n      NA_real_\n    ),\n    # Monthly labor income in GEL\n    monthly_labor_total = if_else(\n      Q7 %in% c(1,2,3,6) | Q13 %in% c(1,2,3,6),\n      (coalesce(\n        monthly_labor_income_job1, 0) +\n       coalesce(\n        monthly_labor_income_job2, 0) +\n        coalesce(\n        monthly_surplus_income, 0)\n      ),\n      NA_real_\n    ))\n\n\n2.5.1 Total income and shares\nTotal labor income at HH level.\n\npp_microsim09 &lt;- pp_microsim08 |&gt;\n  group_by(UID) |&gt;\n  mutate(\n    hh_annual_labor_total  = sum(annual_labor_total,  na.rm = T),\n    hh_monthly_labor_total = sum(monthly_labor_total, na.rm = T)\n    ) |&gt;\n  ungroup()",
    "crumbs": [
      "Home",
      "Supporting materials",
      "Georgia CCDR Microsimulation"
    ]
  },
  {
    "objectID": "supporting-materials/geo-microsimulation.html#aggregation-of-population-data",
    "href": "supporting-materials/geo-microsimulation.html#aggregation-of-population-data",
    "title": "Georgia CCDR Microsimulation",
    "section": "5.1 Aggregation of population data",
    "text": "5.1 Aggregation of population data\nThis is based on a custom command to reweight the survey according to macroeconomic data for every possible combination of variant, year, and country. In the macro data we know they only used the âmediumâ variant and we only need to reweight for two specific years for Georgia (GEO), so we will conduct the reweighting directly with these parameters.\nWe join several cohorts from 0 to 29 years old and from 60 onwards, because the reweighting procedure works best if each category is at least 5% of the population. The solution here works best for Georgia.\n\npopulation_projections &lt;- population_projections |&gt;\n  # filter(Variant == \"Medium\") |&gt;\n  # Recoding cohorts into ordered factors\n    mutate(\n      cohort_short = factor(\n        case_when(\n          cohort %in% \n            c(\"P0004\", \"P0509\",\"P1014\",\n              \"P1519\",\"P2024\", \"P2529\") ~ \"P0029\",\n          cohort %in% \n            c(\"P3034\", \"P3539\") ~ \"P3039\",\n          cohort %in% \n            c(\"P4044\", \"P4549\") ~ \"P4049\",\n          cohort %in% \n            c(\"P5054\", \"P5559\") ~ \"P5059\",\n          cohort %in% \n            c(\"P6064\", \"P6569\",\"P7074\", \"P7579\",\n              \"P8084\", \"P8589\", \"P9094\", \"P9599\",\n              \"P100up\") ~ \"P60up\"), \n        levels = \n          c(\"P0029\", \"P3039\", \"P4049\",\n            \"P5059\", \"P60up\"))) |&gt;\n  # Get also factor 'cohort' to numeric codes\n  mutate(cohort_code = as.integer(cohort_short))\n\nLetâs now create cohorts in our pp_microsim data to match our population projection data.\n\n# Convert 'age' into 'cohort' factor with levels ordered as specified\npp_microsim10 &lt;- pp_microsim09 |&gt;\n    mutate(cohort = factor(case_when(\n    age &gt;= 0  & age &lt;= 29 ~ \"P0029\",\n    age &gt;= 30 & age &lt;= 39 ~ \"P3039\",\n    age &gt;= 40 & age &lt;= 49 ~ \"P4049\",\n    age &gt;= 50 & age &lt;= 59 ~ \"P5059\",\n    age &gt;= 60  ~ \"P60up\"\n  ), levels = c(\"P0029\", \"P3039\", \"P4049\", \"P5059\", \"P60up\")))\n\n# Convert the 'cohort' and 'gender' factor to numeric codes\npp_microsim11 &lt;- pp_microsim10  |&gt; \n  mutate(cohort_code = as.integer(cohort))  |&gt;  \n  mutate(gender_code = as.integer(gender)) |&gt; \n  mutate(weight = Weights / 4)\n\n# rm(list = ls(pattern = \"^pp_microsim[0-9]+$\"))\n\nWe also need demographic targets for 2030 and 2050\n\n# Ensure pop_targets_2030 is correctly prepared\n# We use the \"Medium\" variant = variants[7]\npop_targets_2030 &lt;- population_projections  |&gt; \n  filter(year == 2030, Variant == variants[7])  |&gt; \n  group_by(cohort_code, cohort_short) |&gt; \n    summarize(female = sum(yf),\n              male   = sum(ym), \n              total = sum(total_population),\n              ) |&gt;\n  ungroup()\n\npop_targets_2050 &lt;- population_projections  |&gt; \n  filter(year == 2050, Variant == variants[7])  |&gt; \n  group_by(cohort_code, cohort_short) |&gt; \n    summarize(female = sum(yf),\n              male   = sum(ym), \n              total = sum(total_population),\n              ) |&gt;\n  ungroup()\n\npop_total_2030 &lt;- sum(pop_targets_2030$total)\npop_total_2050 &lt;- sum(pop_targets_2050$total)\n\npop_targets_2030 &lt;- pop_targets_2030 |&gt; \n  mutate(pct_total = total / pop_total_2030)\npop_targets_2050 &lt;- pop_targets_2050 |&gt; \n  mutate(pct_total = total / pop_total_2050)\n\n#writeClipboard(pop_targets_2030)\n# write.table(pop_targets_2030, \"clipboard\", sep=\"\\t\", row.names=FALSE)\n\nWe add economic targets from lmarket, by combining totals from the survey and growth rates by share from the macro file so that shares do not have wild changes (since the shares of lmarket are so different between the macro file and the actual survey). We do this so that labor income doesnât change in a completely radical way.\n\n# Survey baseline (e.g. 2023) weighted totals by labor market group\nsurvey_lmarket_base &lt;- pp_microsim11 |&gt;\n  group_by(lmarket) |&gt;\n  summarize(survey_total = sum(weight, na.rm = TRUE)) |&gt;\n  arrange(lmarket)  # Make sure it's in order 1 to 5\n\nsurvey_totals &lt;- survey_lmarket_base$survey_total  # length 5\n\n# Get the macro growth rates and apply them:\nlmarket_targets &lt;- macro_data |&gt;\n  filter(year %in% analysis_years, scenario_id %in% scenarios, Variant == variants[7]) |&gt;\n  select(scenario_id, year, starts_with(\"lmarket_\")) |&gt;\n  # Select only *_growth columns\n  select(scenario_id, year, matches(\"lmarket_\\\\d+_growth\")) |&gt;\n  arrange(scenario_id, year) |&gt;\n  rowwise() |&gt;\n  mutate(\n    # Apply growth rate to survey baseline\n    l1 = survey_totals[1] * lmarket_1_growth,\n    l2 = survey_totals[2] * lmarket_2_growth,\n    l3 = survey_totals[3] * lmarket_3_growth,\n    l4 = survey_totals[4] * lmarket_4_growth,\n    l5 = survey_totals[5] * lmarket_5_growth\n  ) |&gt;\n  mutate(\n    total = l1 + l2 + l3 + l4 + l5,\n    target_lmarket_1 = l1 / total,\n    target_lmarket_2 = l2 / total,\n    target_lmarket_3 = l3 / total,\n    target_lmarket_4 = l4 / total,\n    target_lmarket_5 = l5 / total\n  ) |&gt;\n  select(scenario_id, year, starts_with(\"target_lmarket\")) |&gt;\n  ungroup()",
    "crumbs": [
      "Home",
      "Supporting materials",
      "Georgia CCDR Microsimulation"
    ]
  },
  {
    "objectID": "supporting-materials/geo-microsimulation.html#reweigting",
    "href": "supporting-materials/geo-microsimulation.html#reweigting",
    "title": "Georgia CCDR Microsimulation",
    "section": "5.2 Reweigting",
    "text": "5.2 Reweigting\nWe use anesrake to calculate targets from known future proportions of sex, age, economic sector. We first create a target list.\n\n# Create a list to store targets for each scenario and year\nall_targets &lt;- list()\n\nfor (sc in scenarios) {\n  for (yr in analysis_years) {\n    \n    # 1. Get population targets\n    pop_targets &lt;- population_projections |&gt;\n      filter(year == yr, Variant == \"Medium\") |&gt;\n      group_by(cohort_code, cohort_short) |&gt;\n      summarize(female = sum(yf),\n                male   = sum(ym),\n                total  = sum(total_population),\n                .groups = \"drop\") |&gt;\n      mutate(pct_total = total / sum(total))\n    \n    gender_code &lt;- c(\n      sum(pop_targets$female) / sum(pop_targets$total),\n      sum(pop_targets$male)   / sum(pop_targets$total)\n    )\n    \n    cohort_code &lt;- pop_targets$pct_total\n\n    # 2. Get labor market targets from the newly computed table\n    lmarket_code &lt;- lmarket_targets |&gt;\n      filter(scenario_id == sc, year == yr) |&gt;\n      select(starts_with(\"target_lmarket\")) |&gt;\n      unlist(use.names = FALSE)\n\n    # 3. Store targets in named list\n    targets &lt;- list(\n      gender_code = gender_code,\n      cohort_code = cohort_code,\n      lmarket = lmarket_code\n    )\n    names(targets) &lt;- c(\"gender_code\", \"cohort_code\", \"lmarket\")\n\n    # 4. Save using naming convention \"name_year_scenario\"\n    key &lt;- paste0(\"targets_\", yr, \"_\", sc)\n    all_targets[[key]] &lt;- targets\n  }\n}\n\nAnd now we perform the reweighting, using the original weights. Initially we had used the default option type = âpctlimâ combined with pctlim=0.05, because the method recommends that if reweighting changes for one variable according to its target are not of at least 5%, then itâs not worth burdening the procedure with it. It then ignored sex as a reweighting variable, leaving a small percentage difference between the target and the final population. However, we then tried removing this limitation and the procedure reached convergence in 40 and 49 iterations very efficiently for 2030 and 2050, respectively.\nThis has now been put into a for loop to facilitate multiple scenarios. See the original Armenia code for a simpler âby handâ version.\n\nrakedata_base &lt;- as.data.frame(pp_microsim11)\noriginal_weight_sum &lt;- sum(rakedata_base$weight)\n\nfor (key in names(all_targets)) {\n  \n  parts &lt;- strsplit(key, \"_\")[[1]]\n  yr &lt;- parts[2]\n  sc &lt;- parts[3]\n  \n  targets &lt;- all_targets[[key]]\n  \n  cat(\"ð Raking:\", yr, sc, \"\\n\")\n  \n  outsave &lt;- anesrake::anesrake(\n    targets,            # &lt;- positional\n    rakedata_base,      # &lt;- positional\n    caseid       = rakedata_base$MemberId,\n    choosemethod = \"total\",\n    type         = \"nolim\",\n    nlim         = 3,\n    iterate      = TRUE,\n    force1       = TRUE,\n    verbose      = TRUE\n  )\n  \n  weight_name &lt;- paste0(\"weight_\", yr, \"_\", sc)\n  new_weight &lt;- unlist(outsave[[1]])\n  rakedata_base[[weight_name]] &lt;- new_weight\n  \n  scaling_factor &lt;- pop_data$total_population[pop_data$year == as.integer(yr)] /\n                    pop_data$total_population[pop_data$year == 2023]\n  target_sum &lt;- original_weight_sum * scaling_factor\n  new_sum &lt;- sum(new_weight)\n  rakedata_base[[weight_name]] &lt;- rakedata_base[[weight_name]] * (target_sum / new_sum)\n  \n  cat(\"â Finished:\", weight_name, \n      \"| Rescaled sum =\", round(sum(rakedata_base[[weight_name]])), \"\\n\\n\")\n}\n\nð Raking: 2030 baseline \n\n\n[1] \"Raking...Iteration 1\"\n[1] \"Current iteration changed total weights by 10198.6236928413\"\n[1] \"Raking...Iteration 2\"\n[1] \"Current iteration changed total weights by 1127.83410643334\"\n[1] \"Raking...Iteration 3\"\n[1] \"Current iteration changed total weights by 105.331275545111\"\n[1] \"Raking...Iteration 4\"\n[1] \"Current iteration changed total weights by 29.3179762115329\"\n[1] \"Raking...Iteration 5\"\n[1] \"Current iteration changed total weights by 12.5350597845507\"\n[1] \"Raking...Iteration 6\"\n[1] \"Current iteration changed total weights by 5.33204611403515\"\n[1] \"Raking...Iteration 7\"\n[1] \"Current iteration changed total weights by 2.2627503653339\"\n[1] \"Raking...Iteration 8\"\n[1] \"Current iteration changed total weights by 0.959752781272666\"\n[1] \"Raking...Iteration 9\"\n[1] \"Current iteration changed total weights by 0.407028549556432\"\n[1] \"Raking...Iteration 10\"\n[1] \"Current iteration changed total weights by 0.172612144088801\"\n[1] \"Raking...Iteration 11\"\n[1] \"Current iteration changed total weights by 0.0731998955294041\"\n[1] \"Raking...Iteration 12\"\n[1] \"Current iteration changed total weights by 0.0310417747231533\"\n[1] \"Raking...Iteration 13\"\n[1] \"Current iteration changed total weights by 0.0131638022302782\"\n[1] \"Raking...Iteration 14\"\n[1] \"Current iteration changed total weights by 0.0055823314047645\"\n[1] \"Raking...Iteration 15\"\n[1] \"Current iteration changed total weights by 0.00236728013479159\"\n[1] \"Raking...Iteration 16\"\n[1] \"Current iteration changed total weights by 0.0010038841452325\"\n[1] \"Raking...Iteration 17\"\n[1] \"Current iteration changed total weights by 0.000425713568770913\"\n[1] \"Raking...Iteration 18\"\n[1] \"Current iteration changed total weights by 0.000180530832390724\"\n[1] \"Raking...Iteration 19\"\n[1] \"Current iteration changed total weights by 7.65570571219509e-05\"\n[1] \"Raking...Iteration 20\"\n[1] \"Current iteration changed total weights by 3.24652799320035e-05\"\n[1] \"Raking...Iteration 21\"\n[1] \"Current iteration changed total weights by 1.37674364605322e-05\"\n[1] \"Raking...Iteration 22\"\n[1] \"Current iteration changed total weights by 5.8383036555254e-06\"\n[1] \"Raking...Iteration 23\"\n[1] \"Current iteration changed total weights by 2.47582724105522e-06\"\n[1] \"Raking...Iteration 24\"\n[1] \"Current iteration changed total weights by 1.04992399557746e-06\"\n[1] \"Raking...Iteration 25\"\n[1] \"Current iteration changed total weights by 4.45227162360062e-07\"\n[1] \"Raking...Iteration 26\"\n[1] \"Current iteration changed total weights by 1.88805963918792e-07\"\n[1] \"Raking...Iteration 27\"\n[1] \"Current iteration changed total weights by 8.00703366388156e-08\"\n[1] \"Raking...Iteration 28\"\n[1] \"Current iteration changed total weights by 3.39568085316877e-08\"\n[1] \"Raking...Iteration 29\"\n[1] \"Current iteration changed total weights by 1.43948009623251e-08\"\n[1] \"Raking...Iteration 30\"\n[1] \"Current iteration changed total weights by 6.10741224260636e-09\"\n[1] \"Raking...Iteration 31\"\n[1] \"Current iteration changed total weights by 2.59449417505664e-09\"\n[1] \"Raking...Iteration 32\"\n[1] \"Current iteration changed total weights by 1.09781445045698e-09\"\n[1] \"Raking...Iteration 33\"\n[1] \"Current iteration changed total weights by 4.68473648762568e-10\"\n[1] \"Raking...Iteration 34\"\n[1] \"Current iteration changed total weights by 1.97515559463568e-10\"\n[1] \"Raking...Iteration 35\"\n[1] \"Current iteration changed total weights by 8.0315976092038e-11\"\n[1] \"Raking...Iteration 36\"\n[1] \"Current iteration changed total weights by 3.81766840362729e-11\"\n[1] \"Raking...Iteration 37\"\n[1] \"Current iteration changed total weights by 1.83053017188683e-11\"\n[1] \"Raking...Iteration 38\"\n[1] \"Current iteration changed total weights by 9.18620735035347e-12\"\n[1] \"Raking...Iteration 39\"\n[1] \"Current iteration changed total weights by 8.56448245656338e-12\"\n[1] \"Raking...Iteration 40\"\n[1] \"Current iteration changed total weights by 5.33656452361697e-12\"\n[1] \"Raking...Iteration 41\"\n[1] \"Current iteration changed total weights by 4.08151290542946e-12\"\n[1] \"Raking...Iteration 42\"\n[1] \"Current iteration changed total weights by 7.0867756107873e-12\"\n[1] \"Raking converged in 42 iterations\"\nâ Finished: weight_2030_baseline | Rescaled sum = 3644937 \n\nð Raking: 2050 baseline \n\n\n[1] \"Raking...Iteration 1\"\n[1] \"Current iteration changed total weights by 12166.9730452093\"\n[1] \"Raking...Iteration 2\"\n[1] \"Current iteration changed total weights by 2555.84553890228\"\n[1] \"Raking...Iteration 3\"\n[1] \"Current iteration changed total weights by 546.934305116116\"\n[1] \"Raking...Iteration 4\"\n[1] \"Current iteration changed total weights by 239.683888795916\"\n[1] \"Raking...Iteration 5\"\n[1] \"Current iteration changed total weights by 116.185080662759\"\n[1] \"Raking...Iteration 6\"\n[1] \"Current iteration changed total weights by 57.352312014411\"\n[1] \"Raking...Iteration 7\"\n[1] \"Current iteration changed total weights by 28.5093443557265\"\n[1] \"Raking...Iteration 8\"\n[1] \"Current iteration changed total weights by 14.2157644921414\"\n[1] \"Raking...Iteration 9\"\n[1] \"Current iteration changed total weights by 7.09903202907279\"\n[1] \"Raking...Iteration 10\"\n[1] \"Current iteration changed total weights by 3.54770021052674\"\n[1] \"Raking...Iteration 11\"\n[1] \"Current iteration changed total weights by 1.77359123884844\"\n[1] \"Raking...Iteration 12\"\n[1] \"Current iteration changed total weights by 0.886828209194404\"\n[1] \"Raking...Iteration 13\"\n[1] \"Current iteration changed total weights by 0.443470901140234\"\n[1] \"Raking...Iteration 14\"\n[1] \"Current iteration changed total weights by 0.221773980549075\"\n[1] \"Raking...Iteration 15\"\n[1] \"Current iteration changed total weights by 0.110908791568697\"\n[1] \"Raking...Iteration 16\"\n[1] \"Current iteration changed total weights by 0.0554659320764487\"\n[1] \"Raking...Iteration 17\"\n[1] \"Current iteration changed total weights by 0.0277388938274802\"\n[1] \"Raking...Iteration 18\"\n[1] \"Current iteration changed total weights by 0.0138724510681142\"\n[1] \"Raking...Iteration 19\"\n[1] \"Current iteration changed total weights by 0.00693773784603019\"\n[1] \"Raking...Iteration 20\"\n[1] \"Current iteration changed total weights by 0.00346962772637716\"\n[1] \"Raking...Iteration 21\"\n[1] \"Current iteration changed total weights by 0.00173519396468169\"\n[1] \"Raking...Iteration 22\"\n[1] \"Current iteration changed total weights by 0.000867787236588813\"\n[1] \"Raking...Iteration 23\"\n[1] \"Current iteration changed total weights by 0.000433988796801399\"\n[1] \"Raking...Iteration 24\"\n[1] \"Current iteration changed total weights by 0.000217042013070101\"\n[1] \"Raking...Iteration 25\"\n[1] \"Current iteration changed total weights by 0.000108544816291412\"\n[1] \"Raking...Iteration 26\"\n[1] \"Current iteration changed total weights by 5.42843211668864e-05\"\n[1] \"Raking...Iteration 27\"\n[1] \"Current iteration changed total weights by 2.71481206534641e-05\"\n[1] \"Raking...Iteration 28\"\n[1] \"Current iteration changed total weights by 1.35770390352064e-05\"\n[1] \"Raking...Iteration 29\"\n[1] \"Current iteration changed total weights by 6.79001472142504e-06\"\n[1] \"Raking...Iteration 30\"\n[1] \"Current iteration changed total weights by 3.39574284752286e-06\"\n[1] \"Raking...Iteration 31\"\n[1] \"Current iteration changed total weights by 1.69824613988068e-06\"\n[1] \"Raking...Iteration 32\"\n[1] \"Current iteration changed total weights by 8.49310797357283e-07\"\n[1] \"Raking...Iteration 33\"\n[1] \"Current iteration changed total weights by 4.24747395588732e-07\"\n[1] \"Raking...Iteration 34\"\n[1] \"Current iteration changed total weights by 2.12422497591902e-07\"\n[1] \"Raking...Iteration 35\"\n[1] \"Current iteration changed total weights by 1.06230828689213e-07\"\n[1] \"Raking...Iteration 36\"\n[1] \"Current iteration changed total weights by 5.31263021907868e-08\"\n[1] \"Raking...Iteration 37\"\n[1] \"Current iteration changed total weights by 2.65626183271195e-08\"\n[1] \"Raking...Iteration 38\"\n[1] \"Current iteration changed total weights by 1.32883724579536e-08\"\n[1] \"Raking...Iteration 39\"\n[1] \"Current iteration changed total weights by 6.64627408664131e-09\"\n[1] \"Raking...Iteration 40\"\n[1] \"Current iteration changed total weights by 3.32198396568728e-09\"\n[1] \"Raking...Iteration 41\"\n[1] \"Current iteration changed total weights by 1.67007246920647e-09\"\n[1] \"Raking...Iteration 42\"\n[1] \"Current iteration changed total weights by 8.27481083653936e-10\"\n[1] \"Raking...Iteration 43\"\n[1] \"Current iteration changed total weights by 4.15582734891728e-10\"\n[1] \"Raking...Iteration 44\"\n[1] \"Current iteration changed total weights by 2.05765682270709e-10\"\n[1] \"Raking...Iteration 45\"\n[1] \"Current iteration changed total weights by 1.08098863194073e-10\"\n[1] \"Raking...Iteration 46\"\n[1] \"Current iteration changed total weights by 4.9506343469119e-11\"\n[1] \"Raking...Iteration 47\"\n[1] \"Current iteration changed total weights by 2.49518183892405e-11\"\n[1] \"Raking...Iteration 48\"\n[1] \"Current iteration changed total weights by 1.48233647578877e-11\"\n[1] \"Raking...Iteration 49\"\n[1] \"Current iteration changed total weights by 8.99130769838052e-12\"\n[1] \"Raking...Iteration 50\"\n[1] \"Current iteration changed total weights by 4.75675054900648e-12\"\n[1] \"Raking...Iteration 51\"\n[1] \"Current iteration changed total weights by 6.77613520849718e-12\"\n[1] \"Raking converged in 51 iterations\"\nâ Finished: weight_2050_baseline | Rescaled sum = 3373040 \n\nð Raking: 2030 dryhot \n[1] \"Raking...Iteration 1\"\n[1] \"Current iteration changed total weights by 10092.8211003811\"\n[1] \"Raking...Iteration 2\"\n[1] \"Current iteration changed total weights by 1099.72500554844\"\n[1] \"Raking...Iteration 3\"\n[1] \"Current iteration changed total weights by 105.150437191272\"\n[1] \"Raking...Iteration 4\"\n[1] \"Current iteration changed total weights by 30.7588105606399\"\n[1] \"Raking...Iteration 5\"\n[1] \"Current iteration changed total weights by 13.1867775869429\"\n[1] \"Raking...Iteration 6\"\n[1] \"Current iteration changed total weights by 5.60552660645767\"\n[1] \"Raking...Iteration 7\"\n[1] \"Current iteration changed total weights by 2.37754822968345\"\n[1] \"Raking...Iteration 8\"\n[1] \"Current iteration changed total weights by 1.00792736318368\"\n[1] \"Raking...Iteration 9\"\n[1] \"Current iteration changed total weights by 0.427239750734547\"\n[1] \"Raking...Iteration 10\"\n[1] \"Current iteration changed total weights by 0.181090001126004\"\n[1] \"Raking...Iteration 11\"\n[1] \"Current iteration changed total weights by 0.0767555200720032\"\n[1] \"Raking...Iteration 12\"\n[1] \"Current iteration changed total weights by 0.032532811317818\"\n[1] \"Raking...Iteration 13\"\n[1] \"Current iteration changed total weights by 0.0137889829705943\"\n[1] \"Raking...Iteration 14\"\n[1] \"Current iteration changed total weights by 0.00584443202548873\"\n[1] \"Raking...Iteration 15\"\n[1] \"Current iteration changed total weights by 0.00247714910628599\"\n[1] \"Raking...Iteration 16\"\n[1] \"Current iteration changed total weights by 0.00104993372004497\"\n[1] \"Raking...Iteration 17\"\n[1] \"Current iteration changed total weights by 0.000445011846301357\"\n[1] \"Raking...Iteration 18\"\n[1] \"Current iteration changed total weights by 0.000188617176996309\"\n[1] \"Raking...Iteration 19\"\n[1] \"Current iteration changed total weights by 7.99449272522179e-05\"\n[1] \"Raking...Iteration 20\"\n[1] \"Current iteration changed total weights by 3.38844589555243e-05\"\n[1] \"Raking...Iteration 21\"\n[1] \"Current iteration changed total weights by 1.43618461846406e-05\"\n[1] \"Raking...Iteration 22\"\n[1] \"Current iteration changed total weights by 6.08723607264938e-06\"\n[1] \"Raking...Iteration 23\"\n[1] \"Current iteration changed total weights by 2.58005313463761e-06\"\n[1] \"Raking...Iteration 24\"\n[1] \"Current iteration changed total weights by 1.09355344457551e-06\"\n[1] \"Raking...Iteration 25\"\n[1] \"Current iteration changed total weights by 4.63499359781849e-07\"\n[1] \"Raking...Iteration 26\"\n[1] \"Current iteration changed total weights by 1.96451841016909e-07\"\n[1] \"Raking...Iteration 27\"\n[1] \"Current iteration changed total weights by 8.32673126005545e-08\"\n[1] \"Raking...Iteration 28\"\n[1] \"Current iteration changed total weights by 3.52907800205138e-08\"\n[1] \"Raking...Iteration 29\"\n[1] \"Current iteration changed total weights by 1.49575364871701e-08\"\n[1] \"Raking...Iteration 30\"\n[1] \"Current iteration changed total weights by 6.34118213493906e-09\"\n[1] \"Raking...Iteration 31\"\n[1] \"Current iteration changed total weights by 2.68501648692521e-09\"\n[1] \"Raking...Iteration 32\"\n[1] \"Current iteration changed total weights by 1.14306630827343e-09\"\n[1] \"Raking...Iteration 33\"\n[1] \"Current iteration changed total weights by 4.77524852993128e-10\"\n[1] \"Raking...Iteration 34\"\n[1] \"Current iteration changed total weights by 2.0108364973126e-10\"\n[1] \"Raking...Iteration 35\"\n[1] \"Current iteration changed total weights by 8.45125636139699e-11\"\n[1] \"Raking...Iteration 36\"\n[1] \"Current iteration changed total weights by 3.79895004343211e-11\"\n[1] \"Raking...Iteration 37\"\n[1] \"Current iteration changed total weights by 1.56520907346192e-11\"\n[1] \"Raking...Iteration 38\"\n[1] \"Current iteration changed total weights by 7.63245022739056e-12\"\n[1] \"Raking...Iteration 39\"\n[1] \"Current iteration changed total weights by 4.93360907682927e-12\"\n[1] \"Raking...Iteration 40\"\n[1] \"Current iteration changed total weights by 1.01476604896789e-11\"\n[1] \"Raking converged in 40 iterations\"\nâ Finished: weight_2030_dryhot | Rescaled sum = 3644937 \n\nð Raking: 2050 dryhot \n\n\n[1] \"Raking...Iteration 1\"\n[1] \"Current iteration changed total weights by 12106.2933773948\"\n[1] \"Raking...Iteration 2\"\n[1] \"Current iteration changed total weights by 2526.45944838028\"\n[1] \"Raking...Iteration 3\"\n[1] \"Current iteration changed total weights by 549.349401454554\"\n[1] \"Raking...Iteration 4\"\n[1] \"Current iteration changed total weights by 241.524424852756\"\n[1] \"Raking...Iteration 5\"\n[1] \"Current iteration changed total weights by 117.013685800146\"\n[1] \"Raking...Iteration 6\"\n[1] \"Current iteration changed total weights by 57.7258836983039\"\n[1] \"Raking...Iteration 7\"\n[1] \"Current iteration changed total weights by 28.6776280986623\"\n[1] \"Raking...Iteration 8\"\n[1] \"Current iteration changed total weights by 14.2911591714348\"\n[1] \"Raking...Iteration 9\"\n[1] \"Current iteration changed total weights by 7.13247750226392\"\n[1] \"Raking...Iteration 10\"\n[1] \"Current iteration changed total weights by 3.56232516745599\"\n[1] \"Raking...Iteration 11\"\n[1] \"Current iteration changed total weights by 1.77986122649579\"\n[1] \"Raking...Iteration 12\"\n[1] \"Current iteration changed total weights by 0.889443408173408\"\n[1] \"Raking...Iteration 13\"\n[1] \"Current iteration changed total weights by 0.444518937419049\"\n[1] \"Raking...Iteration 14\"\n[1] \"Current iteration changed total weights by 0.222168298200355\"\n[1] \"Raking...Iteration 15\"\n[1] \"Current iteration changed total weights by 0.111041122172557\"\n[1] \"Raking...Iteration 16\"\n[1] \"Current iteration changed total weights by 0.0554996903867008\"\n[1] \"Raking...Iteration 17\"\n[1] \"Current iteration changed total weights by 0.0277395722485096\"\n[1] \"Raking...Iteration 18\"\n[1] \"Current iteration changed total weights by 0.0138646911446929\"\n[1] \"Raking...Iteration 19\"\n[1] \"Current iteration changed total weights by 0.00692980891148254\"\n[1] \"Raking...Iteration 20\"\n[1] \"Current iteration changed total weights by 0.00346363905896691\"\n[1] \"Raking...Iteration 21\"\n[1] \"Current iteration changed total weights by 0.0017311876753543\"\n[1] \"Raking...Iteration 22\"\n[1] \"Current iteration changed total weights by 0.000865278184505269\"\n[1] \"Raking...Iteration 23\"\n[1] \"Current iteration changed total weights by 0.000432481360931769\"\n[1] \"Raking...Iteration 24\"\n[1] \"Current iteration changed total weights by 0.000216161858694386\"\n[1] \"Raking...Iteration 25\"\n[1] \"Current iteration changed total weights by 0.000108041526367841\"\n[1] \"Raking...Iteration 26\"\n[1] \"Current iteration changed total weights by 5.40010754817022e-05\"\n[1] \"Raking...Iteration 27\"\n[1] \"Current iteration changed total weights by 2.69906939704967e-05\"\n[1] \"Raking...Iteration 28\"\n[1] \"Current iteration changed total weights by 1.34904286115956e-05\"\n[1] \"Raking...Iteration 29\"\n[1] \"Current iteration changed total weights by 6.74275536705071e-06\"\n[1] \"Raking...Iteration 30\"\n[1] \"Current iteration changed total weights by 3.37015249596284e-06\"\n[1] \"Raking...Iteration 31\"\n[1] \"Current iteration changed total weights by 1.68445549902918e-06\"\n[1] \"Raking...Iteration 32\"\n[1] \"Current iteration changed total weights by 8.41919677752045e-07\"\n[1] \"Raking...Iteration 33\"\n[1] \"Current iteration changed total weights by 4.2081173812214e-07\"\n[1] \"Raking...Iteration 34\"\n[1] \"Current iteration changed total weights by 2.10325613814177e-07\"\n[1] \"Raking...Iteration 35\"\n[1] \"Current iteration changed total weights by 1.05132848760014e-07\"\n[1] \"Raking...Iteration 36\"\n[1] \"Current iteration changed total weights by 5.2541417494556e-08\"\n[1] \"Raking...Iteration 37\"\n[1] \"Current iteration changed total weights by 2.6262089225515e-08\"\n[1] \"Raking...Iteration 38\"\n[1] \"Current iteration changed total weights by 1.31248361623371e-08\"\n[1] \"Raking...Iteration 39\"\n[1] \"Current iteration changed total weights by 6.56191101455761e-09\"\n[1] \"Raking...Iteration 40\"\n[1] \"Current iteration changed total weights by 3.28742305599761e-09\"\n[1] \"Raking...Iteration 41\"\n[1] \"Current iteration changed total weights by 1.63145386089525e-09\"\n[1] \"Raking...Iteration 42\"\n[1] \"Current iteration changed total weights by 8.19097567550386e-10\"\n[1] \"Raking...Iteration 43\"\n[1] \"Current iteration changed total weights by 4.13800105292239e-10\"\n[1] \"Raking...Iteration 44\"\n[1] \"Current iteration changed total weights by 2.04557204508404e-10\"\n[1] \"Raking...Iteration 45\"\n[1] \"Current iteration changed total weights by 9.81050241044557e-11\"\n[1] \"Raking...Iteration 46\"\n[1] \"Current iteration changed total weights by 5.28902477370252e-11\"\n[1] \"Raking...Iteration 47\"\n[1] \"Current iteration changed total weights by 3.22354920534451e-11\"\n[1] \"Raking...Iteration 48\"\n[1] \"Current iteration changed total weights by 1.09625641897537e-11\"\n[1] \"Raking...Iteration 49\"\n[1] \"Current iteration changed total weights by 6.39993613660295e-12\"\n[1] \"Raking...Iteration 50\"\n[1] \"Current iteration changed total weights by 1.26053056881403e-11\"\n[1] \"Raking converged in 50 iterations\"\nâ Finished: weight_2050_dryhot | Rescaled sum = 3373040 \n\nð Raking: 2030 wetwarm \n[1] \"Raking...Iteration 1\"\n[1] \"Current iteration changed total weights by 10143.6303610591\"\n[1] \"Raking...Iteration 2\"\n[1] \"Current iteration changed total weights by 1113.06870446721\"\n[1] \"Raking...Iteration 3\"\n[1] \"Current iteration changed total weights by 105.037972609987\"\n[1] \"Raking...Iteration 4\"\n[1] \"Current iteration changed total weights by 29.9472527882443\"\n[1] \"Raking...Iteration 5\"\n[1] \"Current iteration changed total weights by 12.8230399590764\"\n[1] \"Raking...Iteration 6\"\n[1] \"Current iteration changed total weights by 5.45254412008754\"\n[1] \"Raking...Iteration 7\"\n[1] \"Current iteration changed total weights by 2.31319537664094\"\n[1] \"Raking...Iteration 8\"\n[1] \"Current iteration changed total weights by 0.980864719763577\"\n[1] \"Raking...Iteration 9\"\n[1] \"Current iteration changed total weights by 0.415861450094028\"\n[1] \"Raking...Iteration 10\"\n[1] \"Current iteration changed total weights by 0.17630675687695\"\n[1] \"Raking...Iteration 11\"\n[1] \"Current iteration changed total weights by 0.0747449329100002\"\n[1] \"Raking...Iteration 12\"\n[1] \"Current iteration changed total weights by 0.031687754416488\"\n[1] \"Raking...Iteration 13\"\n[1] \"Current iteration changed total weights by 0.0134338306667572\"\n[1] \"Raking...Iteration 14\"\n[1] \"Current iteration changed total weights by 0.00569518355356508\"\n[1] \"Raking...Iteration 15\"\n[1] \"Current iteration changed total weights by 0.00241443405678576\"\n[1] \"Raking...Iteration 16\"\n[1] \"Current iteration changed total weights by 0.00102358254635254\"\n[1] \"Raking...Iteration 17\"\n[1] \"Current iteration changed total weights by 0.000433940664588184\"\n[1] \"Raking...Iteration 18\"\n[1] \"Current iteration changed total weights by 0.000183966107171363\"\n[1] \"Raking...Iteration 19\"\n[1] \"Current iteration changed total weights by 7.79911425734525e-05\"\n[1] \"Raking...Iteration 20\"\n[1] \"Current iteration changed total weights by 3.30637973288694e-05\"\n[1] \"Raking...Iteration 21\"\n[1] \"Current iteration changed total weights by 1.40171649833376e-05\"\n[1] \"Raking...Iteration 22\"\n[1] \"Current iteration changed total weights by 5.94247738694431e-06\"\n[1] \"Raking...Iteration 23\"\n[1] \"Current iteration changed total weights by 2.51926749139653e-06\"\n[1] \"Raking...Iteration 24\"\n[1] \"Current iteration changed total weights by 1.06802578830889e-06\"\n[1] \"Raking...Iteration 25\"\n[1] \"Current iteration changed total weights by 4.52777600523646e-07\"\n[1] \"Raking...Iteration 26\"\n[1] \"Current iteration changed total weights by 1.91947772842926e-07\"\n[1] \"Raking...Iteration 27\"\n[1] \"Current iteration changed total weights by 8.13775889452195e-08\"\n[1] \"Raking...Iteration 28\"\n[1] \"Current iteration changed total weights by 3.44996672341225e-08\"\n[1] \"Raking...Iteration 29\"\n[1] \"Current iteration changed total weights by 1.46203362194619e-08\"\n[1] \"Raking...Iteration 30\"\n[1] \"Current iteration changed total weights by 6.19908585575146e-09\"\n[1] \"Raking...Iteration 31\"\n[1] \"Current iteration changed total weights by 2.62605176493125e-09\"\n[1] \"Raking...Iteration 32\"\n[1] \"Current iteration changed total weights by 1.11392478574501e-09\"\n[1] \"Raking...Iteration 33\"\n[1] \"Current iteration changed total weights by 4.74708217179654e-10\"\n[1] \"Raking...Iteration 34\"\n[1] \"Current iteration changed total weights by 2.01649696940365e-10\"\n[1] \"Raking...Iteration 35\"\n[1] \"Current iteration changed total weights by 8.35883029459694e-11\"\n[1] \"Raking...Iteration 36\"\n[1] \"Current iteration changed total weights by 3.96921939760375e-11\"\n[1] \"Raking...Iteration 37\"\n[1] \"Current iteration changed total weights by 2.0953350166053e-11\"\n[1] \"Raking...Iteration 38\"\n[1] \"Current iteration changed total weights by 2.14316342450616e-11\"\n[1] \"Raking converged in 38 iterations\"\nâ Finished: weight_2030_wetwarm | Rescaled sum = 3644937 \n\nð Raking: 2050 wetwarm \n\n\n[1] \"Raking...Iteration 1\"\n[1] \"Current iteration changed total weights by 12090.1233458528\"\n[1] \"Raking...Iteration 2\"\n[1] \"Current iteration changed total weights by 2530.22683480276\"\n[1] \"Raking...Iteration 3\"\n[1] \"Current iteration changed total weights by 545.289086929603\"\n[1] \"Raking...Iteration 4\"\n[1] \"Current iteration changed total weights by 239.281867562689\"\n[1] \"Raking...Iteration 5\"\n[1] \"Current iteration changed total weights by 115.949247522464\"\n[1] \"Raking...Iteration 6\"\n[1] \"Current iteration changed total weights by 57.2090896353898\"\n[1] \"Raking...Iteration 7\"\n[1] \"Current iteration changed total weights by 28.4239091829035\"\n[1] \"Raking...Iteration 8\"\n[1] \"Current iteration changed total weights by 14.1658930184014\"\n[1] \"Raking...Iteration 9\"\n[1] \"Current iteration changed total weights by 7.07045651113144\"\n[1] \"Raking...Iteration 10\"\n[1] \"Current iteration changed total weights by 3.53157494715733\"\n[1] \"Raking...Iteration 11\"\n[1] \"Current iteration changed total weights by 1.76460487893446\"\n[1] \"Raking...Iteration 12\"\n[1] \"Current iteration changed total weights by 0.881871777955239\"\n[1] \"Raking...Iteration 13\"\n[1] \"Current iteration changed total weights by 0.440760681424373\"\n[1] \"Raking...Iteration 14\"\n[1] \"Current iteration changed total weights by 0.220302768535746\"\n[1] \"Raking...Iteration 15\"\n[1] \"Current iteration changed total weights by 0.110115109338703\"\n[1] \"Raking...Iteration 16\"\n[1] \"Current iteration changed total weights by 0.0550400471506076\"\n[1] \"Raking...Iteration 17\"\n[1] \"Current iteration changed total weights by 0.0275114284937814\"\n[1] \"Raking...Iteration 18\"\n[1] \"Current iteration changed total weights by 0.0137514570014133\"\n[1] \"Raking...Iteration 19\"\n[1] \"Current iteration changed total weights by 0.00687361027012179\"\n[1] \"Raking...Iteration 20\"\n[1] \"Current iteration changed total weights by 0.00343574877195935\"\n[1] \"Raking...Iteration 21\"\n[1] \"Current iteration changed total weights by 0.00171734697735942\"\n[1] \"Raking...Iteration 22\"\n[1] \"Current iteration changed total weights by 0.000858410010529165\"\n[1] \"Raking...Iteration 23\"\n[1] \"Current iteration changed total weights by 0.000429073351381037\"\n[1] \"Raking...Iteration 24\"\n[1] \"Current iteration changed total weights by 0.000214470876098494\"\n[1] \"Raking...Iteration 25\"\n[1] \"Current iteration changed total weights by 0.000107202549742391\"\n[1] \"Raking...Iteration 26\"\n[1] \"Current iteration changed total weights by 5.3584837172771e-05\"\n[1] \"Raking...Iteration 27\"\n[1] \"Current iteration changed total weights by 2.67842064797241e-05\"\n[1] \"Raking...Iteration 28\"\n[1] \"Current iteration changed total weights by 1.33879998085451e-05\"\n[1] \"Raking...Iteration 29\"\n[1] \"Current iteration changed total weights by 6.6919454595471e-06\"\n[1] \"Raking...Iteration 30\"\n[1] \"Current iteration changed total weights by 3.3449464078017e-06\"\n[1] \"Raking...Iteration 31\"\n[1] \"Current iteration changed total weights by 1.67195333011794e-06\"\n[1] \"Raking...Iteration 32\"\n[1] \"Current iteration changed total weights by 8.35729210946212e-07\"\n[1] \"Raking...Iteration 33\"\n[1] \"Current iteration changed total weights by 4.17734884960996e-07\"\n[1] \"Raking...Iteration 34\"\n[1] \"Current iteration changed total weights by 2.08805286450175e-07\"\n[1] \"Raking...Iteration 35\"\n[1] \"Current iteration changed total weights by 1.0436439773498e-07\"\n[1] \"Raking...Iteration 36\"\n[1] \"Current iteration changed total weights by 5.21646754125804e-08\"\n[1] \"Raking...Iteration 37\"\n[1] \"Current iteration changed total weights by 2.60748477809436e-08\"\n[1] \"Raking...Iteration 38\"\n[1] \"Current iteration changed total weights by 1.30374669393696e-08\"\n[1] \"Raking...Iteration 39\"\n[1] \"Current iteration changed total weights by 6.51523252015451e-09\"\n[1] \"Raking...Iteration 40\"\n[1] \"Current iteration changed total weights by 3.25329541084329e-09\"\n[1] \"Raking...Iteration 41\"\n[1] \"Current iteration changed total weights by 1.62665081404612e-09\"\n[1] \"Raking...Iteration 42\"\n[1] \"Current iteration changed total weights by 8.13767053742254e-10\"\n[1] \"Raking...Iteration 43\"\n[1] \"Current iteration changed total weights by 4.05445566009632e-10\"\n[1] \"Raking...Iteration 44\"\n[1] \"Current iteration changed total weights by 2.10180650661584e-10\"\n[1] \"Raking...Iteration 45\"\n[1] \"Current iteration changed total weights by 1.01577857236634e-10\"\n[1] \"Raking...Iteration 46\"\n[1] \"Current iteration changed total weights by 5.25938181894503e-11\"\n[1] \"Raking...Iteration 47\"\n[1] \"Current iteration changed total weights by 1.94128602082344e-11\"\n[1] \"Raking...Iteration 48\"\n[1] \"Current iteration changed total weights by 1.46402334699758e-11\"\n[1] \"Raking...Iteration 49\"\n[1] \"Current iteration changed total weights by 1.23349663816441e-11\"\n[1] \"Raking...Iteration 50\"\n[1] \"Current iteration changed total weights by 1.2398304605199e-11\"\n[1] \"Raking converged in 50 iterations\"\nâ Finished: weight_2050_wetwarm | Rescaled sum = 3373040 \n\nð Raking: 2030 nzs \n\n\n[1] \"Raking...Iteration 1\"\n[1] \"Current iteration changed total weights by 10310.5139991802\"\n[1] \"Raking...Iteration 2\"\n[1] \"Current iteration changed total weights by 1147.14331690837\"\n[1] \"Raking...Iteration 3\"\n[1] \"Current iteration changed total weights by 101.733262402602\"\n[1] \"Raking...Iteration 4\"\n[1] \"Current iteration changed total weights by 25.9315722748736\"\n[1] \"Raking...Iteration 5\"\n[1] \"Current iteration changed total weights by 11.0252278065824\"\n[1] \"Raking...Iteration 6\"\n[1] \"Current iteration changed total weights by 4.69483316897593\"\n[1] \"Raking...Iteration 7\"\n[1] \"Current iteration changed total weights by 1.99393074738122\"\n[1] \"Raking...Iteration 8\"\n[1] \"Current iteration changed total weights by 0.846385398511415\"\n[1] \"Raking...Iteration 9\"\n[1] \"Current iteration changed total weights by 0.359228191684076\"\n[1] \"Raking...Iteration 10\"\n[1] \"Current iteration changed total weights by 0.152459737715725\"\n[1] \"Raking...Iteration 11\"\n[1] \"Current iteration changed total weights by 0.0647043282166533\"\n[1] \"Raking...Iteration 12\"\n[1] \"Current iteration changed total weights by 0.0274605229968755\"\n[1] \"Raking...Iteration 13\"\n[1] \"Current iteration changed total weights by 0.0116542182249344\"\n[1] \"Raking...Iteration 14\"\n[1] \"Current iteration changed total weights by 0.00494603299837493\"\n[1] \"Raking...Iteration 15\"\n[1] \"Current iteration changed total weights by 0.00209908811282927\"\n[1] \"Raking...Iteration 16\"\n[1] \"Current iteration changed total weights by 0.000890849298668839\"\n[1] \"Raking...Iteration 17\"\n[1] \"Current iteration changed total weights by 0.000378074842956433\"\n[1] \"Raking...Iteration 18\"\n[1] \"Current iteration changed total weights by 0.000160454272056909\"\n[1] \"Raking...Iteration 19\"\n[1] \"Current iteration changed total weights by 6.80965023867608e-05\"\n[1] \"Raking...Iteration 20\"\n[1] \"Current iteration changed total weights by 2.89000258972272e-05\"\n[1] \"Raking...Iteration 21\"\n[1] \"Current iteration changed total weights by 1.2265119010646e-05\"\n[1] \"Raking...Iteration 22\"\n[1] \"Current iteration changed total weights by 5.20529340980458e-06\"\n[1] \"Raking...Iteration 23\"\n[1] \"Current iteration changed total weights by 2.20912054499367e-06\"\n[1] \"Raking...Iteration 24\"\n[1] \"Current iteration changed total weights by 9.37541801249164e-07\"\n[1] \"Raking...Iteration 25\"\n[1] \"Current iteration changed total weights by 3.97889870940027e-07\"\n[1] \"Raking...Iteration 26\"\n[1] \"Current iteration changed total weights by 1.68862695271166e-07\"\n[1] \"Raking...Iteration 27\"\n[1] \"Current iteration changed total weights by 7.16640195519425e-08\"\n[1] \"Raking...Iteration 28\"\n[1] \"Current iteration changed total weights by 3.04108449533658e-08\"\n[1] \"Raking...Iteration 29\"\n[1] \"Current iteration changed total weights by 1.29057503017727e-08\"\n[1] \"Raking...Iteration 30\"\n[1] \"Current iteration changed total weights by 5.47438200326766e-09\"\n[1] \"Raking...Iteration 31\"\n[1] \"Current iteration changed total weights by 2.32431085489537e-09\"\n[1] \"Raking...Iteration 32\"\n[1] \"Current iteration changed total weights by 9.85509063244905e-10\"\n[1] \"Raking...Iteration 33\"\n[1] \"Current iteration changed total weights by 4.1738801304092e-10\"\n[1] \"Raking...Iteration 34\"\n[1] \"Current iteration changed total weights by 1.79832648772305e-10\"\n[1] \"Raking...Iteration 35\"\n[1] \"Current iteration changed total weights by 7.77217179503964e-11\"\n[1] \"Raking...Iteration 36\"\n[1] \"Current iteration changed total weights by 3.09496317463243e-11\"\n[1] \"Raking...Iteration 37\"\n[1] \"Current iteration changed total weights by 1.31100130751349e-11\"\n[1] \"Raking...Iteration 38\"\n[1] \"Current iteration changed total weights by 1.86589632633627e-11\"\n[1] \"Raking converged in 38 iterations\"\nâ Finished: weight_2030_nzs | Rescaled sum = 3644937 \n\nð Raking: 2050 nzs \n\n\n[1] \"Raking...Iteration 1\"\n[1] \"Current iteration changed total weights by 12582.6080258256\"\n[1] \"Raking...Iteration 2\"\n[1] \"Current iteration changed total weights by 2656.25630869676\"\n[1] \"Raking...Iteration 3\"\n[1] \"Current iteration changed total weights by 579.244442638124\"\n[1] \"Raking...Iteration 4\"\n[1] \"Current iteration changed total weights by 255.466182139351\"\n[1] \"Raking...Iteration 5\"\n[1] \"Current iteration changed total weights by 124.12030371334\"\n[1] \"Raking...Iteration 6\"\n[1] \"Current iteration changed total weights by 61.4601183558639\"\n[1] \"Raking...Iteration 7\"\n[1] \"Current iteration changed total weights by 30.659206524823\"\n[1] \"Raking...Iteration 8\"\n[1] \"Current iteration changed total weights by 15.3451459877343\"\n[1] \"Raking...Iteration 9\"\n[1] \"Current iteration changed total weights by 7.69268071979611\"\n[1] \"Raking...Iteration 10\"\n[1] \"Current iteration changed total weights by 3.85949002141116\"\n[1] \"Raking...Iteration 11\"\n[1] \"Current iteration changed total weights by 1.93711317103484\"\n[1] \"Raking...Iteration 12\"\n[1] \"Current iteration changed total weights by 0.972448832449166\"\n[1] \"Raking...Iteration 13\"\n[1] \"Current iteration changed total weights by 0.488227274664997\"\n[1] \"Raking...Iteration 14\"\n[1] \"Current iteration changed total weights by 0.245131521603412\"\n[1] \"Raking...Iteration 15\"\n[1] \"Current iteration changed total weights by 0.123079933429499\"\n[1] \"Raking...Iteration 16\"\n[1] \"Current iteration changed total weights by 0.0617989151597148\"\n[1] \"Raking...Iteration 17\"\n[1] \"Current iteration changed total weights by 0.0310296741706161\"\n[1] \"Raking...Iteration 18\"\n[1] \"Current iteration changed total weights by 0.0155802695684296\"\n[1] \"Raking...Iteration 19\"\n[1] \"Current iteration changed total weights by 0.00782300155729376\"\n[1] \"Raking...Iteration 20\"\n[1] \"Current iteration changed total weights by 0.00392800666774296\"\n[1] \"Raking...Iteration 21\"\n[1] \"Current iteration changed total weights by 0.00197229190246329\"\n[1] \"Raking...Iteration 22\"\n[1] \"Current iteration changed total weights by 0.000990307926894141\"\n[1] \"Raking...Iteration 23\"\n[1] \"Current iteration changed total weights by 0.000497243783062373\"\n[1] \"Raking...Iteration 24\"\n[1] \"Current iteration changed total weights by 0.000249671222702641\"\n[1] \"Raking...Iteration 25\"\n[1] \"Current iteration changed total weights by 0.000125362489825309\"\n[1] \"Raking...Iteration 26\"\n[1] \"Current iteration changed total weights by 6.29458034132058e-05\"\n[1] \"Raking...Iteration 27\"\n[1] \"Current iteration changed total weights by 3.1605737912721e-05\"\n[1] \"Raking...Iteration 28\"\n[1] \"Current iteration changed total weights by 1.58695638226014e-05\"\n[1] \"Raking...Iteration 29\"\n[1] \"Current iteration changed total weights by 7.96826984250654e-06\"\n[1] \"Raking...Iteration 30\"\n[1] \"Current iteration changed total weights by 4.00095074870599e-06\"\n[1] \"Raking...Iteration 31\"\n[1] \"Current iteration changed total weights by 2.00891721136021e-06\"\n[1] \"Raking...Iteration 32\"\n[1] \"Current iteration changed total weights by 1.00869897295963e-06\"\n[1] \"Raking...Iteration 33\"\n[1] \"Current iteration changed total weights by 5.06479979012209e-07\"\n[1] \"Raking...Iteration 34\"\n[1] \"Current iteration changed total weights by 2.543062486704e-07\"\n[1] \"Raking...Iteration 35\"\n[1] \"Current iteration changed total weights by 1.2769646767774e-07\"\n[1] \"Raking...Iteration 36\"\n[1] \"Current iteration changed total weights by 6.41192587913508e-08\"\n[1] \"Raking...Iteration 37\"\n[1] \"Current iteration changed total weights by 3.21929598534609e-08\"\n[1] \"Raking...Iteration 38\"\n[1] \"Current iteration changed total weights by 1.61665286713131e-08\"\n[1] \"Raking...Iteration 39\"\n[1] \"Current iteration changed total weights by 8.11006850565121e-09\"\n[1] \"Raking...Iteration 40\"\n[1] \"Current iteration changed total weights by 4.07511735467381e-09\"\n[1] \"Raking...Iteration 41\"\n[1] \"Current iteration changed total weights by 2.04322259111933e-09\"\n[1] \"Raking...Iteration 42\"\n[1] \"Current iteration changed total weights by 1.0333868205592e-09\"\n[1] \"Raking...Iteration 43\"\n[1] \"Current iteration changed total weights by 5.13258435752562e-10\"\n[1] \"Raking...Iteration 44\"\n[1] \"Current iteration changed total weights by 2.60030219578766e-10\"\n[1] \"Raking...Iteration 45\"\n[1] \"Current iteration changed total weights by 1.27842236796738e-10\"\n[1] \"Raking...Iteration 46\"\n[1] \"Current iteration changed total weights by 6.4663441268209e-11\"\n[1] \"Raking...Iteration 47\"\n[1] \"Current iteration changed total weights by 3.36362604436147e-11\"\n[1] \"Raking...Iteration 48\"\n[1] \"Current iteration changed total weights by 1.82366344247953e-11\"\n[1] \"Raking...Iteration 49\"\n[1] \"Current iteration changed total weights by 1.16116005699496e-11\"\n[1] \"Raking...Iteration 50\"\n[1] \"Current iteration changed total weights by 9.08839670188399e-12\"\n[1] \"Raking...Iteration 51\"\n[1] \"Current iteration changed total weights by 9.20125087233714e-12\"\n[1] \"Raking converged in 51 iterations\"\nâ Finished: weight_2050_nzs | Rescaled sum = 3373040 \n\n\nWeights for the household database. In any household survey, family members share the same household weight. Multiplying that weight by the number of household members over all observations adds to the total population of that year. In the persons dataset, the individualâs weight is the household weight divided by the number of family members. But when we do our raking procedure to reweight the dataset to match projected future conditions, we change the individual weights of some family members, but not of others who are not subject to the new conditions. So the family weights need to change to reflect that. This is what is happening below where we create the variables hh_weight_year_scenario.\n\n# Compute hhsize (if not done already)\nhh_size &lt;- rakedata_base |&gt; \n  select(UID, hhsize) |&gt; \n  mutate(ones = 1) |&gt; \n  group_by(UID) |&gt; \n  summarize(hhsize = sum(ones, na.rm = TRUE), .groups = \"drop\")\n\n# Merge household size back into rakedata_base\n\nrakedata_base &lt;- rakedata_base |&gt;\n  rename(hhsize_old = hhsize) |&gt; \n  left_join(hh_size, by = \"UID\")\n\n# Calculate all hh_weight_* columns\n# Get all dynamically created person-weight columns\nweight_cols &lt;- names(rakedata_base)[grepl(\"^weight_\\\\d{4}_.+\", names(rakedata_base))]\n\n# Create household weight columns\nfor (wcol in weight_cols) {\n  hhcol &lt;- sub(\"weight_\", \"hh_weight_\", wcol)\n  rakedata_base[[hhcol]] &lt;- rakedata_base[[wcol]] / rakedata_base$hhsize\n}\n\n# Aggregate to household level\n# All household-weight columns including 2023\nhh_weight_cols &lt;- grep(\"^hh_weight_\", names(rakedata_base), value = TRUE)\n\nweights_scenarios &lt;- rakedata_base |&gt; \n  group_by(UID) |&gt;\n  summarize(across(all_of(hh_weight_cols), ~sum(.x, na.rm = TRUE))) |&gt;\n  ungroup()\n\n# Save pp_microsim12\npp_microsim12 &lt;- tibble(rakedata_base)",
    "crumbs": [
      "Home",
      "Supporting materials",
      "Georgia CCDR Microsimulation"
    ]
  },
  {
    "objectID": "supporting-materials/geo-microsimulation.html#macro-scenarios-without-additional-impacts",
    "href": "supporting-materials/geo-microsimulation.html#macro-scenarios-without-additional-impacts",
    "title": "Georgia CCDR Microsimulation",
    "section": "7.1 Macro scenarios without additional impacts",
    "text": "7.1 Macro scenarios without additional impacts\nFirst we only adjust labor income according to the reweighting procedure and rescaling of the wage bill. We create household-level total monthly labor income (mli_) and multiplier coefficients (mli_coef_) for each scenario. These will allow us to rescale, labor income, and self-employment income. There is a mix of naming conventions within the transformation below born out of mixing different codebases, but the end result is consistent with the naming convention that we have been using here.\nTotal income in the household dataset (hh_income).\n\n# Identify the new income columns\nmli_cols &lt;- grep(\"^monthly_labor_income_\\\\d{4}_.+\", names(pp_microsim13), value = TRUE)\n\n# Household aggregation\nhh_li &lt;- pp_microsim13 |&gt;\n  group_by(UID) |&gt;\n  summarize(\n    mli_2023 = sum(monthly_labor_income_2023, na.rm = TRUE),\n    across(all_of(mli_cols), ~sum(.x, na.rm = TRUE), .names = \"mli_{.col}\")\n  ) |&gt;\n  ungroup()\n\n# Compute multipliers\n# Extract only the rescaled mli columns\nmli_scen_cols &lt;- grep(\"^mli_monthly_labor_income_\", names(hh_li), value = TRUE)\n\n# Create coefficients\nfor (col in mli_scen_cols) {\n  coef_col &lt;- gsub(\"mli_monthly_labor_income_\", \"mli_coef_\", col)\n  hh_li[[coef_col]] &lt;- ifelse(\n    hh_li$mli_2023 == 0, 1,\n    hh_li[[col]] / hh_li$mli_2023\n  )\n}\n\n# Clean final format\n# Optional: rename scenario mli columns to match old style (mli_2030_baseline)\nnames(hh_li) &lt;- gsub(\"mli_monthly_labor_income_\", \"mli_\", names(hh_li))\n\n# Keep what we need\nhh_li &lt;- hh_li |&gt;\n  select(UID, starts_with(\"mli_\"), starts_with(\"mli_coef_\"))\n\nWe are now ready to merge this into hh_income and use the mli_coef_* variables to rescale household-level income per scenario.\nBuild IC microsim 01\n\nic_microsim01 &lt;- hh_income |&gt;\n  left_join(hh_li, by = \"UID\") |&gt;\n  left_join(weights_scenarios, by = \"UID\") |&gt;\n  rename(\n    labor_income_2023 = ShemDaq,\n    self_employment_income_2023 = ShemTviTdasaqm,\n    agr_income_2023 = Shem_Sof,\n    totalinc_2023 = Shemosavalisul\n  )\n\nRescale incomes using dynamic multipliers.\n\n# Find all mli_coef_* columns\ncoef_cols &lt;- grep(\"^mli_coef_\", names(ic_microsim01), value = TRUE)\n\n# Create rescaled income columns\nfor (coef in coef_cols) {\n  suffix &lt;- sub(\"mli_coef_\", \"\", coef)\n\n  # Create income variable names\n  ic_microsim01[[paste0(\"labor_income_\", suffix)]] &lt;-\n    ic_microsim01$labor_income_2023 * ic_microsim01[[coef]]\n\n  ic_microsim01[[paste0(\"self_employment_income_\", suffix)]] &lt;-\n    ic_microsim01$self_employment_income_2023 * ic_microsim01[[coef]]\n}\n\nAnd recalculate total income.\n\n# Find all suffixes again\nsuffixes &lt;- sub(\"mli_coef_\", \"\", coef_cols)\n\nfor (sfx in suffixes) {\n  ic_microsim01[[paste0(\"totalinc_\", sfx)]] &lt;-\n    ic_microsim01$totalinc_2023 -\n    coalesce(ic_microsim01$labor_income_2023, 0) -\n    coalesce(ic_microsim01$self_employment_income_2023, 0) +\n    coalesce(ic_microsim01[[paste0(\"labor_income_\", sfx)]], 0) +\n    coalesce(ic_microsim01[[paste0(\"self_employment_income_\", sfx)]], 0)\n}\n\nRecalculate adult-equivalent consumption and poverty status\n\ntotinc_cols &lt;- grep(\"^totalinc_\", names(ic_microsim01), value = TRUE)\ntotinc_suffixes &lt;- sub(\"totalinc_\", \"\", totinc_cols)\n\nfor (col in totinc_cols) {\n  suffix &lt;- sub(\"totalinc_\", \"\", col)\n  coef_name &lt;- paste0(\"totinc_coef_\", suffix)\n  ic_microsim01[[coef_name]] &lt;- ifelse(\n    ic_microsim01$totalinc_2023 == 0,\n    1,\n    ic_microsim01[[col]] / ic_microsim01$totalinc_2023\n  )\n}\n\nBuild IC Coef scenarios\n\ncoef_cols &lt;- grep(\"^totinc_coef_\", names(ic_microsim01), value = TRUE)\n\nic_coef_scenarios &lt;- ic_microsim01 |&gt;\n  select(UID, all_of(coef_cols))\n\nAnd we apply to consumption:\n\nca_microsim01 &lt;- poverty |&gt; \n  left_join(weights_scenarios, join_by(UID == UID)) |&gt; \n  left_join(ic_coef_scenarios, join_by(UID == UID)) |&gt; \n  rename(tc_2023 = totcons) |&gt; \n  mutate(\n    hh_weight_2023 = weights,\n    adult_equivalent = tc_2023 / aecons  # derives equivalent household size\n  )\n\nAdjust tc_* and recalculate poverty\n\nfor (coef in coef_cols) {\n  suffix &lt;- sub(\"totinc_coef_\", \"\", coef)\n\n  tc_col &lt;- paste0(\"tc_\", suffix)\n  ae_col &lt;- paste0(\"aecons_\", suffix)\n  poor_col &lt;- paste0(\"poor_\", suffix)\n\n  ca_microsim01[[tc_col]] &lt;-\n    ca_microsim01$tc_2023 * ca_microsim01[[coef]]\n\n  ca_microsim01[[ae_col]] &lt;-\n    ca_microsim01[[tc_col]] / ca_microsim01$adult_equivalent\n\n  ca_microsim01[[poor_col]] &lt;-\n    if_else(ca_microsim01[[ae_col]] &lt; pline, 1, 0)\n}\n\nAt this point we re-calculate decile groups for the NZS scenario, to be able to âgive backâ energy tax revenues to the lower deciles. This scenario is not ready yet, so we need to come back to this. Review Armeniaâs microsimulation file for this.",
    "crumbs": [
      "Home",
      "Supporting materials",
      "Georgia CCDR Microsimulation"
    ]
  },
  {
    "objectID": "supporting-materials/geo-microsimulation.html#climate-change",
    "href": "supporting-materials/geo-microsimulation.html#climate-change",
    "title": "Georgia CCDR Microsimulation",
    "section": "7.2 Climate change",
    "text": "7.2 Climate change\nIn these sections we use Administrative Level 1 data on yield losses and labor productivity losses due to climate change that are provided in the study commissioned for Armeniaâs CCDR Estimating the Economic Impacts of Climate Change in Armenia (Strzepek, Boehlert, Castillo, & Smet, 2024).\nIn the climate change scenario, we ask ourselves, what would happen if agriculture revenues from crops and livestock are reduced due to losses in productivity due to heat? For this, we use crops data.\nWe add a moving window average and max value for our labor productivity data.\n\n# First calculate moving window average\nlabor_productivity01 &lt;- labor_productivity |&gt;\n  # Fix region names\n  mutate(\n    region = case_when(\n      region ==\n        \"Ajaria\" ~ \"Adjara A.R.\",\n      region ==\n        \"Racha-Lechkhumi-Kvemo Svaneti\" ~ \"Racha-Lechkhumi and Kvemo Svaneti\",\n      region ==\n        \"Abkhazia\" ~ \"Autonomous Republic of Abkhazia\",\n      .default = region\n    )\n  ) |&gt;\n  group_by(region,\n           scenario) |&gt;\n  arrange(year) |&gt;\n  # Moving window average 5 years before, 5 after\n  mutate(\n    moving_avg = rollapply(\n      pct_change,\n      width = 11,\n      FUN = mean,\n      partial = TRUE,\n      align = \"center\",\n      fill = NA,\n      na.rm = TRUE\n    )\n  ) |&gt;\n  ungroup()\n\n# Clim scenarios to select\ncs &lt;- sort(unique(labor_productivity01$scenario))\n\n# Moving average for year of interest\n# We are interested in cs[1] = \"Hot/Dry\"\nlabor_pdcvty_loss &lt;- labor_productivity01 |&gt;\n  left_join(\n    regions[,c(1:2)],\n    join_by(region)\n  ) |&gt;\n  filter(scenario == cs[1] & year %in% analysis_years) |&gt;\n  select(-pct_change,\n         -scenario) |&gt;\n  pivot_wider(\n    names_from = c(sector,year),\n    values_from = moving_avg,\n    names_prefix = \"labprod_\")\n\nWe add a moving window average and max value for our crops productivity data.\n\nagriculture_productivity01 &lt;- agriculture_productivity |&gt; \n  # Fix region names\n  mutate(\n    region = case_when(\n      region == \n        \"Ajaria\" ~ \"Adjara A.R.\",\n      region == \n        \"Racha-Lechkhumi-Kvemo Svaneti\" ~ \"Racha-Lechkhumi and Kvemo Svaneti\",\n      region ==\n        \"Abkhazia\" ~ \"Autonomous Republic of Abkhazia\",\n      .default = region\n    )\n  ) |&gt; \n  group_by(region, \n           scenario) |&gt;\n  arrange(year) |&gt;\n  # Fix missing\n  mutate(\n    pct_change = if_else(\n      is.na(pct_change),0,pct_change\n    )\n  ) |&gt; \n  # Moving window average\n  mutate(\n    moving_avg = rollapply(\n      pct_change,\n      width = 11,\n      # 5 years before, 5 after + reference year = 11\n      FUN = mean,\n      partial = TRUE,\n      align = \"center\",\n      fill = NA,\n      na.rm = TRUE\n    )\n  ) |&gt;\n  ungroup()\n\n# Clim scenarios to select\ncs &lt;- sort(unique(agriculture_productivity01$scenario))\n\n# Moving average for year of interest\nag_pdcvty_loss &lt;- agriculture_productivity01 |&gt;\n  left_join(\n    regions[,c(1:2)],\n    join_by(region)\n  ) |&gt; \n  filter(scenario == cs[1] & \n         year %in% analysis_years) |&gt;\n  select(-pct_change, \n         -scenario,\n         -product) |&gt;\n  pivot_wider(\n    names_from = c(year), \n    values_from = moving_avg,\n    names_prefix = \"agprod_\")\n\nThere is no explicit livestock income in this dataset, so we leave livestock productivity out.\nAnd then we introduce these values in our ag income and labor income data. First, we attach the percentage losses to the appropriate data set.\n\n# Persons processed dataset\npp_microsim_cc01 &lt;- pp_microsim13 |&gt;\n  left_join(labor_pdcvty_loss, \n            join_by(region == RegNo))\n\n# Household income processed dataset\n# We also impact ag income with ag labor productivity\nic_microsim_cc01 &lt;- ic_microsim01 |&gt;\n  left_join(hh_basics, join_by(UID)) |&gt; \n  left_join(labor_pdcvty_loss[,c(2,3,6)],\n            join_by(RegNo)) |&gt; \n  cross_join(ag_pdcvty_loss[,c(3,4)])\n\n##write.table(lab_loss_avg, \"clipboard\", sep=\"\\t\", row.names=FALSE)\n\nAnd we first shock labor income (need to automate this in a loop).\n\n# Labor income according to sector\npp_microsim_cc02 &lt;- pp_microsim_cc01 |&gt;\n  mutate(sector = as.numeric(SAM3_job1)) |&gt;\n  mutate(\n    mli_2030_baseline_cc =\n      case_when(\n        sector == 1 ~\n          monthly_labor_income_2030_baseline * \n          (100 + labprod_Agriculture_2030)/100,\n        sector == 2 ~\n          monthly_labor_income_2030_baseline * \n          (100 + labprod_Industry_2030)/100,\n        sector == 3 ~\n          monthly_labor_income_2030_baseline * \n          (100 + labprod_Services_2030)/100,\n        TRUE ~ NA\n      )\n  ) |&gt;\n  mutate(\n    mli_2050_baseline_cc =\n      case_when(\n        sector == 1 ~\n          monthly_labor_income_2050_baseline * \n          (100 + labprod_Agriculture_2050)/100,\n        sector == 2 ~\n          monthly_labor_income_2050_baseline * \n          (100 + labprod_Industry_2050)/100,\n        sector == 3 ~\n          monthly_labor_income_2050_baseline * \n          (100 + labprod_Services_2050)/100,\n        TRUE ~ NA\n      )\n  )\n\nWe aggregate at household level and take note of the percent difference between the two labor incomes, so that we can impact labor income by that amount. We donât do it with absolute numbers because we donât know the assumptions made by the poverty team to construct the income variable.\n\nic_new_incomes01 &lt;- pp_microsim_cc02 |&gt;\n  group_by(UID) |&gt;\n  summarize(\n    mli_2030_baseline_cc = \n      sum(mli_2030_baseline_cc, na.rm = TRUE),\n    mli_2050_baseline_cc = \n      sum(mli_2050_baseline_cc, na.rm = TRUE),\n    mli_2030_original = \n      sum(monthly_labor_income_2030_baseline, na.rm = TRUE),\n    mli_2050_original = \n      sum(monthly_labor_income_2050_baseline, na.rm = TRUE)\n  ) |&gt;\n  mutate(\n    mli_2030_baseline_cc_coef =\n      if_else(\n        mli_2030_original == 0 | is.na(mli_2030_original),\n        1,\n        mli_2030_baseline_cc / mli_2030_original\n      ),\n    mli_2050_baseline_cc_coef =\n      if_else(\n        mli_2050_original == 0 | is.na(mli_2050_original),\n        1,\n        mli_2050_baseline_cc / mli_2050_original\n      )\n  ) |&gt;\n  ungroup()\n\nic_microsim_cc02 &lt;- ic_microsim_cc01 |&gt;\n  left_join(ic_new_incomes01, \n            join_by(UID)) |&gt;\n  mutate(\n    labor_income_2030_baseline_cc = \n      labor_income_2030_baseline * mli_2030_baseline_cc_coef,\n    self_employment_income_2030_baseline_cc = \n      self_employment_income_2030_baseline * mli_2030_baseline_cc_coef,\n    labor_income_2050_baseline_cc = \n      labor_income_2050_baseline * mli_2050_baseline_cc_coef,\n    self_employment_income_2050_baseline_cc = \n      self_employment_income_2050_baseline * mli_2050_baseline_cc_coef\n  )\n\nAnd now we impact agricultural income agr_income_2030_baseline (there is no livestock incomelvstk in this dataset).\nAnd recalculate total income. First labor productivity alone. I learned about pick with this one, because the (.) is no longer interpreted as âthisâ.\n\nic_microsim_cc03 &lt;- ic_microsim_cc02 |&gt;\n  # Labor productivity applied to ag income\n  mutate(\n    agr_income_2030_cc =\n      agr_income_2023 *\n      # Labor shock\n      (100 + labprod_Agriculture_2030)/100 *\n      # Crops shock\n      (100 + agprod_2030)/100,\n    agr_income_2050_cc =\n      agr_income_2023 *\n      # Labor shock\n      (100 + labprod_Agriculture_2050)/100 *\n      # Crops shock\n      (100 + agprod_2050)/100) |&gt;\n  mutate(\n    totalinc_2030_baseline_cc =\n      totalinc_2030_baseline -\n      rowSums(pick(labor_income_2030_baseline,\n                   self_employment_income_2030_baseline,\n                   agr_income_2023), na.rm = TRUE)\n    +\n      rowSums(pick(labor_income_2030_baseline_cc,\n                   self_employment_income_2030_baseline_cc,\n                   agr_income_2030_cc), na.rm = TRUE),\n\n    totalinc_2050_baseline_cc =\n      totalinc_2050_baseline -\n      rowSums(pick(labor_income_2050_baseline,\n                   self_employment_income_2050_baseline,\n                   agr_income_2023), na.rm = TRUE) +\n      rowSums(pick(labor_income_2050_baseline_cc,\n                   self_employment_income_2050_baseline_cc,\n                   agr_income_2050_cc), na.rm = TRUE)\n  ) |&gt;\n  mutate(\n    totalinc_2030_baseline_cc_coef =\n      if_else(totalinc_2030_baseline == 0,\n              1, totalinc_2030_baseline_cc /\n                totalinc_2030_baseline),\n    totalinc_2050_baseline_cc_coef =\n      if_else(totalinc_2050_baseline == 0,\n              1, totalinc_2050_baseline_cc /\n                totalinc_2050_baseline)\n  ) |&gt;\n  mutate(\n    totalinc_2030_baseline_cc_coef =\n      if_else(is.na(totalinc_2030_baseline_cc_coef),\n              1, totalinc_2030_baseline_cc_coef),\n    totalinc_2050_baseline_cc_coef =\n      if_else(is.na(totalinc_2050_baseline_cc_coef),\n              1, totalinc_2050_baseline_cc_coef)\n  )\n\nWe assume that the loss in income translates into a loss of expenditure.\n\nincome_losses &lt;- ic_microsim_cc03 |&gt; \n  select(UID,\n         totalinc_2030_baseline_cc, \n         totalinc_2050_baseline_cc,\n         totalinc_2030_baseline_cc_coef, \n         totalinc_2050_baseline_cc_coef)\n\nca_microsim02 &lt;- ca_microsim01 |&gt; \n  left_join(income_losses, join_by(UID))\n\n# And now reduce total consumption\n\nca_microsim03 &lt;- ca_microsim02 |&gt; \n  mutate(tc_2030_baseline_cc = tc_2030_baseline *\n           totalinc_2030_baseline_cc_coef,\n         tc_2050_baseline_cc = tc_2050_baseline *\n           totalinc_2050_baseline_cc_coef         \n         ) |&gt; \n  mutate(aecons_2030_baseline_cc = \n           tc_2030_baseline_cc / adult_equivalent,\n         aecons_2050_baseline_cc = \n           tc_2050_baseline_cc / adult_equivalent) |&gt; \n  mutate(poor_2030_baseline_cc = \n           if_else(aecons_2030_baseline_cc &lt; pline, 1, 0),\n         poor_2050_baseline_cc = \n           if_else(aecons_2050_baseline_cc &lt; pline, 1, 0)\n         )\n\n##write.table(test, \"clipboard\", sep=\"\\t\", row.names=FALSE)",
    "crumbs": [
      "Home",
      "Supporting materials",
      "Georgia CCDR Microsimulation"
    ]
  },
  {
    "objectID": "supporting-materials/vulnerability.html",
    "href": "supporting-materials/vulnerability.html",
    "title": "Vulnerability Analysis",
    "section": "",
    "text": "In analysis, we estimate number of people under vulnerable circumstances.\nâThe vulnerability of a household to an extreme weather event will depend on the characteristics of the household that determine the eventâs initial impact and the ability of a household to cope with that event (â¦). This is reflected in the IPCC definition, vulnerability includes both âthe sensitivity or susceptibility to harmâ and âthe lack of capacity to cope and adaptââ (Doan et al. 2023).",
    "crumbs": [
      "Home",
      "Supporting materials",
      "Vulnerability Analysis"
    ]
  },
  {
    "objectID": "supporting-materials/vulnerability.html#datasets",
    "href": "supporting-materials/vulnerability.html#datasets",
    "title": "Vulnerability Analysis",
    "section": "Datasets",
    "text": "Datasets\nWe use data from the 2023 survey for the Labor Split and data from the 2022 survey for the household expenditure and capital shares in In mil. GEL per year per household type.\n\n# Household Unique ID, Weights, Location and other basic variables\nhh_basics &lt;- read_sav(\n  \"data/ilcs_2023/sysschedule.sav\") |&gt;\n  mutate(\n    UID = as.integer(UID))\n\n# Household size (includes no. of family members)\nhh_size &lt;- read_sav(\n  \"data/ilcs_2023/familysize.sav\")|&gt; \n  mutate(\n    UID = as.integer(UID))\n\n# Processed income at household level\nhh_income &lt;- read_sav(\n  \"data/ilcs_2023/tblincomes.sav\")|&gt; \n  mutate(\n    UID = as.integer(UID))\n\n# Consumption aggregate at household level \nhh_expenditure &lt;- read_sav(\n  \"data/ilcs_2023/tblexpenditures.sav\")|&gt; \n  rename(# rename total expenditure variables\n         total_expenditure = MTlianixarjebi_,\n         total_expenditure_aeq06 = MTlianimoxmareba_EqAdScale,\n         total_expenditure_aeq08 = Mtlianimoxmareba_EqAdScale_08) |&gt; \n  mutate(\n    UID = as.integer(UID))\n\n# Characteristics of the dwelling\nhh_chars &lt;- read_sav(\n  \"data/ilcs_2023/tblshinda01.sav\")|&gt;\n  mutate(\n    UID = as.integer(UID))\n\n# Persons (pp)\npp &lt;- read_sav(\n  \"data/ilcs_2023/tblshinda02.sav\") |&gt; \n  mutate(\n    UID = as.integer(UID),\n    MemberNo = as.integer(MemberNo))\n\n# Labor (pp)\npp_labor &lt;- read_sav(\n  \"data/ilcs_2023/tblshinda05_1.sav\") |&gt; \n  mutate(\n    UID = as.integer(UID),\n    MemberNo = as.integer(MemberNo),\n    Q5  = as.integer(Q5),\n    Q12 = as.integer(Q12)) \n\n# Poverty\npoverty &lt;- read_dta(\n  \"data/ilcs_2023/POVERTY_stata.dta\") |&gt; \n  mutate(\n    UID = as.integer(UID))\n\n# Ind. Poverty\nind_poverty &lt;- read_dta(\n  \"data/ilcs_2023/IND_POVERTY_stata.dta\") |&gt; \n  rename(MemberNo = memberno) |&gt; \n  mutate(\n    UID = as.integer(UID),\n    MemberNo = as.integer(MemberNo))\n\n# Exposure\nfloods &lt;- read.csv(\n  \"data/exposure/floods/df_exposure_100.csv\"\n)\n\nfloods_all_returns &lt;- read.csv(\n  \"data/exposure/floods/exposure_allrt_v3.0.csv\")\n\ndrought_landslide &lt;- read_excel(\n    \"data/exposure/drought_landslides/Drought_Landslide_Vulnerability_GEO.xlsx\",\n    sheet = \"vulnerabilty_geo\",\n    col_names = T\n  )\n\n# Maps\nadm1 &lt;- sf::read_sf(\"data/gis/geo-adm1.shp\") |&gt; \n  dplyr::select(RegNo, region, ADM1_PCODE, ADM1_EN, ADM1_KA, geometry) |&gt; \n  dplyr::arrange(ADM1_PCODE)",
    "crumbs": [
      "Home",
      "Supporting materials",
      "Vulnerability Analysis"
    ]
  },
  {
    "objectID": "supporting-materials/vulnerability.html#look-up-tables",
    "href": "supporting-materials/vulnerability.html#look-up-tables",
    "title": "Vulnerability Analysis",
    "section": "Look-up tables",
    "text": "Look-up tables\n\nsam_activities &lt;- read_excel(\n    \"data/sam/classifications.xlsx\",\n    sheet = \"SAM-REV2\",\n    col_names = T,\n    col_types = \"text\",\n  )\n\nsam_factors &lt;- read_excel(\n    \"data/sam/classifications.xlsx\",\n    sheet = \"SAM factors\",\n    col_names = T,\n    col_types = \"text\",\n  )\n\ncoicop &lt;- read_excel(\n    \"data/sam/classifications.xlsx\",\n    sheet = \"COICOP\",\n    col_names = T,\n    col_types = \"text\",\n  ) |&gt; \n  mutate(simple_code = as.integer(gsub(\"\\\\.\", \"\", Coicop)))\n\ncoicop_filtered &lt;- coicop |&gt; \n  filter( nchar(as.character(simple_code)) &gt;= 5)",
    "crumbs": [
      "Home",
      "Supporting materials",
      "Vulnerability Analysis"
    ]
  },
  {
    "objectID": "supporting-materials/vulnerability.html#income",
    "href": "supporting-materials/vulnerability.html#income",
    "title": "Vulnerability Analysis",
    "section": "Income",
    "text": "Income\nFollowing the methodology (Doan et al. 2023) this identifies the share of households that have income or consumption less than 1.5 times the poverty line. In the guidance paper, they use $2.15 (2017 PPP), but in our case, we use the official poverty line of Georgia for the year 2023 of 212.81 GEL per cÃ¡pita (adult equivalent) per month. To be consistent with country assessments, we use consumption and not income, but to be consistent with the methodology paper, we continue to call this variable income.\n\n# Poverty line\npoverty_line &lt;- poverty$pline[1]\nincome_threshold &lt;- poverty_line * 1.5\n\nhh_vulnerable &lt;- poverty |&gt; \n  select(\n    QuartNo,\n    UID,\n    DiaryID,\n    RegNo,\n    type,\n    weights_quar, # Sampling weights of the HH\n    weights,      # HH weights\n    hhsize,       # Number of HH members\n    Childern,     # (note typo) Children\n    Adult,        # Adolescents 8-15\n    Working_age_man,\n    Working_age_Woman,\n    Pensioner_age_man,\n    Pensioner_age_Woman,\n    aecons,\n    aeinc,\n    pline,\n    quintilc,\n    decilc) |&gt; \n  mutate(\n    vulnerability_income = if_else(\n      aecons &lt; income_threshold, 1, 0))",
    "crumbs": [
      "Home",
      "Supporting materials",
      "Vulnerability Analysis"
    ]
  },
  {
    "objectID": "supporting-materials/vulnerability.html#education",
    "href": "supporting-materials/vulnerability.html#education",
    "title": "Vulnerability Analysis",
    "section": "Education",
    "text": "Education\nEducation to switch livelihoods or to access information and resources is proxied by a variable reflecting whether the household has an adult that has completed primary education. The GMD is used because this allows us to have information on education and income for the same household which allows us to know whether an individual is deprived on one or both dimensions (Doan et al. 2023). The poverty dataset already has the education level of the head of household. However, this calls for any member having at least primary education, which makes sense, because literate family members often bridge the understanding gap for illiterate ones, regardless of head of family status.\n\nvulnerable_education &lt;- pp |&gt;\n  select(UID, Education) |&gt; \n  mutate(\n    educated_member = case_when(\n      Education &lt; 4 ~ 0, # \"4. Primary education\"\n      Education &gt;= 4 ~ 1,\n      TRUE ~ 0 )) |&gt; \n  group_by(UID) |&gt; \n  summarize(\n    educated_members = sum(educated_member, na.rm = T),\n    vulnerability_education = if_else(\n      educated_members == 0, 1, 0\n    )\n  )\n\neduc_vulnerable_hh_unweighted &lt;- sum(\n  vulnerable_education$vulnerability_education)\n\nIn the entire dataset 15 households (unweighted) meet the education vulnerability criteria. Among the survey households, up to 9 members could be educated with the following distribution. This is a positive metric for Georgia.\n\neducated_data &lt;- as.data.frame(\n  table(vulnerable_education$educated_members))\ncolnames(educated_data) &lt;- c(\"educated_members\", \"count\")\n\n# Convert educated_members to numeric\neducated_data$educated_members &lt;- as.numeric(\n  as.character(educated_data$educated_members))\n\n# The graph\nggplot(educated_data, aes(x = educated_members, y = count)) +\n  geom_bar(stat = \"identity\", fill = \"skyblue\", color = \"black\") +\n  geom_text(aes(label = count), vjust = -0.5, size = 4) +  # Add labels above bars\n  scale_x_continuous(breaks = educated_data$educated_members) +  # Set discrete ticks\n  labs(\n    title = \"Distribution of Educated Members\",\n    x = \"Number of Educated Members\",\n    y = \"Frequency\"\n  ) +\n  theme_minimal()\n\nvulnerable_education &lt;- vulnerable_education |&gt; \n  select(-educated_members)\n\n\n\n\n\n\n\nFigureÂ 1: Households for each number of educated members",
    "crumbs": [
      "Home",
      "Supporting materials",
      "Vulnerability Analysis"
    ]
  },
  {
    "objectID": "supporting-materials/vulnerability.html#access-to-water",
    "href": "supporting-materials/vulnerability.html#access-to-water",
    "title": "Vulnerability Analysis",
    "section": "Access to water",
    "text": "Access to water\nâWhen shocks hit, access to these services is an important determinant of the impact of the shock on welfare. For example, with access to improved drinking water, contaminated water from flooding and storms, or lack of water due to drought has less of an impact. Nevertheless, it is essential to acknowledge that the current indicator of access to improved drinking water, often represented by covered wells in low-income countries, may not sufficiently reflect susceptibility to contamination during extreme events such as floods or droughts. Therefore, there is a need for future work to refine this indicator by considering a potentially higher threshold. Metrics such as âimproved piped waterâ can offer a more precise assessment of the infrastructure safeguarding against water-related risks in the event of shocks.â (Doan et al. 2023)\nWe take note of this caveat and choose the threshold water supply system installed in the dwelling and water system tap in the yard or vicinity as counting towards this dimension from the possible options below:\n\nThe water supply system installed in the dwelling\nThe water system tap in the yard or vicinity\nThe well in the yard or vicinity\nNatural spring in the yard or vicinity\nRiver, lake, spring, channel\nBought water\nOther\n\n\nvulnerable_water &lt;- poverty |&gt; \n  select(UID, WaterSource) |&gt; \n  mutate(\n    vulnerability_water = if_else(\n      WaterSource &lt; 3, 0, 1)) |&gt; \n  select(-WaterSource)\n\n# We check the distribution\n\nas.data.frame(table(vulnerable_water$vulnerability_water)) |&gt; \n  gt()\n\n\n\n\n\n\n\nVar1\nFreq\n\n\n\n\n0\n10709\n\n\n1\n2499",
    "crumbs": [
      "Home",
      "Supporting materials",
      "Vulnerability Analysis"
    ]
  },
  {
    "objectID": "supporting-materials/vulnerability.html#access-to-electricity",
    "href": "supporting-materials/vulnerability.html#access-to-electricity",
    "title": "Vulnerability Analysis",
    "section": "Access to electricity",
    "text": "Access to electricity\nâWith access to electricity, households are more likely to have assets such as fans that can help with heatwaves. A fuller discussion is available in the World Bankâs Lifelines report (Hallegatte et al, 2019). Whilst not a final selection of assets and infrastructure that matter for determining the initial loss of the shock, these measures provide a good first estimate to stimulate discussion.â (Doan et al. 2023) Variable q11_3 from the poverty dataset is a dummy that determines whether the household has access to electricity.\n\nvulnerable_electricity &lt;- poverty |&gt; \n  select(UID, q11_3) |&gt; \n  mutate(\n    vulnerability_electricity = if_else(\n      q11_3 != 1, 1, 0)) |&gt; \n  select(-q11_3)\n\n# We check the distribution\n\nas.data.frame(table(vulnerable_electricity$vulnerability_electricity)) |&gt; \n  gt()\n\n\n\n\n\n\n\nVar1\nFreq\n\n\n\n\n0\n13208\n\n\n\n\n\n\n\nNow, this is not a source of variation in the case of Georgia, since 100% of households report having access to electricity, but the methodology also mentions that âAccess to markets and services, access to early warning systems, sanitation, and building and infrastructure quality are also playing a key role in determining disastersâ impacts, and has been included in other estimates, but is left for future inclusion here.â (Doan et al. 2023). Both sanitation and building infrastructure quality, proxied by wall materials could be included in Georgiaâs estimates. When it comes to sanitation, there is still a gap that the country needs to close.",
    "crumbs": [
      "Home",
      "Supporting materials",
      "Vulnerability Analysis"
    ]
  },
  {
    "objectID": "supporting-materials/vulnerability.html#access-to-sanitation",
    "href": "supporting-materials/vulnerability.html#access-to-sanitation",
    "title": "Vulnerability Analysis",
    "section": "Access to sanitation",
    "text": "Access to sanitation\nFor this variable (TypeOfToilet) we have the following categories, of which we choose âown flush toilet connected to the sewerage systemâ and âshared flush toilet connected to the sewerage systemâ as having access to sanitation.\n\nOwn flush toilet connected to the sewerage system\nShared flush toilet connected to the sewerage system\nFlush latrine not connected to the sewerage system (connected to the river, chan\nPit latrine periodically cleaned or finally filled up and buried\nOther\n\n\nvulnerable_sanitation &lt;- poverty |&gt; \n  select(UID, TypeOfToilet) |&gt; \n  mutate(\n    vulnerability_sanitation = if_else(\n      TypeOfToilet &lt; 3, 0, 1)) |&gt; \n  select(-TypeOfToilet)\n\n# We check the distribution\n\nas.data.frame(table(vulnerable_sanitation$vulnerability_sanitation)) |&gt; \n  gt()\n\n\n\n\n\n\n\nVar1\nFreq\n\n\n\n\n0\n5557\n\n\n1\n7651",
    "crumbs": [
      "Home",
      "Supporting materials",
      "Vulnerability Analysis"
    ]
  },
  {
    "objectID": "supporting-materials/vulnerability.html#building-materials",
    "href": "supporting-materials/vulnerability.html#building-materials",
    "title": "Vulnerability Analysis",
    "section": "Building materials",
    "text": "Building materials\nWhen it comes to building materials of walls and floor, data show that the most precarious categories (mud walls, and bare ground floors) are not present in the country. We will still count concrete walls as not vulnerable and wood as vulnerable, but only relative to each other, not making any assumptions about the quality of wood structures in Georgia.\n\nvulnerable_building &lt;- poverty |&gt; \n  select(UID, Walls) |&gt; \n  mutate(\n    vulnerability_building = if_else(\n      Walls %in% c(1,3), 0, 1)) |&gt; \n  select(-Walls)\n\n# We check the distribution\n\nas.data.frame(table(\n  vulnerable_building$vulnerability_building)) |&gt; \n  gt()\n\n\n\n\n\n\n\nVar1\nFreq\n\n\n\n\n0\n11746\n\n\n1\n1462",
    "crumbs": [
      "Home",
      "Supporting materials",
      "Vulnerability Analysis"
    ]
  },
  {
    "objectID": "supporting-materials/vulnerability.html#social-protection",
    "href": "supporting-materials/vulnerability.html#social-protection",
    "title": "Vulnerability Analysis",
    "section": "Social protection",
    "text": "Social protection\nâThe third dimension of inability to cope is access to public support. There is considerable evidence that cash transfers help households to manage shocks (â¦) [T]here is some evidence in favor of using information on current coverage, as support is more likely to be available in response to a disaster in places where pre-disaster coverage rates are high.â (Doan et al. 2023) In the poverty dataset the variable S_Q2b shows those households that actually received social protection benefits.\n\nvulnerable_ssp &lt;- poverty |&gt; \n  select(UID, S_Q2b) |&gt; \n  mutate(\n    vulnerability_ssp = if_else(\n      coalesce(S_Q2b, 0) == 1, 0, 1)) |&gt; \n  select(-S_Q2b)\n\n# We check the distribution\n\nas.data.frame(table(\n  vulnerable_ssp$vulnerability_ssp)) |&gt; \n  gt()\n\n\n\n\n\n\n\nVar1\nFreq\n\n\n\n\n0\n2330\n\n\n1\n10878",
    "crumbs": [
      "Home",
      "Supporting materials",
      "Vulnerability Analysis"
    ]
  },
  {
    "objectID": "supporting-materials/vulnerability.html#financial-services",
    "href": "supporting-materials/vulnerability.html#financial-services",
    "title": "Vulnerability Analysis",
    "section": "Financial services",
    "text": "Financial services\nâThe variable we use indicates whether a respondent has either a financial institution account or a mobile money account, given the strong relationship in the literature on access to mobile money and ability to use informal networks to manage the impact of large climate shocks.â (Doan et al. 2023) The poverty dataset has information on amount saved by the household, which we will use as proxy for access to some financial security. We cannot assert that the money is being saved in a proper financial institution. However, we assume that having monthly level of savings of any kind can mitigate the impacts of climate change.\n\nvulnerable_financial &lt;- poverty |&gt; \n  select(UID, DazogvaAnCasesxeba) |&gt; \n  mutate(\n    vulnerability_financial = if_else(\n      coalesce(DazogvaAnCasesxeba, 0) == 0, 1, 0)) |&gt; \n  select(-DazogvaAnCasesxeba)\n\n# We check the distribution\n\nas.data.frame(table(\n  vulnerable_financial$vulnerability_financial)) |&gt; \n  gt()\n\n\n\n\n\n\n\nVar1\nFreq\n\n\n\n\n0\n4777\n\n\n1\n8431",
    "crumbs": [
      "Home",
      "Supporting materials",
      "Vulnerability Analysis"
    ]
  },
  {
    "objectID": "supporting-materials/vulnerability.html#join-vulnerability-datasets",
    "href": "supporting-materials/vulnerability.html#join-vulnerability-datasets",
    "title": "Vulnerability Analysis",
    "section": "Join vulnerability datasets",
    "text": "Join vulnerability datasets\n\n# List of data frames to join\nvulnerable_data &lt;- list(\n  vulnerable_education,\n  vulnerable_water,\n  vulnerable_electricity,\n  vulnerable_sanitation,\n  vulnerable_building,\n  vulnerable_ssp,\n  vulnerable_financial\n)\n\n# Start with the initial data frame\nfor (df in vulnerable_data) {\n  hh_vulnerable &lt;- hh_vulnerable |&gt; left_join(df, join_by(UID))\n}",
    "crumbs": [
      "Home",
      "Supporting materials",
      "Vulnerability Analysis"
    ]
  },
  {
    "objectID": "supporting-materials/vulnerability.html#exposure-to-extreme-weather-events-and-poverty",
    "href": "supporting-materials/vulnerability.html#exposure-to-extreme-weather-events-and-poverty",
    "title": "Vulnerability Analysis",
    "section": "Exposure to extreme weather events and poverty",
    "text": "Exposure to extreme weather events and poverty\nWe first replicate the paperâs graph regarding exposure at different return periods. Exposure numbers are presented for a range of return periods (from 5 to 100) at one intensity threshold: flood inundation of 15cm, 50cm and 150cm. Exposure falls with the event severity and increases with the return period.The figure shows that, given increasing return periods, exposure will increase more dramatically at a 100 year return period for Tbilisi (88,865 individuals), Imereti (53,027), Samergeolo and Zemo (upper) Svaneti (48,964), and Shida Kartli (36,314).\n\nfloods_all_returns$regions &lt;- factor(\n  floods_all_returns$regions,\n  levels = unique(floods_all_returns$regions)\n)\n\nfloods_all_returns |&gt; \n  filter(rt_period &lt; 200) |&gt; \n  ggplot(aes(\n    x = rt_period, \n    y = exposure, \n    color = regions)) +\n  geom_line(size = 1) +                      # Add lines for each region\n  geom_point(size = 3) +                     # Add points for each region\n  scale_color_manual(\n    values = c(\n      \"yellow\",    \"darkblue\", \"orange\", \n      \"gold\",      \"green\",    \"purple\", \n      \"cyan\",      \"brown\",    \"pink\", \n      \"darkgreen\", \"navy\",     \"red\"\n  )) +                                       # Provide enough colors for all regions\n  labs(\n    title = \"Flood exposure by return period\",\n    subtitle = \"Regions of Georgia\",\n    x = \"Return period (years)\",\n    y = \"Population exposed (individuals)\"\n  ) +\n  theme_minimal() +\n  theme(\n    legend.title = element_blank(),          # Remove legend title\n    legend.position = \"right\"                # Position legend on the right\n  )\n\n\n\n\n\n\n\nFigureÂ 2: Georgia: Flood exposure by return period and region\n\n\n\n\n\n\nExtreme weather and poor by region\nWe now turn to the question of those who are exposed and poor. We use the official poverty line.\n\nexposed_and_poor &lt;- vulnerable_data |&gt;\n  mutate(\n    conspoor = if_else(\n      aecons &lt; pline, \"Below PL\", \"Above PL\"),\n    individuals = weights_exposure * hhsize\n  ) |&gt; \n  group_by(as_factor(RegNo), exposed_to_floods, conspoor) |&gt; \n  summarize(\n    individuals = sum(individuals, na.rm = TRUE)\n  ) |&gt; \n  pivot_wider(\n    id_cols = c(`as_factor(RegNo)`),\n    names_from = c(exposed_to_floods, conspoor),\n    values_from = individuals,\n    names_expand = TRUE\n  ) |&gt; \n  mutate(\n    total_population = rowSums(across(c(1:4)), na.rm = TRUE),\n    total_exposed = rowSums(across(starts_with(\"Exposed_\")), na.rm = T),\n    Pct_exposed_from_total = total_exposed / total_population * 100,\n    Pct_below_from_exposed = `Exposed_Below PL` / total_exposed *100\n  ) |&gt; \n  select(\n    `as_factor(RegNo)`,\n    total_population,\n    total_exposed,\n    `Exposed_Below PL`,\n    starts_with(\"Pct\")\n  )\n\nnames(exposed_and_poor) &lt;- c(\n  \"Regions\",\n  \"Total Population\",\n  \"Total Floods\",\n  \"Exposed Below PL\",\n  \"Pct. Floods from Total\",\n  \"Pct. Below PL from Floods\"\n)\n\nexposed_and_poor |&gt; \n  ungroup() |&gt; \n  gt() |&gt; \n  fmt_number(\n    columns = c(2:4),   # Apply formatting to totals columns\n    decimals = 0,                 # Set no decimals\n    use_seps = TRUE               # Use thousands separator\n  ) |&gt; \n  fmt_number(\n    columns = c(5:6),   # Apply formatting to percent columns\n    decimals = 1                 # Set one decimal\n  )\n\n\n\nTableÂ 2: Number of people exposed to extreme weather and poor\n\n\n\n\n\n\n\n\n\nRegion\nTotal Population\nTotal Floods\nExposed Below PL\nPct. Floods from Total\nPct. Below PL from Floods\n\n\n\n\nKakheti\n307,650\n6,435\n477\n2.1\n7.4\n\n\nTbilisi\n1,206,504\n92,180\n5,067\n7.6\n5.5\n\n\nShida Kartli\n251,397\n35,789\n4,667\n14.2\n13.0\n\n\nKvemo Kartli\n454,698\n22,140\n4,077\n4.9\n18.4\n\n\nSamtskhe-Javakheti\n150,422\n19,075\n2,120\n12.7\n11.1\n\n\nAdjara A.R.\n370,642\n23,388\n3,902\n6.3\n16.7\n\n\nGuria\n104,588\n11,580\n2,932\n11.1\n25.3\n\n\nSamegrelo-Zemo Svaneti\n285,438\n45,639\n7,934\n16.0\n17.4\n\n\nImereti\n459,035\n49,247\n4,905\n10.7\n10.0\n\n\nMtskheta-Mtianeti\n95,389\n9,868\n1,549\n10.3\n15.7\n\n\nRacha-Lechkhumi and Kvemo Svaneti\n28,113\n6,214\n879\n22.1\n14.1\n\n\n\n\n\n\n\n\n\n\nDrought and poor\n\ndrought_and_poor &lt;- vulnerable_data |&gt;\n  mutate(\n    conspoor = if_else(\n      aecons &lt; pline, \"Below PL\", \"Above PL\"),\n    individuals = weights_drought * hhsize\n  ) |&gt; \n  group_by(as_factor(RegNo), exposed_to_drought, conspoor) |&gt; \n  summarize(\n    individuals = sum(individuals, na.rm = TRUE)\n  ) |&gt; \n  pivot_wider(\n    id_cols = c(`as_factor(RegNo)`),\n    names_from = c(exposed_to_drought, conspoor),\n    values_from = individuals,\n    names_expand = TRUE\n  ) |&gt; \n  mutate(\n    total_population = rowSums(across(c(1:4)), na.rm = TRUE),\n    total_exposed = rowSums(across(starts_with(\"Exposed_\")), na.rm = T),\n    Pct_exposed_from_total = total_exposed / total_population * 100,\n    Pct_below_from_exposed = `Exposed_Below PL` / total_exposed *100\n  ) |&gt; \n  select(\n    `as_factor(RegNo)`,\n    total_population,\n    total_exposed,\n    `Exposed_Below PL`,\n    starts_with(\"Pct\")\n  )\n\nnames(drought_and_poor) &lt;- c(\n  \"Regions\",\n  \"Total Population\",\n  \"Total Drought\",\n  \"Drought Below PL\",\n  \"Pct. Drought from Total\",\n  \"Pct. Below PL from Drought\"\n)\n\ndrought_and_poor |&gt; \n  ungroup() |&gt; \n  gt() |&gt; \n  fmt_number(\n    columns = c(2:4),   # Apply formatting to totals columns\n    decimals = 0,                 # Set no decimals\n    use_seps = TRUE               # Use thousands separator\n  ) |&gt; \n  fmt_number(\n    columns = c(5:6),   # Apply formatting to percent columns\n    decimals = 1                 # Set one decimal\n  )\n\n\n\nTableÂ 3: Number of people exposed to drought and poor\n\n\n\n\n\n\n\n\n\nRegion\nTotal Population\nTotal Drought\nDrought Below PL\nPct. Drought from Total\nPct. Below PL from Drought\n\n\n\n\nKakheti\n307,650\n148,926\n11,035\n48.4\n7.4\n\n\nTbilisi\n1,206,504\n85,181\n4,682\n7.1\n5.5\n\n\nShida Kartli\n251,397\n99,230\n12,940\n39.5\n13.0\n\n\nKvemo Kartli\n454,698\n175,783\n32,369\n38.7\n18.4\n\n\nSamtskhe-Javakheti\n150,422\n32,433\n3,605\n21.6\n11.1\n\n\nAdjara A.R.\n370,642\n41,920\n6,994\n11.3\n16.7\n\n\nGuria\n104,588\n318\n80\n0.3\n25.3\n\n\nSamegrelo-Zemo Svaneti\n285,438\n43\n7\n0.0\n17.4\n\n\nImereti\n459,035\n92,952\n9,258\n20.2\n10.0\n\n\nMtskheta-Mtianeti\n95,389\n19,455\n3,053\n20.4\n15.7\n\n\nRacha-Lechkhumi and Kvemo Svaneti\n28,113\n5\n1\n0.0\n14.1\n\n\n\n\n\n\n\n\n\n\nLandslides and poor\n\nlandslides_and_poor &lt;- vulnerable_data |&gt;\n  mutate(\n    conspoor = if_else(\n      aecons &lt; pline, \"Below PL\", \"Above PL\"),\n    individuals = weights_landslides * hhsize\n  ) |&gt; \n  group_by(as_factor(RegNo), exposed_to_landslides, conspoor) |&gt; \n  summarize(\n    individuals = sum(individuals, na.rm = TRUE)\n  ) |&gt; \n  pivot_wider(\n    id_cols = c(`as_factor(RegNo)`),\n    names_from = c(exposed_to_landslides, conspoor),\n    values_from = individuals,\n    names_expand = TRUE\n  ) |&gt; \n  mutate(\n    total_population = rowSums(across(c(1:4)), na.rm = TRUE),\n    total_exposed = rowSums(across(starts_with(\"Exposed_\")), na.rm = T),\n    Pct_exposed_from_total = total_exposed / total_population * 100,\n    Pct_below_from_exposed = `Exposed_Below PL` / total_exposed *100\n  ) |&gt; \n  select(\n    `as_factor(RegNo)`,\n    total_population,\n    total_exposed,\n    `Exposed_Below PL`,\n    starts_with(\"Pct\")\n  )\n\nnames(landslides_and_poor) &lt;- c(\n  \"Regions\",\n  \"Total Population\",\n  \"Total Landslides\",\n  \"Landslides Below PL\",\n  \"Pct. Landslides from Total\",\n  \"Pct. Below PL from Landslides\"\n)\n\nlandslides_and_poor |&gt; \n  ungroup() |&gt; \n  gt() |&gt; \n  fmt_number(\n    columns = c(2:4),   # Apply formatting to totals columns\n    decimals = 0,                 # Set no decimals\n    use_seps = TRUE               # Use thousands separator\n  ) |&gt; \n  fmt_number(\n    columns = c(5:6),   # Apply formatting to percent columns\n    decimals = 1                 # Set one decimal\n  )\n\n\n\nTableÂ 4: Number of people exposed to drought and poor\n\n\n\n\n\n\n\n\n\nRegion\nTotal Population\nTotal Landslides\nLandslides Below PL\nPct. Landslides from Total\nPct. Below PL from Landslides\n\n\n\n\nKakheti\n307,650\n782\n58\n0.3\n7.4\n\n\nTbilisi\n1,206,504\n0\n0\n0.0\nNaN\n\n\nShida Kartli\n251,397\n0\n0\n0.0\nNaN\n\n\nKvemo Kartli\n454,698\n14\n3\n0.0\n18.4\n\n\nSamtskhe-Javakheti\n150,422\n36\n4\n0.0\n11.1\n\n\nAdjara A.R.\n370,642\n4,028\n672\n1.1\n16.7\n\n\nGuria\n104,588\n143\n36\n0.1\n25.3\n\n\nSamegrelo-Zemo Svaneti\n285,438\n2,826\n491\n1.0\n17.4\n\n\nImereti\n459,035\n1,439\n143\n0.3\n10.0\n\n\nMtskheta-Mtianeti\n95,389\n2,255\n354\n2.4\n15.7\n\n\nRacha-Lechkhumi and Kvemo Svaneti\n28,113\n1,039\n147\n3.7\n14.1\n\n\n\n\n\n\n\n\n\n\n\n\nExtreme weather and poor by consumption quintile\nThe paper replicates the table by country income level. Since our tables are at the country level, we could replicate these results by income (consumption) quintile, but as evident below it is a rather uninformative table, because those below poverty belong exclusively to the first quintile, leaving the remaining of the table unpopulated.\n\nexposed_and_poor_q &lt;- vulnerable_data |&gt;\n  mutate(\n    conspoor = if_else(\n      aecons &lt; pline, \"Below PL\", \"Above PL\"),\n    individuals = weights_exposure * hhsize\n  ) |&gt; \n  group_by(quintilc, exposed_to_floods, conspoor) |&gt; \n  summarize(\n    individuals = sum(coalesce(individuals,0), na.rm = TRUE)\n  ) |&gt; \n  pivot_wider(\n    id_cols = c(quintilc),\n    names_from = c(exposed_to_floods, conspoor),\n    values_from = individuals,\n    names_expand = TRUE,\n    values_fill = 0\n  ) |&gt; \n  mutate(\n    total_population = rowSums(across(c(1:4)), na.rm = TRUE),\n    total_exposed = rowSums(across(starts_with(\"Exposed_\")), na.rm = T),\n    Pct_exposed_from_total = total_exposed / total_population * 100,\n    Pct_below_from_exposed = `Exposed_Below PL` / total_exposed *100\n  ) |&gt; \n  select(\n    quintilc,\n    total_population,\n    total_exposed,\n    `Exposed_Below PL`,\n    starts_with(\"Pct\")\n  ) |&gt; \n  ungroup()\n\ncolnames(exposed_and_poor_q) &lt;- c(\n  \"Quintiles\",\n  \"Total Population\",\n  \"Total Floods\",\n  \"Exposed Below PL\",\n  \"Pct. Floods from total\",\n  \"Pct. Below PL from Floods\"\n)\n\nexposed_and_poor_q |&gt; \n  gt() |&gt; \n  fmt_number(\n    columns = c(2:4),   # Apply formatting to totals columns\n    decimals = 0,                 # Set no decimals\n    use_seps = TRUE               # Use thousands separator\n  ) |&gt; \n  fmt_number(\n    columns = c(5:6),   # Apply formatting to percent columns\n    decimals = 1                 # Set one decimal\n  )\n\n\n\nTableÂ 5: Number of people exposed to extreme weather and poor\n\n\n\n\n\n\n\n\n\nQuintiles of aecons\nTotal Population\nTotal Floods\nExposed Below PL\nPct. Floods from total\nPct. Below PL from Floods\n\n\n\n\n1\n676,026\n60,685\n38,508\n9.0\n63.5\n\n\n2\n826,458\n69,537\n0\n8.4\n0.0\n\n\n3\n787,172\n68,020\n0\n8.6\n0.0\n\n\n4\n721,889\n61,521\n0\n8.5\n0.0\n\n\n5\n702,330\n61,793\n0\n8.8\n0.0\n\n\n\n\n\n\n\n\n\n\nDrought\n\ndrought_and_poor_q &lt;- vulnerable_data |&gt;\n  mutate(\n    conspoor = if_else(\n      aecons &lt; pline, \"Below PL\", \"Above PL\"),\n    individuals = weights_drought * hhsize\n  ) |&gt; \n  group_by(quintilc, exposed_to_drought, conspoor) |&gt; \n  summarize(\n    individuals = sum(coalesce(individuals,0), na.rm = TRUE)\n  ) |&gt; \n  pivot_wider(\n    id_cols = c(quintilc),\n    names_from = c(exposed_to_drought, conspoor),\n    values_from = individuals,\n    names_expand = TRUE,\n    values_fill = 0\n  ) |&gt; \n  mutate(\n    total_population = rowSums(across(c(1:4)), na.rm = TRUE),\n    total_exposed = rowSums(across(starts_with(\"Exposed_\")), na.rm = T),\n    Pct_exposed_from_total = total_exposed / total_population * 100,\n    Pct_below_from_exposed = `Exposed_Below PL` / total_exposed *100\n  ) |&gt; \n  select(\n    quintilc,\n    total_population,\n    total_exposed,\n    `Exposed_Below PL`,\n    starts_with(\"Pct\")\n  ) |&gt; \n  ungroup()\n\n`summarise()` has grouped output by 'quintilc', 'exposed_to_drought'. You can\noverride using the `.groups` argument.\n\ncolnames(drought_and_poor_q) &lt;- c(\n  \"Quintiles\",\n  \"Total Population\",\n  \"Total Drought\",\n  \"Drought Below PL\",\n  \"Pct. Drought from Total\",\n  \"Pct. Below PL from Drought\"\n)\n\ndrought_and_poor_q |&gt; \n  gt() |&gt; \n  fmt_number(\n    columns = c(2:4),   # Apply formatting to totals columns\n    decimals = 0,                 # Set no decimals\n    use_seps = TRUE               # Use thousands separator\n  ) |&gt; \n  fmt_number(\n    columns = c(5:6),   # Apply formatting to percent columns\n    decimals = 1                 # Set one decimal\n  )\n\n\n\n\n\n\n\nQuintiles of aecons\nTotal Population\nTotal Drought\nDrought Below PL\nPct. Drought from Total\nPct. Below PL from Drought\n\n\n\n\n1\n676,026\n129,008\n84,025\n19.1\n65.1\n\n\n2\n826,458\n156,462\n0\n18.9\n0.0\n\n\n3\n787,172\n144,192\n0\n18.3\n0.0\n\n\n4\n721,889\n134,756\n0\n18.7\n0.0\n\n\n5\n702,330\n131,828\n0\n18.8\n0.0\n\n\n\n\n\n\n\nLandslides\n\nlandslides_and_poor_q &lt;- vulnerable_data |&gt;\n  mutate(\n    conspoor = if_else(\n      aecons &lt; pline, \"Below PL\", \"Above PL\"),\n    individuals = weights_landslides * hhsize\n  ) |&gt; \n  group_by(quintilc, exposed_to_landslides, conspoor) |&gt; \n  summarize(\n    individuals = sum(coalesce(individuals,0), na.rm = TRUE)\n  ) |&gt; \n  pivot_wider(\n    id_cols = c(quintilc),\n    names_from = c(exposed_to_landslides, conspoor),\n    values_from = individuals,\n    names_expand = TRUE,\n    values_fill = 0\n  ) |&gt; \n  mutate(\n    total_population = rowSums(across(c(1:4)), na.rm = TRUE),\n    total_exposed = rowSums(across(starts_with(\"Exposed_\")), na.rm = T),\n    Pct_exposed_from_total = total_exposed / total_population * 100,\n    Pct_below_from_exposed = `Exposed_Below PL` / total_exposed *100\n  ) |&gt; \n  select(\n    quintilc,\n    total_population,\n    total_exposed,\n    `Exposed_Below PL`,\n    starts_with(\"Pct\")\n  ) |&gt; \n  ungroup()\n\n`summarise()` has grouped output by 'quintilc', 'exposed_to_landslides'. You\ncan override using the `.groups` argument.\n\ncolnames(drought_and_poor_q) &lt;- c(\n  \"Quintiles\",\n  \"Total Population\",\n  \"Total Landslides\",\n  \"Landslides Below PL\",\n  \"Pct. Landslides from Total\",\n  \"Pct. Below PL from Landslides\"\n)\n\ndrought_and_poor_q |&gt; \n  gt() |&gt; \n  fmt_number(\n    columns = c(2:4),   # Apply formatting to totals columns\n    decimals = 0,                 # Set no decimals\n    use_seps = TRUE               # Use thousands separator\n  ) |&gt; \n  fmt_number(\n    columns = c(5:6),   # Apply formatting to percent columns\n    decimals = 1                 # Set one decimal\n  )\n\n\n\n\n\n\n\nQuintiles of aecons\nTotal Population\nTotal Landslides\nLandslides Below PL\nPct. Landslides from Total\nPct. Below PL from Landslides\n\n\n\n\n1\n676,026\n129,008\n84,025\n19.1\n65.1\n\n\n2\n826,458\n156,462\n0\n18.9\n0.0\n\n\n3\n787,172\n144,192\n0\n18.3\n0.0\n\n\n4\n721,889\n134,756\n0\n18.7\n0.0\n\n\n5\n702,330\n131,828\n0\n18.8\n0.0",
    "crumbs": [
      "Home",
      "Supporting materials",
      "Vulnerability Analysis"
    ]
  },
  {
    "objectID": "supporting-materials/vulnerability.html#at-risk-from-extreme-weather-events",
    "href": "supporting-materials/vulnerability.html#at-risk-from-extreme-weather-events",
    "title": "Vulnerability Analysis",
    "section": "At risk from extreme weather events",
    "text": "At risk from extreme weather events\n\nNumber of people exposed and vulnerable in each indicator\nâFor these same events and risk thresholds, we consider the share of households that are exposed and highly vulnerable. Being highly vulnerable is defined as failing to reach the threshold in or lacking access to one or more dimensions (e.g., lacking access to electricity or coverage by social protection or having an insufficient income).â (Doan et al. 2023)\nFloods\n\nat_risk_floods &lt;- vulnerable_data |&gt;\n  mutate(\n    conspoor = if_else(\n      aecons &lt; pline, \"Below PL\", \"Above PL\"),\n    individuals = weights_exposure * hhsize,\n    risk_income = individuals * vulnerability_income,\n    risk_education = individuals * vulnerability_education,\n    risk_water = individuals * vulnerability_water,\n    # risk_electricity = individuals * vulnerability_electricity, # 100% in GEO\n    risk_sanitation = individuals * vulnerability_sanitation,\n    risk_building = individuals * vulnerability_building,\n    risk_ssp = individuals * vulnerability_ssp,\n    risk_financial = individuals * vulnerability_financial\n  ) |&gt; \n  group_by(as_factor(RegNo), exposed_to_floods) |&gt; \n  summarize(\n    Individuals = sum(individuals, na.rm = T),\n    Income = sum(risk_income, na.rm = T),\n    Education = sum(risk_education, na.rm = T),\n    Water = sum(risk_water, na.rm = T),\n    # Electricity = sum(risk_income, na.rm = T),\n    Sanitation = sum(risk_sanitation, na.rm = T),\n    Buildings = sum(risk_building, na.rm = T),\n    SSP = sum(risk_ssp, na.rm = T),\n    Financial = sum(risk_financial, na.rm = T)\n  ) |&gt; \n  pivot_wider(\n    id_cols = c(`as_factor(RegNo)`),\n    names_from = c(exposed_to_floods),\n    values_from = c(\n      Individuals,\n      Income,\n      Education,\n      Water,\n      # Electricity,\n      Sanitation,\n      Buildings,\n      SSP,\n      Financial),\n    names_expand = TRUE\n  ) |&gt; \n  mutate(\n    total_population = rowSums(across(starts_with(\"Individuals_\")), na.rm = TRUE),\n  ) |&gt; \n  select(\n    `as_factor(RegNo)`,\n    total_population,\n    ends_with(\"_Exposed\")\n  ) |&gt; \n  ungroup()\n\nnames(at_risk_floods) &lt;- c(\n  \"Regions\",\n  \"Total Population\",\n  \"Total Floods\",\n  \"Income\",\n  \"Education\",\n  \"Water\",\n  \"Sanitation\",\n  \"Buildings\",\n  \"Social Protection\",\n  \"Financial inclusion\"\n)\n\nat_risk_floods |&gt; \n  ungroup() |&gt; \n  gt() |&gt; \n  fmt_number(\n    columns = where(is.numeric),   # Apply formatting to totals columns\n    decimals = 0,                 # Set no decimals\n    use_seps = TRUE               # Use thousands separator\n  )\n# write.table(at_risk, \"clipboard\", sep = \"\\t\", row.names = F)\n\n\n\nTableÂ 6: Number of people exposed and vulnerable by region\n\n\n\n\n\n\n\n\n\nRegion\nTotal Population\nTotal Floods\nIncome\nEducation\nWater\nSanitation\nBuildings\nSocial Protection\nFinancial inclusion\n\n\n\n\nKakheti\n307,650\n6,435\n1,462\n0\n1,344\n5,500\n0\n5,562\n3,816\n\n\nTbilisi\n1,206,504\n92,180\n22,275\n0\n0\n351\n417\n78,230\n61,190\n\n\nShida Kartli\n251,397\n35,789\n10,725\n51\n9,154\n19,837\n480\n29,582\n19,092\n\n\nKvemo Kartli\n454,698\n22,140\n9,866\n187\n1,608\n12,548\n895\n17,200\n16,079\n\n\nSamtskhe-Javakheti\n150,422\n19,075\n4,545\n0\n527\n10,792\n711\n17,322\n8,935\n\n\nAdjara A.R.\n370,642\n23,388\n9,368\n0\n3,601\n8,754\n3,259\n19,401\n11,569\n\n\nGuria\n104,588\n11,580\n6,547\n0\n4,836\n8,391\n4,119\n9,425\n7,691\n\n\nSamegrelo-Zemo Svaneti\n285,438\n45,639\n17,925\n0\n25,669\n34,630\n10,065\n37,740\n30,110\n\n\nImereti\n459,035\n49,247\n10,541\n0\n14,325\n24,106\n2,647\n38,173\n23,016\n\n\nMtskheta-Mtianeti\n95,389\n9,868\n3,945\n11\n424\n5,634\n22\n8,680\n6,632\n\n\nRacha-Lechkhumi and Kvemo Svaneti\n28,113\n6,214\n1,757\n0\n573\n3,726\n1,785\n3,385\n3,486\n\n\n\n\n\n\n\n\n\n\nDrought\n\nat_risk_drought &lt;- vulnerable_data |&gt;\n  mutate(\n    conspoor = if_else(\n      aecons &lt; pline, \"Below PL\", \"Above PL\"),\n    individuals = weights_drought * hhsize,\n    risk_income = individuals * vulnerability_income,\n    risk_education = individuals * vulnerability_education,\n    risk_water = individuals * vulnerability_water,\n    # risk_electricity = individuals * vulnerability_electricity, # 100% in GEO\n    risk_sanitation = individuals * vulnerability_sanitation,\n    risk_building = individuals * vulnerability_building,\n    risk_ssp = individuals * vulnerability_ssp,\n    risk_financial = individuals * vulnerability_financial\n  ) |&gt; \n  group_by(as_factor(RegNo), exposed_to_drought) |&gt; \n  summarize(\n    Individuals = sum(individuals, na.rm = T),\n    Income = sum(risk_income, na.rm = T),\n    Education = sum(risk_education, na.rm = T),\n    Water = sum(risk_water, na.rm = T),\n    # Electricity = sum(risk_income, na.rm = T),\n    Sanitation = sum(risk_sanitation, na.rm = T),\n    Buildings = sum(risk_building, na.rm = T),\n    SSP = sum(risk_ssp, na.rm = T),\n    Financial = sum(risk_financial, na.rm = T)\n  ) |&gt; \n  pivot_wider(\n    id_cols = c(`as_factor(RegNo)`),\n    names_from = c(exposed_to_drought),\n    values_from = c(\n      Individuals,\n      Income,\n      Education,\n      Water,\n      # Electricity,\n      Sanitation,\n      Buildings,\n      SSP,\n      Financial),\n    names_expand = TRUE\n  ) |&gt; \n  mutate(\n    total_population = rowSums(across(starts_with(\"Individuals_\")), na.rm = TRUE),\n  ) |&gt; \n  select(\n    `as_factor(RegNo)`,\n    total_population,\n    ends_with(\"_Exposed\")\n  ) |&gt; \n  ungroup()\n\n`summarise()` has grouped output by 'as_factor(RegNo)'. You can override using\nthe `.groups` argument.\n\nnames(at_risk_drought) &lt;- c(\n  \"Regions\",\n  \"Total Population\",\n  \"Total Drought\",\n  \"Income\",\n  \"Education\",\n  \"Water\",\n  \"Sanitation\",\n  \"Buildings\",\n  \"Social Protection\",\n  \"Financial inclusion\"\n)\n\nat_risk_drought |&gt; \n  ungroup() |&gt; \n  gt() |&gt; \n  fmt_number(\n    columns = where(is.numeric),   # Apply formatting to totals columns\n    decimals = 0,                 # Set no decimals\n    use_seps = TRUE               # Use thousands separator\n  )\n\n\n\n\n\n\n\nRegion\nTotal Population\nTotal Drought\nIncome\nEducation\nWater\nSanitation\nBuildings\nSocial Protection\nFinancial inclusion\n\n\n\n\nKakheti\n307,650\n148,926\n33,825\n0\n31,111\n127,294\n0\n128,720\n88,308\n\n\nTbilisi\n1,206,504\n85,181\n20,584\n0\n0\n324\n385\n72,290\n56,544\n\n\nShida Kartli\n251,397\n99,230\n29,736\n142\n25,381\n55,000\n1,331\n82,020\n52,935\n\n\nKvemo Kartli\n454,698\n175,783\n78,332\n1,485\n12,769\n99,624\n7,102\n136,561\n127,666\n\n\nSamtskhe-Javakheti\n150,422\n32,433\n7,728\n0\n897\n18,350\n1,210\n29,452\n15,191\n\n\nAdjara A.R.\n370,642\n41,920\n16,791\n0\n6,455\n15,691\n5,841\n34,774\n20,735\n\n\nGuria\n104,588\n318\n180\n0\n133\n230\n113\n258\n211\n\n\nSamegrelo-Zemo Svaneti\n285,438\n43\n17\n0\n24\n32\n9\n35\n28\n\n\nImereti\n459,035\n92,952\n19,895\n0\n27,039\n45,499\n4,997\n72,050\n43,442\n\n\nMtskheta-Mtianeti\n95,389\n19,455\n7,778\n21\n836\n11,108\n44\n17,113\n13,075\n\n\nRacha-Lechkhumi and Kvemo Svaneti\n28,113\n5\n1\n0\n0\n3\n2\n3\n3\n\n\n\n\n\n\n\nLandslides\n\nat_risk_landslides &lt;- vulnerable_data |&gt;\n  mutate(\n    conspoor = if_else(\n      aecons &lt; pline, \"Below PL\", \"Above PL\"),\n    individuals = weights_landslides * hhsize,\n    risk_income = individuals * vulnerability_income,\n    risk_education = individuals * vulnerability_education,\n    risk_water = individuals * vulnerability_water,\n    # risk_electricity = individuals * vulnerability_electricity, # 100% in GEO\n    risk_sanitation = individuals * vulnerability_sanitation,\n    risk_building = individuals * vulnerability_building,\n    risk_ssp = individuals * vulnerability_ssp,\n    risk_financial = individuals * vulnerability_financial\n  ) |&gt; \n  group_by(as_factor(RegNo), exposed_to_landslides) |&gt; \n  summarize(\n    Individuals = sum(individuals, na.rm = T),\n    Income = sum(risk_income, na.rm = T),\n    Education = sum(risk_education, na.rm = T),\n    Water = sum(risk_water, na.rm = T),\n    # Electricity = sum(risk_income, na.rm = T),\n    Sanitation = sum(risk_sanitation, na.rm = T),\n    Buildings = sum(risk_building, na.rm = T),\n    SSP = sum(risk_ssp, na.rm = T),\n    Financial = sum(risk_financial, na.rm = T)\n  ) |&gt; \n  pivot_wider(\n    id_cols = c(`as_factor(RegNo)`),\n    names_from = c(exposed_to_landslides),\n    values_from = c(\n      Individuals,\n      Income,\n      Education,\n      Water,\n      # Electricity,\n      Sanitation,\n      Buildings,\n      SSP,\n      Financial),\n    names_expand = TRUE\n  ) |&gt; \n  mutate(\n    total_population = rowSums(across(starts_with(\"Individuals_\")), na.rm = TRUE),\n  ) |&gt; \n  select(\n    `as_factor(RegNo)`,\n    total_population,\n    ends_with(\"_Exposed\")\n  ) |&gt; \n  ungroup()\n\n`summarise()` has grouped output by 'as_factor(RegNo)'. You can override using\nthe `.groups` argument.\n\nnames(at_risk_landslides) &lt;- c(\n  \"Regions\",\n  \"Total Population\",\n  \"Total Landslides\",\n  \"Income\",\n  \"Education\",\n  \"Water\",\n  \"Sanitation\",\n  \"Buildings\",\n  \"Social Protection\",\n  \"Financial inclusion\"\n)\n\nat_risk_landslides |&gt; \n  ungroup() |&gt; \n  gt() |&gt; \n  fmt_number(\n    columns = where(is.numeric),   # Apply formatting to totals columns\n    decimals = 0,                 # Set no decimals\n    use_seps = TRUE               # Use thousands separator\n  )\n\n\n\n\n\n\n\nRegion\nTotal Population\nTotal Landslides\nIncome\nEducation\nWater\nSanitation\nBuildings\nSocial Protection\nFinancial inclusion\n\n\n\n\nKakheti\n307,650\n782\n178\n0\n163\n669\n0\n676\n464\n\n\nTbilisi\n1,206,504\n0\n0\n0\n0\n0\n0\n0\n0\n\n\nShida Kartli\n251,397\n0\n0\n0\n0\n0\n0\n0\n0\n\n\nKvemo Kartli\n454,698\n14\n6\n0\n1\n8\n1\n11\n10\n\n\nSamtskhe-Javakheti\n150,422\n36\n9\n0\n1\n21\n1\n33\n17\n\n\nAdjara A.R.\n370,642\n4,028\n1,613\n0\n620\n1,508\n561\n3,341\n1,992\n\n\nGuria\n104,588\n143\n81\n0\n60\n104\n51\n117\n95\n\n\nSamegrelo-Zemo Svaneti\n285,438\n2,826\n1,110\n0\n1,590\n2,145\n623\n2,337\n1,865\n\n\nImereti\n459,035\n1,439\n308\n0\n419\n704\n77\n1,116\n673\n\n\nMtskheta-Mtianeti\n95,389\n2,255\n902\n2\n97\n1,287\n5\n1,983\n1,515\n\n\nRacha-Lechkhumi and Kvemo Svaneti\n28,113\n1,039\n294\n0\n96\n623\n298\n566\n583\n\n\n\n\n\n\n\n\n\nNumber of people highly vulnerable on multiple dimensions\n\nat_risk_dimensions_floods &lt;- vulnerable_data |&gt;\n  mutate(\n    individuals = weights_exposure * hhsize,\n    number_of_dimensions = rowSums(across(starts_with(\"vulnerability_\")))\n    ) |&gt; \n  group_by(\n    as_factor(RegNo), \n    exposed_to_floods, \n    number_of_dimensions) |&gt; \n  summarize(\n    Individuals = sum(individuals, na.rm = T),\n  ) |&gt; \n  pivot_wider(\n    id_cols = c(`as_factor(RegNo)`),\n    names_from = c(exposed_to_floods, number_of_dimensions),\n    values_from = c(\n      Individuals),\n    names_expand = TRUE,\n    values_fill = 0\n  ) |&gt; \n  mutate(\n    total_population = rowSums(across(where(is.numeric)), na.rm = TRUE),\n    total_exposed = rowSums(across(starts_with(\"Exposed_\")), na.rm = TRUE)\n  ) |&gt; \n  select(\n    `as_factor(RegNo)`,\n    total_population,\n    total_exposed,\n    starts_with(\"Exposed_\")\n  ) |&gt; \n  ungroup()\n\nnames(at_risk_dimensions_floods) &lt;- c(\n  \"Regions\",\n  \"Total Population\",\n  \"Total Floods\",\n  \"0 dimensions\",\n  \"1 dimension\",\n  \"2 dimensions\",\n  \"3 dimensions\",\n  \"4 dimensions\",\n  \"5 dimensions\",\n  \"6 dimensions\"\n)\n\nat_risk_dimensions_floods |&gt; \n  gt() |&gt; \n  fmt_number(\n    columns = where(is.numeric),   # Apply formatting to totals columns\n    decimals = 0,                 # Set no decimals\n    use_seps = TRUE               # Use thousands separator\n  )\n# write.table(at_risk_dimensions, \"clipboard\", sep = \"\\t\", row.names = F)\n\n\n\nTableÂ 7: Number of people highly vulnerable on multiple dimensions\n\n\n\n\n\n\n\n\n\nRegion\nTotal Population\nTotal Floods\n0 dimensions\n1 dimension\n2 dimensions\n3 dimensions\n4 dimensions\n5 dimensions\n6 dimensions\n\n\n\n\nKakheti\n307,650\n6,435\n0\n555\n1,926\n2,593\n1,306\n55\n0\n\n\nTbilisi\n1,206,504\n92,180\n2,088\n28,552\n50,877\n10,496\n167\n0\n0\n\n\nShida Kartli\n251,397\n35,789\n50\n7,054\n10,963\n12,153\n4,393\n1,152\n26\n\n\nKvemo Kartli\n454,698\n22,140\n155\n3,449\n6,095\n7,320\n4,821\n300\n0\n\n\nSamtskhe-Javakheti\n150,422\n19,075\n0\n2,960\n9,497\n5,687\n836\n94\n0\n\n\nAdjara A.R.\n370,642\n23,388\n123\n5,746\n8,252\n5,136\n2,584\n1,322\n224\n\n\nGuria\n104,588\n11,580\n15\n632\n2,365\n2,105\n3,469\n2,511\n484\n\n\nSamegrelo-Zemo Svaneti\n285,438\n45,639\n0\n3,506\n8,984\n9,278\n13,657\n9,083\n1,132\n\n\nImereti\n459,035\n49,247\n1,871\n13,060\n13,742\n11,645\n7,315\n1,614\n0\n\n\nMtskheta-Mtianeti\n95,389\n9,868\n102\n1,853\n2,374\n3,657\n1,631\n250\n0\n\n\nRacha-Lechkhumi and Kvemo Svaneti\n28,113\n6,214\n189\n1,398\n1,981\n1,621\n719\n220\n86\n\n\n\n\n\n\n\n\n\n\nDrought\n\nat_risk_dimensions_drought &lt;- vulnerable_data |&gt;\n  mutate(\n    individuals = weights_drought * hhsize,\n    number_of_dimensions = rowSums(across(starts_with(\"vulnerability_\")))\n    ) |&gt; \n  group_by(\n    as_factor(RegNo), \n    exposed_to_drought, \n    number_of_dimensions) |&gt; \n  summarize(\n    Individuals = sum(individuals, na.rm = T),\n  ) |&gt; \n  pivot_wider(\n    id_cols = c(`as_factor(RegNo)`),\n    names_from = c(exposed_to_drought, number_of_dimensions),\n    values_from = c(\n      Individuals),\n    names_expand = TRUE,\n    values_fill = 0\n  ) |&gt; \n  mutate(\n    total_population = rowSums(across(where(is.numeric)), na.rm = TRUE),\n    total_exposed = rowSums(across(starts_with(\"Exposed_\")), na.rm = TRUE)\n  ) |&gt; \n  select(\n    `as_factor(RegNo)`,\n    total_population,\n    total_exposed,\n    starts_with(\"Exposed_\")\n  ) |&gt; \n  ungroup()\n\n`summarise()` has grouped output by 'as_factor(RegNo)', 'exposed_to_drought'.\nYou can override using the `.groups` argument.\n\nnames(at_risk_dimensions_drought) &lt;- c(\n  \"Regions\",\n  \"Total Population\",\n  \"Total Drought\",\n  \"0 dimensions\",\n  \"1 dimension\",\n  \"2 dimensions\",\n  \"3 dimensions\",\n  \"4 dimensions\",\n  \"5 dimensions\",\n  \"6 dimensions\"\n)\n\nat_risk_dimensions_drought |&gt; \n  gt() |&gt; \n  fmt_number(\n    columns = where(is.numeric),   # Apply formatting to totals columns\n    decimals = 0,                 # Set no decimals\n    use_seps = TRUE               # Use thousands separator\n  )\n\n\n\n\n\n\n\nRegion\nTotal Population\nTotal Drought\n0 dimensions\n1 dimension\n2 dimensions\n3 dimensions\n4 dimensions\n5 dimensions\n6 dimensions\n\n\n\n\nKakheti\n307,650\n148,926\n0\n12,851\n44,570\n60,019\n30,226\n1,262\n0\n\n\nTbilisi\n1,206,504\n85,181\n1,929\n26,385\n47,014\n9,699\n154\n0\n0\n\n\nShida Kartli\n251,397\n99,230\n138\n19,557\n30,397\n33,694\n12,179\n3,194\n71\n\n\nKvemo Kartli\n454,698\n175,783\n1,229\n27,385\n48,392\n58,120\n38,275\n2,382\n0\n\n\nSamtskhe-Javakheti\n150,422\n32,433\n0\n5,033\n16,148\n9,670\n1,422\n160\n0\n\n\nAdjara A.R.\n370,642\n41,920\n220\n10,299\n14,791\n9,206\n4,632\n2,370\n402\n\n\nGuria\n104,588\n318\n0\n17\n65\n58\n95\n69\n13\n\n\nSamegrelo-Zemo Svaneti\n285,438\n43\n0\n3\n8\n9\n13\n8\n1\n\n\nImereti\n459,035\n92,952\n3,532\n24,651\n25,937\n21,979\n13,806\n3,047\n0\n\n\nMtskheta-Mtianeti\n95,389\n19,455\n201\n3,654\n4,681\n7,211\n3,216\n493\n0\n\n\nRacha-Lechkhumi and Kvemo Svaneti\n28,113\n5\n0\n1\n2\n1\n1\n0\n0\n\n\n\n\n\n\n\nLandslides\n\nat_risk_dimensions_landslides &lt;- vulnerable_data |&gt;\n  mutate(\n    individuals = weights_landslides * hhsize,\n    number_of_dimensions = rowSums(across(starts_with(\"vulnerability_\")))\n    ) |&gt; \n  group_by(\n    as_factor(RegNo), \n    exposed_to_landslides, \n    number_of_dimensions) |&gt; \n  summarize(\n    Individuals = sum(individuals, na.rm = T),\n  ) |&gt; \n  pivot_wider(\n    id_cols = c(`as_factor(RegNo)`),\n    names_from = c(exposed_to_landslides, number_of_dimensions),\n    values_from = c(\n      Individuals),\n    names_expand = TRUE,\n    values_fill = 0\n  ) |&gt; \n  mutate(\n    total_population = rowSums(across(where(is.numeric)), na.rm = TRUE),\n    total_exposed = rowSums(across(starts_with(\"Exposed_\")), na.rm = TRUE)\n  ) |&gt; \n  select(\n    `as_factor(RegNo)`,\n    total_population,\n    total_exposed,\n    starts_with(\"Exposed_\")\n  ) |&gt; \n  ungroup()\n\n`summarise()` has grouped output by 'as_factor(RegNo)',\n'exposed_to_landslides'. You can override using the `.groups` argument.\n\nnames(at_risk_dimensions_landslides) &lt;- c(\n  \"Regions\",\n  \"Total Population\",\n  \"Total Landslides\",\n  \"0 dimensions\",\n  \"1 dimension\",\n  \"2 dimensions\",\n  \"3 dimensions\",\n  \"4 dimensions\",\n  \"5 dimensions\",\n  \"6 dimensions\"\n)\n\nat_risk_dimensions_landslides |&gt; \n  gt() |&gt; \n  fmt_number(\n    columns = where(is.numeric),   # Apply formatting to totals columns\n    decimals = 0,                 # Set no decimals\n    use_seps = TRUE               # Use thousands separator\n  )\n\n\n\n\n\n\n\nRegion\nTotal Population\nTotal Landslides\n0 dimensions\n1 dimension\n2 dimensions\n3 dimensions\n4 dimensions\n5 dimensions\n6 dimensions\n\n\n\n\nKakheti\n307,650\n782\n0\n68\n234\n315\n159\n7\n0\n\n\nTbilisi\n1,206,504\n0\n0\n0\n0\n0\n0\n0\n0\n\n\nShida Kartli\n251,397\n0\n0\n0\n0\n0\n0\n0\n0\n\n\nKvemo Kartli\n454,698\n14\n0\n2\n4\n5\n3\n0\n0\n\n\nSamtskhe-Javakheti\n150,422\n36\n0\n6\n18\n11\n2\n0\n0\n\n\nAdjara A.R.\n370,642\n4,028\n21\n990\n1,421\n884\n445\n228\n39\n\n\nGuria\n104,588\n143\n0\n8\n29\n26\n43\n31\n6\n\n\nSamegrelo-Zemo Svaneti\n285,438\n2,826\n0\n217\n556\n575\n846\n562\n70\n\n\nImereti\n459,035\n1,439\n55\n382\n402\n340\n214\n47\n0\n\n\nMtskheta-Mtianeti\n95,389\n2,255\n23\n423\n543\n836\n373\n57\n0\n\n\nRacha-Lechkhumi and Kvemo Svaneti\n28,113\n1,039\n32\n234\n331\n271\n120\n37\n14\n\n\n\n\n\n\n\n\n\nTraditionally vulnerable groups\nFloods\n\ntraditionally_vulnerable &lt;- vulnerable_data |&gt;\n  mutate(\n    all_members = weights_exposure * hhsize,\n    children = weights_exposure * Childern,\n    youth = weights_exposure * Adult,\n    women = weights_exposure * Working_age_Woman,\n    men = weights_exposure * Working_age_man,\n    elderly = weights_exposure *\n      (Pensioner_age_man + Pensioner_age_Woman)\n  ) |&gt;\n  select(\n    UID,\n    RegNo,\n    type,\n    # all_members,\n    children,\n    youth,\n    women,\n    elderly,\n    men,\n    vulnerability_income,\n    vulnerability_education,\n    vulnerability_water,\n    vulnerability_sanitation,\n    vulnerability_building,\n    vulnerability_ssp,\n    vulnerability_financial,\n    exposed_to_floods\n  ) |&gt;\n  pivot_longer(\n    cols = starts_with(\"vulnerability_\"),\n    names_to = \"vulnerability_type\",\n    names_prefix = \"vulnerability_\",\n    values_to = \"is_vulnerable\"\n  ) |&gt;\n  pivot_longer(\n    cols = c(children, youth, women, elderly, men),\n    names_to = \"vulnerable_group\",\n    values_to = \"no_vulnerable_people\"\n  ) |&gt;\n  filter(is_vulnerable == 1, exposed_to_floods == \"Exposed\") |&gt;\n  mutate(\n    vulnerability_type = factor(\n      vulnerability_type,\n      levels = c(\n        \"income\",\n        \"education\",\n        \"water\",\n        \"sanitation\",\n        \"building\",\n        \"ssp\",\n        \"financial\"\n      )\n    ),\n    vulnerable_group = factor(\n      vulnerable_group,\n      levels = c(\n        \"children\", \"youth\", \n        \"women\", \"elderly\", \"men\"),\n      # labels(\n      #   \"Children\", \"Youth\", \n      #   \"Women\", \"Elderly\", \"Men\"\n      # )\n    )\n  )\n\ntraditionally_vulnerable_area &lt;- traditionally_vulnerable |&gt; \n  group_by(\n    as_factor(type),\n    vulnerability_type,\n    vulnerable_group\n  ) |&gt; \n  summarize(\n    value = sum(no_vulnerable_people, na.rm = T)\n  ) |&gt; \n  pivot_wider(\n    id_cols = c(\n      `as_factor(type)`,\n      vulnerable_group\n    ),\n    names_from = vulnerability_type,\n    values_from = value,\n    names_expand = T,\n    values_fill = 0\n  ) \n\ncolnames(traditionally_vulnerable_area) &lt;- c(\n  \"Area\", \"Group\", \"Income\",\n  \"Education\", \"Water\", \"Sanitation\",\n  \"Building\", \"Social Protection\", \"Financial\"\n)\n\ntraditionally_vulnerable_area |&gt; \n  # ungroup() |&gt;\n  gt() |&gt; \n  summary_rows(\n    groups = everything(),\n    columns = c(\n      \"Income\", \"Education\", \n      \"Water\", \"Sanitation\",\n      \"Building\", \"Social Protection\", \n      \"Financial\"),\n    fns = list(label = \"Subtotal\", id = \"subtotals\", fn = \"sum\")\n  ) |&gt; \n  grand_summary_rows(\n    columns = c(\n      \"Income\", \"Education\", \n      \"Water\", \"Sanitation\",\n      \"Building\", \"Social Protection\", \n      \"Financial\"),\n    fns = list(label = \"Total\", id = \"totals\", fn = \"sum\")\n  )\n# names(exposed_and_poor) &lt;- c(\n#   \"Regions\",\n#   \"Total Population\",\n#   \"Total Exposed\",\n#   \"Exposed Below PL\",\n#   \"Pct. exposed from total\",\n#   \"Pct. Below PL from exposed\"\n# )\n# write.table((traditionally_vulnerable_rural), \"clipboard\", sep = \"\\t\", row.names = F)\n# writeClipboard(as_raw_html(traditionally_vulnerable_rural))\n\n\n\nTableÂ 8: Number of people at risk from traditionally vulnerable groups\n\n\n\n\n\n\n\n\n\n\nGroup\nIncome\nEducation\nWater\nSanitation\nBuilding\nSocial Protection\nFinancial\n\n\n\n\nUrban\n\n\n\nchildren\n4973.215\n0.00000\n106.2592\n1183.134\n578.8928\n13823.046\n8414.002\n\n\n\nyouth\n7147.863\n0.00000\n370.4468\n1707.531\n673.8152\n16043.521\n12074.951\n\n\n\nwomen\n13803.958\n0.00000\n568.3721\n4296.589\n1797.5706\n46870.276\n31181.670\n\n\n\nelderly\n8786.141\n0.00000\n570.9228\n4411.369\n1418.4736\n38762.553\n27757.956\n\n\n\nmen\n14071.600\n0.00000\n710.6323\n4314.826\n1803.9962\n48231.634\n29708.787\n\n\nSubtotal\nâ\n48782.78\n0.0000\n2326.633\n15913.45\n6272.748\n163731.0\n109137.37\n\n\nRural\n\n\n\nchildren\n4875.646\n0.00000\n4896.4696\n9576.187\n1314.2184\n7267.694\n6394.284\n\n\n\nyouth\n6146.748\n79.88596\n6178.4539\n12265.521\n1332.9164\n8504.401\n7240.389\n\n\n\nwomen\n13186.474\n53.25730\n14062.3933\n28752.102\n4195.1169\n24259.520\n19368.964\n\n\n\nelderly\n10118.454\n89.25736\n16705.5469\n31258.916\n5857.1767\n29150.273\n23982.255\n\n\n\nmen\n15846.988\n26.62865\n17892.7140\n36503.605\n5428.6156\n31787.209\n25491.481\n\n\nSubtotal\nâ\n50174.31\n249.0293\n59735.578\n118356.33\n18128.044\n100969.1\n82477.37\n\n\nTotal\nâ\n98957.09\n249.0293\n62062.21\n134269.8\n24400.79\n264700.1\n191614.7\n\n\n\n\n\n\n\n\n\n\nDrought\n\ntraditionally_vulnerable_drought &lt;- vulnerable_data |&gt;\n  mutate(\n    all_members = weights_drought * hhsize,\n    children = weights_drought * Childern,\n    youth = weights_drought * Adult,\n    women = weights_drought * Working_age_Woman,\n    men = weights_drought * Working_age_man,\n    elderly = weights_drought *\n      (Pensioner_age_man + Pensioner_age_Woman)\n  ) |&gt;\n  select(\n    UID,\n    RegNo,\n    type,\n    # all_members,\n    children,\n    youth,\n    women,\n    elderly,\n    men,\n    vulnerability_income,\n    vulnerability_education,\n    vulnerability_water,\n    vulnerability_sanitation,\n    vulnerability_building,\n    vulnerability_ssp,\n    vulnerability_financial,\n    exposed_to_drought\n  ) |&gt;\n  pivot_longer(\n    cols = starts_with(\"vulnerability_\"),\n    names_to = \"vulnerability_type\",\n    names_prefix = \"vulnerability_\",\n    values_to = \"is_vulnerable\"\n  ) |&gt;\n  pivot_longer(\n    cols = c(children, youth, women, elderly, men),\n    names_to = \"vulnerable_group\",\n    values_to = \"no_vulnerable_people\"\n  ) |&gt;\n  filter(is_vulnerable == 1, exposed_to_drought == \"Exposed\") |&gt;\n  mutate(\n    vulnerability_type = factor(\n      vulnerability_type,\n      levels = c(\n        \"income\",\n        \"education\",\n        \"water\",\n        \"sanitation\",\n        \"building\",\n        \"ssp\",\n        \"financial\"\n      )\n    ),\n    vulnerable_group = factor(\n      vulnerable_group,\n      levels = c(\n        \"children\", \"youth\", \n        \"women\", \"elderly\", \"men\"),\n      # labels(\n      #   \"Children\", \"Youth\", \n      #   \"Women\", \"Elderly\", \"Men\"\n      # )\n    )\n  )\n\ntraditionally_vulnerable_area_drought &lt;- traditionally_vulnerable_drought |&gt; \n  group_by(\n    as_factor(type),\n    vulnerability_type,\n    vulnerable_group\n  ) |&gt; \n  summarize(\n    value = sum(no_vulnerable_people, na.rm = T)\n  ) |&gt; \n  pivot_wider(\n    id_cols = c(\n      `as_factor(type)`,\n      vulnerable_group\n    ),\n    names_from = vulnerability_type,\n    values_from = value,\n    names_expand = T,\n    values_fill = 0\n  ) \n\n`summarise()` has grouped output by 'as_factor(type)', 'vulnerability_type'.\nYou can override using the `.groups` argument.\n\ncolnames(traditionally_vulnerable_area_drought) &lt;- c(\n  \"Area\", \"Group\", \"Income\",\n  \"Education\", \"Water\", \"Sanitation\",\n  \"Building\", \"Social Protection\", \"Financial\"\n)\n\ntraditionally_vulnerable_area_drought |&gt; \n  # ungroup() |&gt;\n  gt() |&gt; \n  summary_rows(\n    groups = everything(),\n    columns = c(\n      \"Income\", \"Education\", \n      \"Water\", \"Sanitation\",\n      \"Building\", \"Social Protection\", \n      \"Financial\"),\n    fns = list(label = \"Subtotal\", id = \"subtotals\", fn = \"sum\")\n  ) |&gt; \n  grand_summary_rows(\n    columns = c(\n      \"Income\", \"Education\", \n      \"Water\", \"Sanitation\",\n      \"Building\", \"Social Protection\", \n      \"Financial\"),\n    fns = list(label = \"Total\", id = \"totals\", fn = \"sum\")\n  )\n\n\n\n\n\n\n\n\nGroup\nIncome\nEducation\nWater\nSanitation\nBuilding\nSocial Protection\nFinancial\n\n\n\n\nUrban\n\n\n\nchildren\n9069.039\n0.0000\n332.5333\n2551.341\n1157.7712\n25473.14\n14479.07\n\n\n\nyouth\n13478.582\n0.0000\n1146.0354\n3187.612\n1979.9725\n28393.94\n21261.59\n\n\n\nwomen\n24250.602\n0.0000\n1734.6024\n9023.872\n2724.6854\n80886.28\n50918.04\n\n\n\nelderly\n15094.279\n0.0000\n783.1295\n7113.436\n1985.1225\n65346.81\n46056.82\n\n\n\nmen\n24024.621\n0.0000\n2043.9058\n9360.840\n3118.6620\n83002.24\n48918.26\n\n\nSubtotal\nâ\n85917.12\n0.000\n6040.207\n31237.1\n10966.21\n283102.4\n181633.8\n\n\nRural\n\n\n\nchildren\n14389.537\n0.0000\n9448.0653\n30137.675\n616.4112\n23147.45\n20690.98\n\n\n\nyouth\n20027.381\n634.2671\n14052.9290\n41266.729\n732.9969\n26904.27\n27137.11\n\n\n\nwomen\n34547.916\n422.8447\n24438.0314\n86320.526\n2369.9658\n73132.15\n58537.10\n\n\n\nelderly\n22530.684\n379.7286\n20382.8737\n77704.539\n2916.8783\n73522.00\n57934.69\n\n\n\nmen\n37454.447\n211.4224\n30282.2358\n106489.442\n3432.0343\n93468.61\n72202.59\n\n\nSubtotal\nâ\n128949.97\n1648.263\n98604.135\n341918.9\n10068.29\n290174.5\n236502.5\n\n\nTotal\nâ\n214867.1\n1648.263\n104644.3\n373156\n21034.5\n573276.9\n418136.3\n\n\n\n\n\n\n\nLandslides\n\ntraditionally_vulnerable_landslides &lt;- vulnerable_data |&gt;\n  mutate(\n    all_members = weights_landslides * hhsize,\n    children = weights_landslides * Childern,\n    youth = weights_landslides * Adult,\n    women = weights_landslides * Working_age_Woman,\n    men = weights_landslides * Working_age_man,\n    elderly = weights_landslides *\n      (Pensioner_age_man + Pensioner_age_Woman)\n  ) |&gt;\n  select(\n    UID,\n    RegNo,\n    type,\n    # all_members,\n    children,\n    youth,\n    women,\n    elderly,\n    men,\n    vulnerability_income,\n    vulnerability_education,\n    vulnerability_water,\n    vulnerability_sanitation,\n    vulnerability_building,\n    vulnerability_ssp,\n    vulnerability_financial,\n    exposed_to_landslides\n  ) |&gt;\n  pivot_longer(\n    cols = starts_with(\"vulnerability_\"),\n    names_to = \"vulnerability_type\",\n    names_prefix = \"vulnerability_\",\n    values_to = \"is_vulnerable\"\n  ) |&gt;\n  pivot_longer(\n    cols = c(children, youth, women, elderly, men),\n    names_to = \"vulnerable_group\",\n    values_to = \"no_vulnerable_people\"\n  ) |&gt;\n  filter(is_vulnerable == 1, exposed_to_landslides == \"Exposed\") |&gt;\n  mutate(\n    vulnerability_type = factor(\n      vulnerability_type,\n      levels = c(\n        \"income\",\n        \"education\",\n        \"water\",\n        \"sanitation\",\n        \"building\",\n        \"ssp\",\n        \"financial\"\n      )\n    ),\n    vulnerable_group = factor(\n      vulnerable_group,\n      levels = c(\n        \"children\", \"youth\", \n        \"women\", \"elderly\", \"men\"),\n      # labels(\n      #   \"Children\", \"Youth\", \n      #   \"Women\", \"Elderly\", \"Men\"\n      # )\n    )\n  )\n\ntraditionally_vulnerable_area_landslides &lt;- traditionally_vulnerable_landslides |&gt; \n  group_by(\n    as_factor(type),\n    vulnerability_type,\n    vulnerable_group\n  ) |&gt; \n  summarize(\n    value = sum(no_vulnerable_people, na.rm = T)\n  ) |&gt; \n  pivot_wider(\n    id_cols = c(\n      `as_factor(type)`,\n      vulnerable_group\n    ),\n    names_from = vulnerability_type,\n    values_from = value,\n    names_expand = T,\n    values_fill = 0\n  ) \n\n`summarise()` has grouped output by 'as_factor(type)', 'vulnerability_type'.\nYou can override using the `.groups` argument.\n\ncolnames(traditionally_vulnerable_area_landslides) &lt;- c(\n  \"Area\", \"Group\", \"Income\",\n  \"Education\", \"Water\", \"Sanitation\",\n  \"Building\", \"Social Protection\", \"Financial\"\n)\n\ntraditionally_vulnerable_area_landslides |&gt; \n  # ungroup() |&gt;\n  gt() |&gt; \n  summary_rows(\n    groups = everything(),\n    columns = c(\n      \"Income\", \"Education\", \n      \"Water\", \"Sanitation\",\n      \"Building\", \"Social Protection\", \n      \"Financial\"),\n    fns = list(label = \"Subtotal\", id = \"subtotals\", fn = \"sum\")\n  ) |&gt; \n  grand_summary_rows(\n    columns = c(\n      \"Income\", \"Education\", \n      \"Water\", \"Sanitation\",\n      \"Building\", \"Social Protection\", \n      \"Financial\"),\n    fns = list(label = \"Total\", id = \"totals\", fn = \"sum\"))\n\n\n\n\n\n\n\n\nGroup\nIncome\nEducation\nWater\nSanitation\nBuilding\nSocial Protection\nFinancial\n\n\n\n\nUrban\n\n\n\nchildren\n135.1345\n0.00000000\n0.3776685\n60.71366\n44.19447\n428.7800\n211.3420\n\n\n\nyouth\n190.2090\n0.00000000\n3.1224355\n92.31271\n25.28094\n447.3497\n252.6255\n\n\n\nwomen\n412.3411\n0.00000000\n9.3984672\n283.17720\n94.72482\n1308.9029\n738.1745\n\n\n\nelderly\n259.3446\n0.00000000\n16.5523364\n293.11818\n74.31923\n1174.0218\n756.8419\n\n\n\nmen\n421.5052\n0.00000000\n9.0221120\n278.19871\n87.22953\n1331.9319\n691.2868\n\n\nSubtotal\nâ\n1418.534\n0.000000\n38.47302\n1007.520\n325.749\n4690.986\n2650.271\n\n\nRural\n\n\n\nchildren\n259.8458\n0.00000000\n217.5477489\n441.28994\n93.00019\n346.4798\n301.1058\n\n\n\nyouth\n358.6067\n0.04927940\n305.9739720\n597.00472\n88.87130\n462.4660\n377.3827\n\n\n\nwomen\n810.5586\n0.03285293\n724.8273466\n1479.34749\n316.35646\n1347.2577\n1084.5900\n\n\n\nelderly\n654.2719\n2.49684613\n882.8478798\n1705.86282\n410.32467\n1627.0371\n1383.6822\n\n\n\nmen\n998.3975\n0.01642647\n876.7265483\n1836.84832\n384.00113\n1705.3004\n1416.6374\n\n\nSubtotal\nâ\n3081.680\n2.595405\n3007.92350\n6060.353\n1292.554\n5488.541\n4563.398\n\n\nTotal\nâ\n4500.215\n2.595405\n3046.397\n7067.874\n1618.303\n10179.53\n7213.669",
    "crumbs": [
      "Home",
      "Supporting materials",
      "Vulnerability Analysis"
    ]
  },
  {
    "objectID": "supporting-materials/vulnerability.html#exposed",
    "href": "supporting-materials/vulnerability.html#exposed",
    "title": "Vulnerability Analysis",
    "section": "Exposed",
    "text": "Exposed\n\nmap_object &lt;-\ntm_shape(exposed_and_poor_map)+\n  tm_polygons(\"Pct. Floods from Total\",\n              title=\"Percent\", \n              legend.show = TRUE,\n              style = \"fixed\",\n              scale = 5,\n              breaks = c(0, 5, 10, 15, 20, 25, 30),\n              textNA = \"Unavailable\",\n              colorNA = \"grey\"\n              ) +\n  tm_text(c(\"pct_exposed_label\"), size = .7, col = \"black\")+\n  tm_layout(\n    #legend.outside = TRUE,\n    legend.position = c(\"right\", \"top\"),\n    #title.snap.to.legend = FALSE,\n    title = \n      \"Percent Floods from Total\",\n    frame = FALSE,\n#            outer.margins=c(.10,.10, .10, .10), \n            title.position = c('left', 'bottom'),\n            title.size = 0.9)\n\ntmap_save(\n  map_object,\n  \"data/outputs/vulnerability_img/flood/pct_flood_exposed_fm_total.svg\",\n  width = 8,\n  height = 5,\n  units = \"in\"\n)\ntmap_save(\n  map_object,\n  \"data/outputs/vulnerability_img/flood/pct_flood_exposed_fm_total.png\",\n  width = 8,\n  height = 5,\n  units = \"in\",\n  dpi = 300\n)\nmap_object\n\n\n\n\n\n\n\nFigureÂ 3: Percent exposed from total",
    "crumbs": [
      "Home",
      "Supporting materials",
      "Vulnerability Analysis"
    ]
  },
  {
    "objectID": "supporting-materials/vulnerability.html#exposed-and-poor",
    "href": "supporting-materials/vulnerability.html#exposed-and-poor",
    "title": "Vulnerability Analysis",
    "section": "Exposed and poor",
    "text": "Exposed and poor\n\nmap_object &lt;-\ntm_shape(exposed_and_poor_map)+\n  tm_polygons(\"Pct. Below PL from Floods\",\n              title=\"Percent\", \n              legend.show = TRUE,\n              style = \"fixed\",\n              scale = 5,\n              breaks = c(0, 5, 10, 15, 20, 25, 30),\n              textNA = \"Unavailable\",\n              colorNA = \"grey\"\n              ) +\n  tm_text(c(\"pct_exposed_poor_label\"), size = .7, col = \"black\")+\n  tm_layout(\n    #legend.outside = TRUE,\n    legend.position = c(\"right\", \"top\"),\n    #title.snap.to.legend = FALSE,\n    title = \n      \"Percent below poverty line\\nfrom those exposed to floods\",\n    frame = FALSE,\n#            outer.margins=c(.10,.10, .10, .10), \n            title.position = c('left', 'bottom'),\n            title.size = 0.9)\n\ntmap_save(\n  map_object,\n  \"data/outputs/vulnerability_img/flood/pct_flood_poor_fm_exposed.svg\",\n  width = 8,\n  height = 5,\n  units = \"in\"\n)\ntmap_save(\n  map_object,\n  \"data/outputs/vulnerability_img/flood/pct_flood_poor_fm_exposed.png\",\n  width = 8,\n  height = 5,\n  units = \"in\",\n  dpi = 300\n)\nmap_object\n\n\n\n\n\n\n\nFigureÂ 4: Percent below poverty line from those exposed",
    "crumbs": [
      "Home",
      "Supporting materials",
      "Vulnerability Analysis"
    ]
  },
  {
    "objectID": "supporting-materials/vulnerability.html#at-risk-by-dimension",
    "href": "supporting-materials/vulnerability.html#at-risk-by-dimension",
    "title": "Vulnerability Analysis",
    "section": "At risk by dimension",
    "text": "At risk by dimension\n\nat_risk_map_floods &lt;- adm1 |&gt; \n  left_join(\n    at_risk_floods,\n    join_by(region == Regions)\n  ) |&gt; \n  mutate(\n    region = case_when(\n      region == \"Racha-Lechkhumi and Kvemo Svaneti\" ~\n      \"Racha-Lechkhumi\\nand Kvemo Svaneti\",\n      region == \"Samegrelo-Zemo Svaneti\" ~\n      \"Samegrelo-\\nZemo\\nSvaneti\",\n      region == \"Mtskheta-Mtianeti\" ~\n      \"Mtskheta-\\nMtianeti\",\n      region == \"Samtskhe-Javakheti\" ~\n      \"Samtskhe-\\nJavakheti\",\n      .default = region\n    ),\n    pct_income = Income / `Total Floods` * 100,\n    pct_education = Education  / `Total Floods` * 100,\n    pct_water = Water / `Total Floods` * 100,\n    pct_sanitation = Sanitation  / `Total Floods` * 100,\n    pct_buildings = Buildings / `Total Floods` * 100,\n    pct_ssp = `Social Protection` / `Total Floods` * 100,\n    pct_financial = `Financial inclusion` / `Total Floods` * 100,\n    pct_income_label = if_else(\n      is.na(Income), \n      \"Unavailable\", \n      paste(\n        region,\n        sprintf(\"\\n%.1f%%\", pct_income)\n      ) \n    ),\n    pct_education_label = if_else(\n      is.na(Education), \n      \"Unavailable\", \n      paste(\n        region,\n        sprintf(\"\\n%.1f%%\", pct_education)\n      ) \n    ),\n    pct_water_label = if_else(\n      is.na(Water), \n      \"Unavailable\", \n      paste(\n        region,\n        sprintf(\"\\n%.1f%%\", pct_water)\n      ) \n    ),\n    pct_sanitation_label = if_else(\n      is.na(Sanitation), \n      \"Unavailable\", \n      paste(\n        region,\n        sprintf(\"\\n%.1f%%\", pct_sanitation)\n      ) \n    ),\n    pct_buildings_label = if_else(\n      is.na(Buildings), \n      \"Unavailable\", \n      paste(\n        region,\n        sprintf(\"\\n%.1f%%\", pct_buildings)\n      ) \n    ),\n    pct_ssp_label = if_else(\n      is.na(`Social Protection`), \n      \"Unavailable\", \n      paste(\n        region,\n        sprintf(\"\\n%.1f%%\", pct_ssp)\n      ) \n    ),\n    pct_financial_label = if_else(\n      is.na(`Financial inclusion`), \n      \"Unavailable\", \n      paste(\n        region,\n        sprintf(\"\\n%.1f%%\", pct_financial)\n      ) \n    )\n  )\n\n\nIncome\n\nmap_object &lt;-\ntm_shape(at_risk_map_floods)+\n  tm_polygons(\"pct_income\",\n              title=\"Percent\", \n              legend.show = TRUE,\n              style = \"fixed\",\n              scale = 10,\n              breaks = c(0, 10, 20, 30, 40, 50, 60),\n              palette = \"Blues\",\n              textNA = \"Unavailable\",\n              colorNA = \"grey\"\n              ) +\n  tm_text(c(\"pct_income_label\"), size = .7, col = \"black\")+\n  tm_layout(\n    #legend.outside = TRUE,\n    legend.position = c(\"right\", \"top\"),\n    #title.snap.to.legend = FALSE,\n    title = \n      \"Percent income dimension\\nfrom those exposed to floods\",\n    frame = FALSE,\n#            outer.margins=c(.10,.10, .10, .10), \n            title.position = c('left', 'bottom'),\n            title.size = 0.9)\n\ntmap_save(\n  map_object,\n  \"data/outputs/vulnerability_img/flood/pct_flood_income.svg\",\n  width = 8,\n  height = 5,\n  units = \"in\"\n)\ntmap_save(\n  map_object,\n  \"data/outputs/vulnerability_img/flood/pct_flood_income.png\",\n  width = 8,\n  height = 5,\n  units = \"in\",\n  dpi = 300\n)\nmap_object\n\n\n\n\n\n\n\nFigureÂ 5: Percent with income dimension from those exposed\n\n\n\n\n\n\n\nEducation\n\nmap_object &lt;-\ntm_shape(at_risk_map_floods)+\n  tm_polygons(\"pct_education\",\n              title=\"Percent\", \n              legend.show = TRUE,\n              style = \"fixed\",\n              scale = 10,\n              breaks = c(0, 10, 20, 30, 40, 50, 60),\n              palette = \"Blues\",\n              textNA = \"Unavailable\",\n              colorNA = \"grey\"\n              ) +\n  tm_text(c(\"pct_education_label\"), size = .7, col = \"black\")+\n  tm_layout(\n    #legend.outside = TRUE,\n    legend.position = c(\"right\", \"top\"),\n    #title.snap.to.legend = FALSE,\n    title = \n      \"Percent education dimension\\nfrom those exposed to floods\",\n    frame = FALSE,\n#            outer.margins=c(.10,.10, .10, .10), \n            title.position = c('left', 'bottom'),\n            title.size = 0.9)\n\ntmap_save(\n  map_object,\n  \"data/outputs/vulnerability_img/flood/pct_flood_education.svg\",\n  width = 8,\n  height = 5,\n  units = \"in\"\n)\ntmap_save(\n  map_object,\n  \"data/outputs/vulnerability_img/flood/pct_flood_education.png\",\n  width = 8,\n  height = 5,\n  units = \"in\",\n  dpi = 300\n)\nmap_object\n\n\n\n\n\n\n\nFigureÂ 6: Percent with education dimension from those exposed\n\n\n\n\n\n\n\nWater\n\nmap_object &lt;-\ntm_shape(at_risk_map_floods)+\n  tm_polygons(\"pct_water\",\n              title=\"Percent\", \n              legend.show = TRUE,\n              style = \"fixed\",\n              scale = 10,\n              breaks = c(0, 10, 20, 30, 40, 50, 60),\n              palette = \"Blues\",\n              textNA = \"Unavailable\",\n              colorNA = \"grey\"\n              ) +\n  tm_text(c(\"pct_water_label\"), size = .7, col = \"black\")+\n  tm_layout(\n    #legend.outside = TRUE,\n    legend.position = c(\"right\", \"top\"),\n    #title.snap.to.legend = FALSE,\n    title = \n      \"Percent water dimension\\nfrom those exposed to floods\",\n    frame = FALSE,\n#            outer.margins=c(.10,.10, .10, .10), \n            title.position = c('left', 'bottom'),\n            title.size = 0.9)\n\ntmap_save(\n  map_object,\n  \"data/outputs/vulnerability_img/flood/pct_flood_water.svg\",\n  width = 8,\n  height = 5,\n  units = \"in\"\n)\ntmap_save(\n  map_object,\n  \"data/outputs/vulnerability_img/flood/pct_flood_water.png\",\n  width = 8,\n  height = 5,\n  units = \"in\",\n  dpi = 300\n)\nmap_object\n\n\n\n\n\n\n\nFigureÂ 7: Percent with water dimension from those exposed to floods\n\n\n\n\n\n\n\nSanitation\n\nmap_object &lt;-\ntm_shape(at_risk_map_floods)+\n  tm_polygons(\"pct_sanitation\",\n              title=\"Percent\", \n              legend.show = TRUE,\n              style = \"fixed\",\n              scale = 20,\n              breaks = c(0, 20, 40, 60, 80, 100),\n              palette = \"Blues\",\n              textNA = \"Unavailable\",\n              colorNA = \"grey\"\n              ) +\n  tm_text(c(\"pct_sanitation_label\"), size = .7, col = \"black\")+\n  tm_layout(\n    #legend.outside = TRUE,\n    legend.position = c(\"right\", \"top\"),\n    #title.snap.to.legend = FALSE,\n    title = \n      \"Percent sanitation dimension\\nfrom those exposed to floods\",\n    frame = FALSE,\n#            outer.margins=c(.10,.10, .10, .10), \n            title.position = c('left', 'bottom'),\n            title.size = 0.9)\n\ntmap_save(\n  map_object,\n  \"data/outputs/vulnerability_img/flood/pct_flood_sanitation.svg\",\n  width = 8,\n  height = 5,\n  units = \"in\"\n)\ntmap_save(\n  map_object,\n  \"data/outputs/vulnerability_img/flood/pct_flood_sanitation.png\",\n  width = 8,\n  height = 5,\n  units = \"in\",\n  dpi = 300\n)\nmap_object\n\n\n\n\n\n\n\nFigureÂ 8: Percent with sanitation dimension from those exposed\n\n\n\n\n\n\n\nBuilding materials\n\nmap_object &lt;-\ntm_shape(at_risk_map_floods)+\n  tm_polygons(\"pct_buildings\",\n              title=\"Percent\", \n              legend.show = TRUE,\n              style = \"fixed\",\n              scale = 10,\n              breaks = c(0, 10, 20, 30, 40, 50, 60),\n              palette = \"Blues\",\n              textNA = \"Unavailable\",\n              colorNA = \"grey\"\n              ) +\n  tm_text(c(\"pct_buildings_label\"), size = .7, col = \"black\")+\n  tm_layout(\n    #legend.outside = TRUE,\n    legend.position = c(\"right\", \"top\"),\n    #title.snap.to.legend = FALSE,\n    title = \n      \"Percent building materials\\ndimension from those exposed to floods\",\n    frame = FALSE,\n#            outer.margins=c(.10,.10, .10, .10), \n            title.position = c('left', 'bottom'),\n            title.size = 0.9)\n\ntmap_save(\n  map_object,\n  \"data/outputs/vulnerability_img/flood/pct_flood_buildings.svg\",\n  width = 8,\n  height = 5,\n  units = \"in\"\n)\ntmap_save(\n  map_object,\n  \"data/outputs/vulnerability_img/flood/pct_flood_buildings.png\",\n  width = 8,\n  height = 5,\n  units = \"in\",\n  dpi = 300\n)\nmap_object\n\n\n\n\n\n\n\nFigureÂ 9: Percent with buildings dimension from those exposed\n\n\n\n\n\n\n\nSocial protection\n\nmap_object &lt;-\ntm_shape(at_risk_map_floods)+\n  tm_polygons(\"pct_ssp\",\n              title=\"Percent\", \n              legend.show = TRUE,\n              style = \"fixed\",\n              scale = 10,\n              breaks = c(50,60, 70,80, 90, 100),\n              palette = \"Blues\",\n              textNA = \"Unavailable\",\n              colorNA = \"grey\"\n              ) +\n  tm_text(c(\"pct_ssp_label\"), size = .7, col = \"black\")+\n  tm_layout(\n    #legend.outside = TRUE,\n    legend.position = c(\"right\", \"top\"),\n    #title.snap.to.legend = FALSE,\n    title = \n      \"Percent social protection\\ndimension from those exposed to floods\",\n    frame = FALSE,\n#            outer.margins=c(.10,.10, .10, .10), \n            title.position = c('left', 'bottom'),\n            title.size = 0.9)\n\ntmap_save(\n  map_object,\n  \"data/outputs/vulnerability_img/flood/pct_flood_ssp.svg\",\n  width = 8,\n  height = 5,\n  units = \"in\"\n)\ntmap_save(\n  map_object,\n  \"data/outputs/vulnerability_img/flood/pct_flood_ssp.png\",\n  width = 8,\n  height = 5,\n  units = \"in\",\n  dpi = 300\n)\nmap_object\n\n\n\n\n\n\n\nFigureÂ 10: Percent with social dimension from those exposed\n\n\n\n\n\n\n\nFinancial services\n\nmap_object &lt;-\ntm_shape(at_risk_map_floods)+\n  tm_polygons(\"pct_financial\",\n              title=\"Percent\", \n              legend.show = TRUE,\n              style = \"fixed\",\n              scale = 10,\n              breaks = c(40, 50,60, 70,80, 90, 100),\n              palette = \"Blues\",\n              textNA = \"Unavailable\",\n              colorNA = \"grey\"\n              ) +\n  tm_text(c(\"pct_financial_label\"), size = .7, col = \"black\")+\n  tm_layout(\n    #legend.outside = TRUE,\n    legend.position = c(\"right\", \"top\"),\n    #title.snap.to.legend = FALSE,\n    title = \n      \"Percent financial dimension\\nfrom those exposed to floods\",\n    frame = FALSE,\n#            outer.margins=c(.10,.10, .10, .10), \n            title.position = c('left', 'bottom'),\n            title.size = 0.9)\n\ntmap_save(\n  map_object,\n  \"data/outputs/vulnerability_img/flood/pct_flood_financial.svg\",\n  width = 8,\n  height = 5,\n  units = \"in\"\n)\ntmap_save(\n  map_object,\n  \"data/outputs/vulnerability_img/flood/pct_flood_financial.png\",\n  width = 8,\n  height = 5,\n  units = \"in\"\n)\nmap_object\n\n\n\n\n\n\n\nFigureÂ 11: Percent with financial dimension from those exposed",
    "crumbs": [
      "Home",
      "Supporting materials",
      "Vulnerability Analysis"
    ]
  },
  {
    "objectID": "supporting-materials/vulnerability.html#at-risk-by-many-dimensions",
    "href": "supporting-materials/vulnerability.html#at-risk-by-many-dimensions",
    "title": "Vulnerability Analysis",
    "section": "At risk by many dimensions",
    "text": "At risk by many dimensions\nPrepare map data\n\nat_risk_dimensions_map_floods &lt;- adm1 |&gt; \n  left_join(\n    at_risk_dimensions_floods,\n    join_by(region == Regions)\n  ) |&gt; \n  mutate(\n    region = case_when(\n      region == \"Racha-Lechkhumi and Kvemo Svaneti\" ~\n      \"Racha-Lechkhumi\\nand Kvemo Svaneti\",\n      region == \"Samegrelo-Zemo Svaneti\" ~\n      \"Samegrelo-\\nZemo\\nSvaneti\",\n      region == \"Mtskheta-Mtianeti\" ~\n      \"Mtskheta-\\nMtianeti\",\n      region == \"Samtskhe-Javakheti\" ~\n      \"Samtskhe-\\nJavakheti\",\n      .default = region\n    ),\n    up_to_2_dims = case_when(\n      is.na(`1 dimension`) | is.na(`2 dimensions`) ~ NA,\n      .default = `1 dimension` + `2 dimensions`\n    ),\n    pct_up_to_2_dims = if_else(\n      is.na(`Total Floods`), `Total Floods`,\n      up_to_2_dims / `Total Floods` * 100\n    )\n  ) |&gt; \n  mutate(\n    pct_up_to_2_dims_label = if_else(\n      is.na(pct_up_to_2_dims), \n      \"Unavailable\", \n      paste(\n        region,\n        sprintf(\"\\n%.1f%%\", pct_up_to_2_dims)\n      ) \n    )\n  )\n\n\nmap_object &lt;-\ntm_shape(at_risk_dimensions_map_floods)+\n  tm_polygons(\"pct_up_to_2_dims\",\n              title=\"Percent\", \n              legend.show = TRUE,\n              style = \"fixed\",\n              scale = 10,\n              breaks = c(20,40, 50,60, 70,80, 90,100),\n              palette = \"Purples\",\n              textNA = \"Unavailable\",\n              colorNA = \"grey\"\n              ) +\n  tm_text(c(\"pct_up_to_2_dims_label\"), size = .7, col = \"black\")+\n  tm_layout(\n    #legend.outside = TRUE,\n    legend.position = c(\"right\", \"top\"),\n    #title.snap.to.legend = FALSE,\n    title = \n      \"Percent with up to 2 dimensions\\nfrom those exposed to floods\",\n    frame = FALSE,\n#            outer.margins=c(.10,.10, .10, .10), \n            title.position = c('left', 'bottom'),\n            title.size = 0.9)\n\ntmap_save(\n  map_object,\n  \"data/outputs/vulnerability_img/flood/pct_flood_up_to_2_dimensions.svg\",\n  width = 8,\n  height = 5,\n  units = \"in\"\n)\ntmap_save(\n  map_object,\n  \"data/outputs/vulnerability_img/flood/pct_flood_up_to_2_dimensions.png\",\n  width = 8,\n  height = 5,\n  units = \"in\",\n  dpi = 300\n)\nmap_object\n\n\n\n\n\n\n\nFigureÂ 12: Percent with up to 2 dimensions from those exposed",
    "crumbs": [
      "Home",
      "Supporting materials",
      "Vulnerability Analysis"
    ]
  },
  {
    "objectID": "supporting-materials/vulnerability.html#exposed-1",
    "href": "supporting-materials/vulnerability.html#exposed-1",
    "title": "Vulnerability Analysis",
    "section": "Exposed",
    "text": "Exposed\n\nmap_object &lt;-\ntm_shape(drought_and_poor_map)+\n  tm_polygons(\"Pct. Drought from Total\",\n              title=\"Percent\", \n              legend.show = TRUE,\n              style = \"fixed\",\n              scale = 5,\n              breaks = c(0, 10, 20, 30, 40, 50),\n              textNA = \"Unavailable\",\n              colorNA = \"grey\"\n              ) +\n  tm_text(c(\"pct_exposed_label\"), size = .7, col = \"black\")+\n  tm_layout(\n    #legend.outside = TRUE,\n    legend.position = c(\"right\", \"top\"),\n    #title.snap.to.legend = FALSE,\n    title = \n      \"Percent Drought from Total\",\n    frame = FALSE,\n#            outer.margins=c(.10,.10, .10, .10), \n            title.position = c('left', 'bottom'),\n            title.size = 0.9)\n\ntmap_save(\n  map_object,\n  \"data/outputs/vulnerability_img/drought/pct_drought_exposed_fm_total.svg\",\n  width = 8,\n  height = 5,\n  units = \"in\"\n)\ntmap_save(\n  map_object,\n  \"data/outputs/vulnerability_img/drought/pct_drought_exposed_fm_total.png\",\n  width = 8,\n  height = 5,\n  units = \"in\",\n  dpi = 300\n)\nmap_object",
    "crumbs": [
      "Home",
      "Supporting materials",
      "Vulnerability Analysis"
    ]
  },
  {
    "objectID": "supporting-materials/vulnerability.html#exposed-and-poor-1",
    "href": "supporting-materials/vulnerability.html#exposed-and-poor-1",
    "title": "Vulnerability Analysis",
    "section": "Exposed and poor",
    "text": "Exposed and poor\n\nmap_object &lt;-\ntm_shape(drought_and_poor_map)+\n  tm_polygons(\"Pct. Below PL from Drought\",\n              title=\"Percent\", \n              legend.show = TRUE,\n              style = \"fixed\",\n              scale = 5,\n              breaks = c(0, 5, 10, 15, 20, 25, 30),\n              textNA = \"Unavailable\",\n              colorNA = \"grey\"\n              ) +\n  tm_text(c(\"pct_exposed_poor_label\"), size = .7, col = \"black\")+\n  tm_layout(\n    #legend.outside = TRUE,\n    legend.position = c(\"right\", \"top\"),\n    #title.snap.to.legend = FALSE,\n    title = \n      \"Percent below poverty line\\nfrom those exposed to drought\",\n    frame = FALSE,\n#            outer.margins=c(.10,.10, .10, .10), \n            title.position = c('left', 'bottom'),\n            title.size = 0.9)\n\ntmap_save(\n  map_object,\n  \"data/outputs/vulnerability_img/drought/pct_drought_poor_fm_exposed.svg\",\n  width = 8,\n  height = 5,\n  units = \"in\"\n)\ntmap_save(\n  map_object,\n  \"data/outputs/vulnerability_img/drought/pct_drought_poor_fm_exposed.png\",\n  width = 8,\n  height = 5,\n  units = \"in\",\n  dpi = 300\n)\nmap_object",
    "crumbs": [
      "Home",
      "Supporting materials",
      "Vulnerability Analysis"
    ]
  },
  {
    "objectID": "supporting-materials/vulnerability.html#at-risk-by-dimension-1",
    "href": "supporting-materials/vulnerability.html#at-risk-by-dimension-1",
    "title": "Vulnerability Analysis",
    "section": "At risk by dimension",
    "text": "At risk by dimension\n\nat_risk_map_drought &lt;- adm1 |&gt; \n  left_join(\n    at_risk_drought,\n    join_by(region == Regions)\n  ) |&gt; \n  mutate(\n    region = case_when(\n      region == \"Racha-Lechkhumi and Kvemo Svaneti\" ~\n      \"Racha-Lechkhumi\\nand Kvemo Svaneti\",\n      region == \"Samegrelo-Zemo Svaneti\" ~\n      \"Samegrelo-\\nZemo\\nSvaneti\",\n      region == \"Mtskheta-Mtianeti\" ~\n      \"Mtskheta-\\nMtianeti\",\n      region == \"Samtskhe-Javakheti\" ~\n      \"Samtskhe-\\nJavakheti\",\n      .default = region\n    ),\n    pct_income = Income / `Total Drought` * 100,\n    pct_education = Education  / `Total Drought` * 100,\n    pct_water = Water / `Total Drought` * 100,\n    pct_sanitation = Sanitation  / `Total Drought` * 100,\n    pct_buildings = Buildings / `Total Drought` * 100,\n    pct_ssp = `Social Protection` / `Total Drought` * 100,\n    pct_financial = `Financial inclusion` / `Total Drought` * 100,\n    pct_income_label = if_else(\n      is.na(Income), \n      \"Unavailable\", \n      paste(\n        region,\n        sprintf(\"\\n%.1f%%\", pct_income)\n      ) \n    ),\n    pct_education_label = if_else(\n      is.na(Education), \n      \"Unavailable\", \n      paste(\n        region,\n        sprintf(\"\\n%.1f%%\", pct_education)\n      ) \n    ),\n    pct_water_label = if_else(\n      is.na(Water), \n      \"Unavailable\", \n      paste(\n        region,\n        sprintf(\"\\n%.1f%%\", pct_water)\n      ) \n    ),\n    pct_sanitation_label = if_else(\n      is.na(Sanitation), \n      \"Unavailable\", \n      paste(\n        region,\n        sprintf(\"\\n%.1f%%\", pct_sanitation)\n      ) \n    ),\n    pct_buildings_label = if_else(\n      is.na(Buildings), \n      \"Unavailable\", \n      paste(\n        region,\n        sprintf(\"\\n%.1f%%\", pct_buildings)\n      ) \n    ),\n    pct_ssp_label = if_else(\n      is.na(`Social Protection`), \n      \"Unavailable\", \n      paste(\n        region,\n        sprintf(\"\\n%.1f%%\", pct_ssp)\n      ) \n    ),\n    pct_financial_label = if_else(\n      is.na(`Financial inclusion`), \n      \"Unavailable\", \n      paste(\n        region,\n        sprintf(\"\\n%.1f%%\", pct_financial)\n      ) \n    )\n  )\n\n\nIncome\n\nmap_object &lt;-\ntm_shape(at_risk_map_drought)+\n  tm_polygons(\"pct_income\",\n              title=\"Percent\", \n              legend.show = TRUE,\n              style = \"fixed\",\n              scale = 10,\n              breaks = c(0, 10, 20, 30, 40, 50, 60),\n              palette = \"Blues\",\n              textNA = \"Unavailable\",\n              colorNA = \"grey\"\n              ) +\n  tm_text(c(\"pct_income_label\"), size = .7, col = \"black\")+\n  tm_layout(\n    #legend.outside = TRUE,\n    legend.position = c(\"right\", \"top\"),\n    #title.snap.to.legend = FALSE,\n    title = \n      \"Percent income dimension\\nfrom those exposed to drought\",\n    frame = FALSE,\n#            outer.margins=c(.10,.10, .10, .10), \n            title.position = c('left', 'bottom'),\n            title.size = 0.9)\n\ntmap_save(\n  map_object,\n  \"data/outputs/vulnerability_img/drought/pct_drought_income.svg\",\n  width = 8,\n  height = 5,\n  units = \"in\"\n)\ntmap_save(\n  map_object,\n  \"data/outputs/vulnerability_img/drought/pct_drought_income.png\",\n  width = 8,\n  height = 5,\n  units = \"in\",\n  dpi = 300\n)\nmap_object\n\n\n\n\n\n\n\n\n\n\nEducation\n\nmap_object &lt;-\ntm_shape(at_risk_map_drought)+\n  tm_polygons(\"pct_education\",\n              title=\"Percent\", \n              legend.show = TRUE,\n              style = \"fixed\",\n              scale = 10,\n              breaks = c(0, 10, 20, 30, 40, 50, 60),\n              palette = \"Blues\",\n              textNA = \"Unavailable\",\n              colorNA = \"grey\"\n              ) +\n  tm_text(c(\"pct_education_label\"), size = .7, col = \"black\")+\n  tm_layout(\n    #legend.outside = TRUE,\n    legend.position = c(\"right\", \"top\"),\n    #title.snap.to.legend = FALSE,\n    title = \n      \"Percent education dimension\\nfrom those exposed to drought\",\n    frame = FALSE,\n#            outer.margins=c(.10,.10, .10, .10), \n            title.position = c('left', 'bottom'),\n            title.size = 0.9)\n\ntmap_save(\n  map_object,\n  \"data/outputs/vulnerability_img/drought/pct_drought_education.svg\",\n  width = 8,\n  height = 5,\n  units = \"in\"\n)\ntmap_save(\n  map_object,\n  \"data/outputs/vulnerability_img/drought/pct_drought_education.png\",\n  width = 8,\n  height = 5,\n  units = \"in\",\n  dpi = 300\n)\nmap_object\n\n\n\n\n\n\n\n\n\n\nWater\n\nmap_object &lt;-\ntm_shape(at_risk_map_drought)+\n  tm_polygons(\"pct_water\",\n              title=\"Percent\", \n              legend.show = TRUE,\n              style = \"fixed\",\n              scale = 10,\n              breaks = c(0, 10, 20, 30, 40, 50, 60),\n              palette = \"Blues\",\n              textNA = \"Unavailable\",\n              colorNA = \"grey\"\n              ) +\n  tm_text(c(\"pct_water_label\"), size = .7, col = \"black\")+\n  tm_layout(\n    #legend.outside = TRUE,\n    legend.position = c(\"right\", \"top\"),\n    #title.snap.to.legend = FALSE,\n    title = \n      \"Percent water dimension\\nfrom those exposed to drought\",\n    frame = FALSE,\n#            outer.margins=c(.10,.10, .10, .10), \n            title.position = c('left', 'bottom'),\n            title.size = 0.9)\n\ntmap_save(\n  map_object,\n  \"data/outputs/vulnerability_img/drought/pct_drought_water.svg\",\n  width = 8,\n  height = 5,\n  units = \"in\"\n)\ntmap_save(\n  map_object,\n  \"data/outputs/vulnerability_img/drought/pct_drought_water.png\",\n  width = 8,\n  height = 5,\n  units = \"in\",\n  dpi = 300\n)\nmap_object\n\n\n\n\n\n\n\n\n\n\nSanitation\n\nmap_object &lt;-\ntm_shape(at_risk_map_drought)+\n  tm_polygons(\"pct_sanitation\",\n              title=\"Percent\", \n              legend.show = TRUE,\n              style = \"fixed\",\n              scale = 20,\n              breaks = c(0, 20, 40, 60, 80, 100),\n              palette = \"Blues\",\n              textNA = \"Unavailable\",\n              colorNA = \"grey\"\n              ) +\n  tm_text(c(\"pct_sanitation_label\"), size = .7, col = \"black\")+\n  tm_layout(\n    #legend.outside = TRUE,\n    legend.position = c(\"right\", \"top\"),\n    #title.snap.to.legend = FALSE,\n    title = \n      \"Percent sanitation dimension\\nfrom those exposed to drought\",\n    frame = FALSE,\n#            outer.margins=c(.10,.10, .10, .10), \n            title.position = c('left', 'bottom'),\n            title.size = 0.9)\n\ntmap_save(\n  map_object,\n  \"data/outputs/vulnerability_img/drought/pct_drought_sanitation.svg\",\n  width = 8,\n  height = 5,\n  units = \"in\"\n)\ntmap_save(\n  map_object,\n  \"data/outputs/vulnerability_img/drought/pct_drought_sanitation.png\",\n  width = 8,\n  height = 5,\n  units = \"in\",\n  dpi = 300\n)\nmap_object\n\n\n\n\n\n\n\n\n\n\nBuilding materials\n\nmap_object &lt;-\ntm_shape(at_risk_map_drought)+\n  tm_polygons(\"pct_buildings\",\n              title=\"Percent\", \n              legend.show = TRUE,\n              style = \"fixed\",\n              scale = 10,\n              breaks = c(0, 10, 20, 30, 40, 50, 60),\n              palette = \"Blues\",\n              textNA = \"Unavailable\",\n              colorNA = \"grey\"\n              ) +\n  tm_text(c(\"pct_buildings_label\"), size = .7, col = \"black\")+\n  tm_layout(\n    #legend.outside = TRUE,\n    legend.position = c(\"right\", \"top\"),\n    #title.snap.to.legend = FALSE,\n    title = \n      \"Percent building materials\\ndimension from those exposed to drought\",\n    frame = FALSE,\n#            outer.margins=c(.10,.10, .10, .10), \n            title.position = c('left', 'bottom'),\n            title.size = 0.9)\n\ntmap_save(\n  map_object,\n  \"data/outputs/vulnerability_img/drought/pct_drought_buildings.svg\",\n  width = 8,\n  height = 5,\n  units = \"in\"\n)\ntmap_save(\n  map_object,\n  \"data/outputs/vulnerability_img/drought/pct_drought_buildings.png\",\n  width = 8,\n  height = 5,\n  units = \"in\",\n  dpi = 300\n)\nmap_object\n\n\n\n\n\n\n\n\n\n\nSocial protection\n\nmap_object &lt;-\ntm_shape(at_risk_map_drought)+\n  tm_polygons(\"pct_ssp\",\n              title=\"Percent\", \n              legend.show = TRUE,\n              style = \"fixed\",\n              scale = 10,\n              breaks = c(50,60, 70,80, 90, 100),\n              palette = \"Blues\",\n              textNA = \"Unavailable\",\n              colorNA = \"grey\"\n              ) +\n  tm_text(c(\"pct_ssp_label\"), size = .7, col = \"black\")+\n  tm_layout(\n    #legend.outside = TRUE,\n    legend.position = c(\"right\", \"top\"),\n    #title.snap.to.legend = FALSE,\n    title = \n      \"Percent social protection\\ndimension from those exposed to drought\",\n    frame = FALSE,\n#            outer.margins=c(.10,.10, .10, .10), \n            title.position = c('left', 'bottom'),\n            title.size = 0.9)\n\ntmap_save(\n  map_object,\n  \"data/outputs/vulnerability_img/drought/pct_drought_ssp.svg\",\n  width = 8,\n  height = 5,\n  units = \"in\"\n)\ntmap_save(\n  map_object,\n  \"data/outputs/vulnerability_img/drought/pct_drought_ssp.png\",\n  width = 8,\n  height = 5,\n  units = \"in\",\n  dpi = 300\n)\nmap_object\n\n\n\n\n\n\n\n\n\n\nFinancial services\n\nmap_object &lt;-\ntm_shape(at_risk_map_drought)+\n  tm_polygons(\"pct_financial\",\n              title=\"Percent\", \n              legend.show = TRUE,\n              style = \"fixed\",\n              scale = 10,\n              breaks = c(40, 50,60, 70,80, 90, 100),\n              palette = \"Blues\",\n              textNA = \"Unavailable\",\n              colorNA = \"grey\"\n              ) +\n  tm_text(c(\"pct_financial_label\"), size = .7, col = \"black\")+\n  tm_layout(\n    #legend.outside = TRUE,\n    legend.position = c(\"right\", \"top\"),\n    #title.snap.to.legend = FALSE,\n    title = \n      \"Percent financial dimension\\nfrom those exposed to drought\",\n    frame = FALSE,\n#            outer.margins=c(.10,.10, .10, .10), \n            title.position = c('left', 'bottom'),\n            title.size = 0.9)\n\ntmap_save(\n  map_object,\n  \"data/outputs/vulnerability_img/drought/pct_drought_financial.svg\",\n  width = 8,\n  height = 5,\n  units = \"in\"\n)\ntmap_save(\n  map_object,\n  \"data/outputs/vulnerability_img/drought/pct_drought_financial.png\",\n  width = 8,\n  height = 5,\n  units = \"in\",\n  dpi = 300\n)\nmap_object",
    "crumbs": [
      "Home",
      "Supporting materials",
      "Vulnerability Analysis"
    ]
  },
  {
    "objectID": "supporting-materials/vulnerability.html#at-risk-by-many-dimensions-1",
    "href": "supporting-materials/vulnerability.html#at-risk-by-many-dimensions-1",
    "title": "Vulnerability Analysis",
    "section": "At risk by many dimensions",
    "text": "At risk by many dimensions\nPrepare map data\n\nat_risk_dimensions_map_drought &lt;- adm1 |&gt; \n  left_join(\n    at_risk_dimensions_drought,\n    join_by(region == Regions)\n  ) |&gt; \n  mutate(\n    region = case_when(\n      region == \"Racha-Lechkhumi and Kvemo Svaneti\" ~\n      \"Racha-Lechkhumi\\nand Kvemo Svaneti\",\n      region == \"Samegrelo-Zemo Svaneti\" ~\n      \"Samegrelo-\\nZemo\\nSvaneti\",\n      region == \"Mtskheta-Mtianeti\" ~\n      \"Mtskheta-\\nMtianeti\",\n      region == \"Samtskhe-Javakheti\" ~\n      \"Samtskhe-\\nJavakheti\",\n      .default = region\n    ),\n    up_to_2_dims = case_when(\n      is.na(`1 dimension`) | is.na(`2 dimensions`) ~ NA,\n      .default = `1 dimension` + `2 dimensions`\n    ),\n    pct_up_to_2_dims = if_else(\n      is.na(`Total Drought`), `Total Drought`,\n      up_to_2_dims / `Total Drought` * 100\n    )\n  ) |&gt; \n  mutate(\n    pct_up_to_2_dims_label = if_else(\n      is.na(pct_up_to_2_dims), \n      \"Unavailable\", \n      paste(\n        region,\n        sprintf(\"\\n%.1f%%\", pct_up_to_2_dims)\n      ) \n    )\n  )\n\n\nmap_object &lt;-\ntm_shape(at_risk_dimensions_map_drought)+\n  tm_polygons(\"pct_up_to_2_dims\",\n              title=\"Percent\", \n              legend.show = TRUE,\n              style = \"fixed\",\n              scale = 10,\n              breaks = c(20,40, 50,60, 70,80, 90,100),\n              palette = \"Purples\",\n              textNA = \"Unavailable\",\n              colorNA = \"grey\"\n              ) +\n  tm_text(c(\"pct_up_to_2_dims_label\"), size = .7, col = \"black\")+\n  tm_layout(\n    #legend.outside = TRUE,\n    legend.position = c(\"right\", \"top\"),\n    #title.snap.to.legend = FALSE,\n    title = \n      \"Percent with up to 2 dimensions\\nfrom those exposed to drought\",\n    frame = FALSE,\n#            outer.margins=c(.10,.10, .10, .10), \n            title.position = c('left', 'bottom'),\n            title.size = 0.9)\n\ntmap_save(\n  map_object,\n  \"data/outputs/vulnerability_img/drought/pct_drought_up_to_2_dimensions.svg\",\n  width = 8,\n  height = 5,\n  units = \"in\"\n)\ntmap_save(\n  map_object,\n  \"data/outputs/vulnerability_img/drought/pct_drought_up_to_2_dimensions.png\",\n  width = 8,\n  height = 5,\n  units = \"in\",\n  dpi = 300\n)\nmap_object",
    "crumbs": [
      "Home",
      "Supporting materials",
      "Vulnerability Analysis"
    ]
  },
  {
    "objectID": "supporting-materials/vulnerability.html#exposed-2",
    "href": "supporting-materials/vulnerability.html#exposed-2",
    "title": "Vulnerability Analysis",
    "section": "Exposed",
    "text": "Exposed\n\nmap_object &lt;-\ntm_shape(landslides_and_poor_map)+\n  tm_polygons(\"Pct. Landslides from Total\",\n              title=\"Percent\", \n              legend.show = TRUE,\n              style = \"fixed\",\n              scale = 5,\n              breaks = c(0, 10, 20, 30, 40, 50),\n              textNA = \"Unavailable\",\n              colorNA = \"grey\"\n              ) +\n  tm_text(c(\"pct_exposed_label\"), size = .7, col = \"black\")+\n  tm_layout(\n    #legend.outside = TRUE,\n    legend.position = c(\"right\", \"top\"),\n    #title.snap.to.legend = FALSE,\n    title = \n      \"Percent Landslides from Total\",\n    frame = FALSE,\n#            outer.margins=c(.10,.10, .10, .10), \n            title.position = c('left', 'bottom'),\n            title.size = 0.9)\n\ntmap_save(\n  map_object,\n  \"data/outputs/vulnerability_img/landslides/pct_landslides_exposed_fm_total.svg\",\n  width = 8,\n  height = 5,\n  units = \"in\"\n)\ntmap_save(\n  map_object,\n  \"data/outputs/vulnerability_img/landslides/pct_landslides_exposed_fm_total.png\",\n  width = 8,\n  height = 5,\n  units = \"in\",\n  dpi = 300\n)\nmap_object",
    "crumbs": [
      "Home",
      "Supporting materials",
      "Vulnerability Analysis"
    ]
  },
  {
    "objectID": "supporting-materials/vulnerability.html#exposed-and-poor-2",
    "href": "supporting-materials/vulnerability.html#exposed-and-poor-2",
    "title": "Vulnerability Analysis",
    "section": "Exposed and poor",
    "text": "Exposed and poor\n\nmap_object &lt;-\ntm_shape(landslides_and_poor_map)+\n  tm_polygons(\"Pct. Below PL from Landslides\",\n              title=\"Percent\", \n              legend.show = TRUE,\n              style = \"fixed\",\n              scale = 5,\n              breaks = c(0, 5, 10, 15, 20, 25, 30),\n              textNA = \"Unavailable\",\n              colorNA = \"grey\"\n              ) +\n  tm_text(c(\"pct_exposed_poor_label\"), size = .7, col = \"black\")+\n  tm_layout(\n    #legend.outside = TRUE,\n    legend.position = c(\"right\", \"top\"),\n    #title.snap.to.legend = FALSE,\n    title = \n      \"Percent below poverty line\\nfrom those exposed to landslides\",\n    frame = FALSE,\n#            outer.margins=c(.10,.10, .10, .10), \n            title.position = c('left', 'bottom'),\n            title.size = 0.9)\n\ntmap_save(\n  map_object,\n  \"data/outputs/vulnerability_img/landslides/pct_landslides_poor_fm_exposed.svg\",\n  width = 8,\n  height = 5,\n  units = \"in\"\n)\ntmap_save(\n  map_object,\n  \"data/outputs/vulnerability_img/landslides/pct_landslides_poor_fm_exposed.png\",\n  width = 8,\n  height = 5,\n  units = \"in\",\n  dpi = 300\n)\nmap_object",
    "crumbs": [
      "Home",
      "Supporting materials",
      "Vulnerability Analysis"
    ]
  },
  {
    "objectID": "supporting-materials/vulnerability.html#at-risk-by-dimension-2",
    "href": "supporting-materials/vulnerability.html#at-risk-by-dimension-2",
    "title": "Vulnerability Analysis",
    "section": "At risk by dimension",
    "text": "At risk by dimension\n\nat_risk_map_landslides &lt;- adm1 |&gt; \n  left_join(\n    at_risk_landslides,\n    join_by(region == Regions)\n  ) |&gt; \n  mutate(\n    region = case_when(\n      region == \"Racha-Lechkhumi and Kvemo Svaneti\" ~\n      \"Racha-Lechkhumi\\nand Kvemo Svaneti\",\n      region == \"Samegrelo-Zemo Svaneti\" ~\n      \"Samegrelo-\\nZemo\\nSvaneti\",\n      region == \"Mtskheta-Mtianeti\" ~\n      \"Mtskheta-\\nMtianeti\",\n      region == \"Samtskhe-Javakheti\" ~\n      \"Samtskhe-\\nJavakheti\",\n      .default = region\n    ),\n    pct_income = Income / `Total Landslides` * 100,\n    pct_education = Education  / `Total Landslides` * 100,\n    pct_water = Water / `Total Landslides` * 100,\n    pct_sanitation = Sanitation  / `Total Landslides` * 100,\n    pct_buildings = Buildings / `Total Landslides` * 100,\n    pct_ssp = `Social Protection` / `Total Landslides` * 100,\n    pct_financial = `Financial inclusion` / `Total Landslides` * 100,\n    pct_income_label = if_else(\n      is.na(Income), \n      \"Unavailable\", \n      paste(\n        region,\n        sprintf(\"\\n%.1f%%\", pct_income)\n      ) \n    ),\n    pct_education_label = if_else(\n      is.na(Education), \n      \"Unavailable\", \n      paste(\n        region,\n        sprintf(\"\\n%.1f%%\", pct_education)\n      ) \n    ),\n    pct_water_label = if_else(\n      is.na(Water), \n      \"Unavailable\", \n      paste(\n        region,\n        sprintf(\"\\n%.1f%%\", pct_water)\n      ) \n    ),\n    pct_sanitation_label = if_else(\n      is.na(Sanitation), \n      \"Unavailable\", \n      paste(\n        region,\n        sprintf(\"\\n%.1f%%\", pct_sanitation)\n      ) \n    ),\n    pct_buildings_label = if_else(\n      is.na(Buildings), \n      \"Unavailable\", \n      paste(\n        region,\n        sprintf(\"\\n%.1f%%\", pct_buildings)\n      ) \n    ),\n    pct_ssp_label = if_else(\n      is.na(`Social Protection`), \n      \"Unavailable\", \n      paste(\n        region,\n        sprintf(\"\\n%.1f%%\", pct_ssp)\n      ) \n    ),\n    pct_financial_label = if_else(\n      is.na(`Financial inclusion`), \n      \"Unavailable\", \n      paste(\n        region,\n        sprintf(\"\\n%.1f%%\", pct_financial)\n      ) \n    )\n  )\n\n\nIncome\n\nmap_object &lt;-\ntm_shape(at_risk_map_landslides)+\n  tm_polygons(\"pct_income\",\n              title=\"Percent\", \n              legend.show = TRUE,\n              style = \"fixed\",\n              scale = 10,\n              breaks = c(0, 10, 20, 30, 40, 50, 60),\n              palette = \"Blues\",\n              textNA = \"Unavailable\",\n              colorNA = \"grey\"\n              ) +\n  tm_text(c(\"pct_income_label\"), size = .7, col = \"black\")+\n  tm_layout(\n    #legend.outside = TRUE,\n    legend.position = c(\"right\", \"top\"),\n    #title.snap.to.legend = FALSE,\n    title = \n      \"Percent income dimension\\nfrom those exposed to landslides\",\n    frame = FALSE,\n#            outer.margins=c(.10,.10, .10, .10), \n            title.position = c('left', 'bottom'),\n            title.size = 0.9)\n\ntmap_save(\n  map_object,\n  \"data/outputs/vulnerability_img/landslides/pct_landslides_income.svg\",\n  width = 8,\n  height = 5,\n  units = \"in\"\n)\ntmap_save(\n  map_object,\n  \"data/outputs/vulnerability_img/landslides/pct_landslides_income.png\",\n  width = 8,\n  height = 5,\n  units = \"in\",\n  dpi = 300\n)\nmap_object\n\n\n\n\n\n\n\n\n\n\nEducation\n\nmap_object &lt;-\ntm_shape(at_risk_map_landslides)+\n  tm_polygons(\"pct_education\",\n              title=\"Percent\", \n              legend.show = TRUE,\n              style = \"fixed\",\n              scale = 10,\n              breaks = c(0, 10, 20, 30, 40, 50, 60),\n              palette = \"Blues\",\n              textNA = \"Unavailable\",\n              colorNA = \"grey\"\n              ) +\n  tm_text(c(\"pct_education_label\"), size = .7, col = \"black\")+\n  tm_layout(\n    #legend.outside = TRUE,\n    legend.position = c(\"right\", \"top\"),\n    #title.snap.to.legend = FALSE,\n    title = \n      \"Percent education dimension\\nfrom those exposed to landslides\",\n    frame = FALSE,\n#            outer.margins=c(.10,.10, .10, .10), \n            title.position = c('left', 'bottom'),\n            title.size = 0.9)\n\ntmap_save(\n  map_object,\n  \"data/outputs/vulnerability_img/landslides/pct_landslides_education.svg\",\n  width = 8,\n  height = 5,\n  units = \"in\"\n)\ntmap_save(\n  map_object,\n  \"data/outputs/vulnerability_img/landslides/pct_landslides_education.png\",\n  width = 8,\n  height = 5,\n  units = \"in\",\n  dpi = 300\n)\nmap_object\n\n\n\n\n\n\n\n\n\n\nWater\n\nmap_object &lt;-\ntm_shape(at_risk_map_landslides)+\n  tm_polygons(\"pct_water\",\n              title=\"Percent\", \n              legend.show = TRUE,\n              style = \"fixed\",\n              scale = 10,\n              breaks = c(0, 10, 20, 30, 40, 50, 60),\n              palette = \"Blues\",\n              textNA = \"Unavailable\",\n              colorNA = \"grey\"\n              ) +\n  tm_text(c(\"pct_water_label\"), size = .7, col = \"black\")+\n  tm_layout(\n    #legend.outside = TRUE,\n    legend.position = c(\"right\", \"top\"),\n    #title.snap.to.legend = FALSE,\n    title = \n      \"Percent water dimension\\nfrom those exposed to landslides\",\n    frame = FALSE,\n#            outer.margins=c(.10,.10, .10, .10), \n            title.position = c('left', 'bottom'),\n            title.size = 0.9)\n\ntmap_save(\n  map_object,\n  \"data/outputs/vulnerability_img/landslides/pct_landslides_water.svg\",\n  width = 8,\n  height = 5,\n  units = \"in\"\n)\ntmap_save(\n  map_object,\n  \"data/outputs/vulnerability_img/landslides/pct_landslides_water.png\",\n  width = 8,\n  height = 5,\n  units = \"in\",\n  dpi = 300\n)\nmap_object\n\n\n\n\n\n\n\n\n\n\nSanitation\n\nmap_object &lt;-\ntm_shape(at_risk_map_landslides)+\n  tm_polygons(\"pct_sanitation\",\n              title=\"Percent\", \n              legend.show = TRUE,\n              style = \"fixed\",\n              scale = 20,\n              breaks = c(0, 20, 40, 60, 80, 100),\n              palette = \"Blues\",\n              textNA = \"Unavailable\",\n              colorNA = \"grey\"\n              ) +\n  tm_text(c(\"pct_sanitation_label\"), size = .7, col = \"black\")+\n  tm_layout(\n    #legend.outside = TRUE,\n    legend.position = c(\"right\", \"top\"),\n    #title.snap.to.legend = FALSE,\n    title = \n      \"Percent sanitation dimension\\nfrom those exposed to landslides\",\n    frame = FALSE,\n#            outer.margins=c(.10,.10, .10, .10), \n            title.position = c('left', 'bottom'),\n            title.size = 0.9)\n\ntmap_save(\n  map_object,\n  \"data/outputs/vulnerability_img/landslides/pct_landslides_sanitation.svg\",\n  width = 8,\n  height = 5,\n  units = \"in\"\n)\ntmap_save(\n  map_object,\n  \"data/outputs/vulnerability_img/landslides/pct_landslides_sanitation.png\",\n  width = 8,\n  height = 5,\n  units = \"in\",\n  dpi = 300\n)\nmap_object\n\n\n\n\n\n\n\n\n\n\nBuilding materials\n\nmap_object &lt;-\ntm_shape(at_risk_map_landslides)+\n  tm_polygons(\"pct_buildings\",\n              title=\"Percent\", \n              legend.show = TRUE,\n              style = \"fixed\",\n              scale = 10,\n              breaks = c(0, 10, 20, 30, 40, 50, 60),\n              palette = \"Blues\",\n              textNA = \"Unavailable\",\n              colorNA = \"grey\"\n              ) +\n  tm_text(c(\"pct_buildings_label\"), size = .7, col = \"black\")+\n  tm_layout(\n    #legend.outside = TRUE,\n    legend.position = c(\"right\", \"top\"),\n    #title.snap.to.legend = FALSE,\n    title = \n      \"Percent building materials\\ndimension from those exposed to landslides\",\n    frame = FALSE,\n#            outer.margins=c(.10,.10, .10, .10), \n            title.position = c('left', 'bottom'),\n            title.size = 0.9)\n\ntmap_save(\n  map_object,\n  \"data/outputs/vulnerability_img/landslides/pct_landslides_buildings.svg\",\n  width = 8,\n  height = 5,\n  units = \"in\"\n)\ntmap_save(\n  map_object,\n  \"data/outputs/vulnerability_img/landslides/pct_landslides_buildings.png\",\n  width = 8,\n  height = 5,\n  units = \"in\",\n  dpi = 300\n)\nmap_object\n\n\n\n\n\n\n\n\n\n\nSocial protection\n\nmap_object &lt;-\ntm_shape(at_risk_map_landslides)+\n  tm_polygons(\"pct_ssp\",\n              title=\"Percent\", \n              legend.show = TRUE,\n              style = \"fixed\",\n              scale = 10,\n              breaks = c(50,60, 70,80, 90, 100),\n              palette = \"Blues\",\n              textNA = \"Unavailable\",\n              colorNA = \"grey\"\n              ) +\n  tm_text(c(\"pct_ssp_label\"), size = .7, col = \"black\")+\n  tm_layout(\n    #legend.outside = TRUE,\n    legend.position = c(\"right\", \"top\"),\n    #title.snap.to.legend = FALSE,\n    title = \n      \"Percent social protection\\ndimension from those exposed to landslides\",\n    frame = FALSE,\n#            outer.margins=c(.10,.10, .10, .10), \n            title.position = c('left', 'bottom'),\n            title.size = 0.9)\n\ntmap_save(\n  map_object,\n  \"data/outputs/vulnerability_img/landslides/pct_landslides_ssp.svg\",\n  width = 8,\n  height = 5,\n  units = \"in\"\n)\ntmap_save(\n  map_object,\n  \"data/outputs/vulnerability_img/landslides/pct_landslides_ssp.png\",\n  width = 8,\n  height = 5,\n  units = \"in\",\n  dpi = 300\n)\nmap_object\n\n\n\n\n\n\n\n\n\n\nFinancial services\n\nmap_object &lt;-\ntm_shape(at_risk_map_landslides)+\n  tm_polygons(\"pct_financial\",\n              title=\"Percent\", \n              legend.show = TRUE,\n              style = \"fixed\",\n              scale = 10,\n              breaks = c(40, 50,60, 70,80, 90, 100),\n              palette = \"Blues\",\n              textNA = \"Unavailable\",\n              colorNA = \"grey\"\n              ) +\n  tm_text(c(\"pct_financial_label\"), size = .7, col = \"black\")+\n  tm_layout(\n    #legend.outside = TRUE,\n    legend.position = c(\"right\", \"top\"),\n    #title.snap.to.legend = FALSE,\n    title = \n      \"Percent financial dimension\\nfrom those exposed to landslides\",\n    frame = FALSE,\n#            outer.margins=c(.10,.10, .10, .10), \n            title.position = c('left', 'bottom'),\n            title.size = 0.9)\n\ntmap_save(\n  map_object,\n  \"data/outputs/vulnerability_img/landslides/pct_landslides_financial.svg\",\n  width = 8,\n  height = 5,\n  units = \"in\"\n)\ntmap_save(\n  map_object,\n  \"data/outputs/vulnerability_img/landslides/pct_landslides_financial.png\",\n  width = 8,\n  height = 5,\n  units = \"in\",\n  dpi = 300\n)\nmap_object",
    "crumbs": [
      "Home",
      "Supporting materials",
      "Vulnerability Analysis"
    ]
  },
  {
    "objectID": "supporting-materials/vulnerability.html#at-risk-by-many-dimensions-2",
    "href": "supporting-materials/vulnerability.html#at-risk-by-many-dimensions-2",
    "title": "Vulnerability Analysis",
    "section": "At risk by many dimensions",
    "text": "At risk by many dimensions\nPrepare map data\n\nat_risk_dimensions_map_landslides &lt;- adm1 |&gt; \n  left_join(\n    at_risk_dimensions_landslides,\n    join_by(region == Regions)\n  ) |&gt; \n  mutate(\n    region = case_when(\n      region == \"Racha-Lechkhumi and Kvemo Svaneti\" ~\n      \"Racha-Lechkhumi\\nand Kvemo Svaneti\",\n      region == \"Samegrelo-Zemo Svaneti\" ~\n      \"Samegrelo-\\nZemo\\nSvaneti\",\n      region == \"Mtskheta-Mtianeti\" ~\n      \"Mtskheta-\\nMtianeti\",\n      region == \"Samtskhe-Javakheti\" ~\n      \"Samtskhe-\\nJavakheti\",\n      .default = region\n    ),\n    up_to_2_dims = case_when(\n      is.na(`1 dimension`) | is.na(`2 dimensions`) ~ NA,\n      .default = `1 dimension` + `2 dimensions`\n    ),\n    pct_up_to_2_dims = if_else(\n      is.na(`Total Landslides`), `Total Landslides`,\n      up_to_2_dims / `Total Landslides` * 100\n    )\n  ) |&gt; \n  mutate(\n    pct_up_to_2_dims_label = if_else(\n      is.na(pct_up_to_2_dims), \n      \"Unavailable\", \n      paste(\n        region,\n        sprintf(\"\\n%.1f%%\", pct_up_to_2_dims)\n      ) \n    )\n  )\n\n\nmap_object &lt;-\ntm_shape(at_risk_dimensions_map_landslides)+\n  tm_polygons(\"pct_up_to_2_dims\",\n              title=\"Percent\", \n              legend.show = TRUE,\n              style = \"fixed\",\n              scale = 10,\n              breaks = c(20,40, 50,60, 70,80, 90,100),\n              palette = \"Purples\",\n              textNA = \"Unavailable\",\n              colorNA = \"grey\"\n              ) +\n  tm_text(c(\"pct_up_to_2_dims_label\"), size = .7, col = \"black\")+\n  tm_layout(\n    #legend.outside = TRUE,\n    legend.position = c(\"right\", \"top\"),\n    #title.snap.to.legend = FALSE,\n    title = \n      \"Percent with up to 2 dimensions\\nfrom those exposed to landslides\",\n    frame = FALSE,\n#            outer.margins=c(.10,.10, .10, .10), \n            title.position = c('left', 'bottom'),\n            title.size = 0.9)\n\ntmap_save(\n  map_object,\n  \"data/outputs/vulnerability_img/landslides/pct_landslides_up_to_2_dimensions.svg\",\n  width = 8,\n  height = 5,\n  units = \"in\"\n)\ntmap_save(\n  map_object,\n  \"data/outputs/vulnerability_img/landslides/pct_landslides_up_to_2_dimensions.png\",\n  width = 8,\n  height = 5,\n  units = \"in\",\n  dpi = 300\n)\nmap_object",
    "crumbs": [
      "Home",
      "Supporting materials",
      "Vulnerability Analysis"
    ]
  },
  {
    "objectID": "supporting-materials/vulnerability.html#spatially-distributed-population",
    "href": "supporting-materials/vulnerability.html#spatially-distributed-population",
    "title": "Vulnerability Analysis",
    "section": "Spatially distributed population",
    "text": "Spatially distributed population\n\npop &lt;- raster::raster(\"data/gis/grided_population_2020.tif\")\n\nmap_object &lt;-\ntm_shape(pop) +\n  tm_raster(\"grided_population_2020\", \n            style = \"fixed\", \n            breaks = c(0, 100, 150, 200, 600, 800, 1000, 10000),\n            # palette = \"YlOrRd\",\n            palette = \"BuPu\",\n            title = \"People per pixel\") +\n  tm_shape(adm1) +\n  tm_borders() +\n  tm_layout(\n    legend.position = c(\"right\", \"top\"),\n    #title.snap.to.legend = FALSE,\n    title = \n      \"Spatially distributed population layer\",\n    frame = FALSE,\n#            outer.margins=c(.10,.10, .10, .10), \n            title.position = c('left', 'bottom'),\n            title.size = 0.9\n    )\n\ntmap_save(\n  map_object,\n  \"data/outputs/vulnerability_img/other/gridded_pop_2020.svg\",\n  width = 8,\n  height = 5,\n  units = \"in\"\n)\ntmap_save(\n  map_object,\n  \"data/outputs/vulnerability_img/other/gridded_pop_2020.png\",\n  width = 8,\n  height = 5,\n  units = \"in\",\n  dpi = 300\n)\nmap_object",
    "crumbs": [
      "Home",
      "Supporting materials",
      "Vulnerability Analysis"
    ]
  }
]