---
title: "Georgia CCDR Microsimulation"
author:
  - name: "Renato Vargas"
    id: rv
    email: renovargas@gmail.com
    affiliation: 
      - name: Consultant for The World Bank
            
format:
  html:
    toc: true
    number-sections: true
    number-depth: 3
    highlight-style: github
  # docx:
  #   toc: true
  #   number-sections: true
  #   highlight-style: arrow
  # pdf:
  #   toc: true
  #   number-sections: true
  #   colorlinks: true
editor: source
editor_options: 
  chunk_output_type: console
bibliography: references.bib
csl: apa-6th-edition.csl
---

# Introduction

In this calculation file, we "age" the Georgian household survey according to demographic projections and different macroeconomic scenarios to explore the impact of climate-related risks and policy measures on the consumption expenditure distribution. It is part of a larger project with all background contributions to Georgia's CCDR, [available in this repository](https://rvconsulting.github.io/geo-ccdr24/supporting-materials/geo-microsimulation.html).

Using RStudio project makes it possible to not use `setwd()` to establish the root directory and refer to subdirectories in a relative manner, making interoperability easier within teams and not hard coding a particular computer's file structure into the code. If you are using Positron or Visual Studio Code (and the Quarto extension) just "open folder" at the root of the repository. If you are using R directly, just add `setwd(r'(C:\My\path\to\project\root)')` at the beginning of your coding session.

## Preamble

We start with a clean environment, making sure that any objects from a previous session are not present. We keep our country ISO code in a variable `iso` in case we need it later.

```{r}
#| warning: false
#| message: false

# Clean workspace
rm(list = ls())

# Georgia country ISO code
iso <- "GEO"

# Survey year
survey_year <- 2023

# Exchange rate USD per GEL
er <- 0.37

# Years of interest for our macroeconomic scenario analysis
analysis_years <- c(2030, 2050)
```

We call the appropriate libraries.

Rather than calling our libraries as we go, we will make sure we have everything we need from the beginning.

```{r}
#| output: false
#| lst-label: lst-load-packages

library(tidyverse) # includes dplyr, ggplot2, purr...
library(haven)     # to read SPSS and Stata datasets
library(readxl)    # to read from MS-Excel
library(openxlsx)  # to write to MS-Excel.
library(gt)        # pretty tables
library(car)       # companion to applied regression
library(modelr)    # regression models
#library(anesrake)  
# Raking reweighting but we don't load it, because 
# it changes the meaning of summarize from dplyr, 
# so we use the form anesrake::anesrake() when using it.
library(janitor)   # pretty subtotals
library(broom)     # More regressions
library(zoo)       # Calculate moving window average and max value
# library(ineq) # Inequality measures
# library(acid)

# Geopackages
library(sf)        # to read and write shapefile maps
library(terra)     # to perform geocalculations
library(tmap)      # for static and interactive maps
```

## Datasets

We then load the datasets that we need for this study. These are based on Georgia's Integrated Living Conditions Survey 2022 [@geostat_integrated_2023]. We make a note that the household identification variable is `UID`.

```{r}
#| warning: false
#| message: false
#| output: false
#| lst-label: original-datasets

## Household Unique ID, Weights, Location and other basic variables
hh_basics <- read_sav(
  "data/ilcs_2023/sysschedule.sav") |>
  mutate(
    UID = as.integer(UID))

# Household size (includes no. of family members)
hh_size <- read_sav(
  "data/ilcs_2023/familysize.sav")|> 
  mutate(
    UID = as.integer(UID))

# Processed income at household level
hh_income <- read_sav(
  "data/ilcs_2023/tblincomes.sav")|> 
  mutate(
    UID = as.integer(UID))

# Consumption aggregate at household level 
hh_expenditure <- read_sav(
  "data/ilcs_2023/tblexpenditures.sav")|> 
  rename(# rename total expenditure variables
         total_expenditure = MTlianixarjebi_,
         total_expenditure_aeq06 = MTlianimoxmareba_EqAdScale,
         total_expenditure_aeq08 = Mtlianimoxmareba_EqAdScale_08) |> 
  mutate(
    UID = as.integer(UID))

# Characteristics of the dwelling
hh_chars <- read_sav(
  "data/ilcs_2023/tblshinda01.sav")|>
  mutate(
    UID = as.integer(UID))

# Persons (pp)
pp <- read_sav(
  "data/ilcs_2023/tblshinda02.sav") |> 
  mutate(
    UID = as.integer(UID),
    MemberNo = as.integer(MemberNo))

# Labor (pp)
pp_labor <- read_sav(
  "data/ilcs_2023/tblshinda05_1.sav") |> 
  mutate(
    UID = as.integer(UID),
    MemberNo = as.integer(MemberNo),
    Q5  = as.integer(Q5),
    Q12 = as.integer(Q12)) 

# Poverty
poverty <- read_dta(
  "data/ilcs_2023/POVERTY_stata.dta") |> 
  mutate(
    UID = as.integer(UID))

# Ind. Poverty
ind_poverty <- read_dta(
  "data/ilcs_2023/IND_POVERTY_stata.dta") |> 
  rename(MemberNo = memberno) |> 
  mutate(
    UID = as.integer(UID),
    MemberNo = as.integer(MemberNo))

# Food diary
food_q <- read_sav(
  "data/ilcs_2023/tblconsumption.sav") |> 
  rename(UID = UID)

food_price <- read_sav( 
  "data/ilcs_2023/tblavgprices.sav")

```

We also need look-up tables.

```{r}
#| warning: false
#| message: false
#| label: look-up-tables

sam_activities <- read_excel(
    "data/sam/classifications.xlsx",
    sheet = "SAM-REV2",
    col_names = T,
    col_types = c("text", "text", "text","text", "numeric")
  )

sam_factors <- read_excel(
    "data/sam/classifications.xlsx",
    sheet = "SAM factors",
    col_names = T,
    col_types = "text",
  )

coicop <- read_excel(
    "data/sam/classifications.xlsx",
    sheet = "COICOP",
    col_names = T,
    col_types = "text",
  ) |> 
  mutate(simple_code = as.integer(gsub("\\.", "", Coicop)))

coicop_filtered <- coicop |> 
  filter( nchar(as.character(simple_code)) >= 5)

```


We also have Continuous Labor Survey data at the individual level, which will come in handy if we do not get access to the labor part of the ILCS. See data folder for documents describing the datasets.

```{r}
#| warning: false
#| message: false
#| output: false
#| lst-label: labor-survey

# Labor Force Survey
lfs_2023 <- read_sav(
  "data/lfs_2023/LFS_ECSTAT_ENG_2023.sav") |> 
  rename(UID = UID)

# Labor Force Survey Demographic Characteristics
lfs_2023_dem <- read_sav(
  "data/lfs_2023/LFS_Demographic_ENG_2023.sav") |> 
  rename(UID = UID)

```

We will work non-destructively, meaning we will not rewrite these data sets and we will only create intermediate data frame objects from them to perform transformations, selections and other data management tasks. For example, we will keep household assignment to poverty status and consumption deciles handy by creating a subset of our `hh_expenditure` data with only our household identifiers, deciles, and poverty if available.

```{r}
#| lst-label: lst-deciles
#| warning: FALSE
#| message: FALSE

# We will estimate deciles from consumption
deciles <- hh_expenditure |> 
  select( 
    # Keep household id and expenditure variables
    UID, 
    total_expenditure,
    total_expenditure_aeq06, # Adult equivalent * 0.6
    total_expenditure_aeq08) # Adult equivalent * 0.8
```

Our population data comes from UN's projections.

```{r}
#| warning: FALSE
#| message: FALSE 
#| lst-label: lst-population-projections

population_projections <- read_dta("data/population/UN2022_population.dta") |> 
  filter(country == iso) # we filter for Georgia
```

The macro scenario dataset is an input provided by the Macroeconomic CGE simulation team, with yearly information on GDP, working age population, employment by economic activity (for an aggregation of three sectors: agriculture, manufacturing, and services), wages by economic activity, value added by economic activity, remittances, consumer price index, food price index and energy price index (for a bundle of gas, oil, coal, electricity) by decile (10 representative households in the macro model), and carbon tax revenue transfers to household deciles.

```{r}
#| eval: false
#| warning: false
#| message: false
#| output: false
#| lst-label: lst-import-macro-scenarios

scenario_file <- "data/sam/MacroScenarioInformation_GEO.xlsx"
scenario_varlist <- read_xlsx("data/sam/GEO_Macro_varlist.xlsx") |> 
  select(-category)
# prices_2030 <- 
#   read.csv("data/ARM-Microsimulation/prices2030.csv")
```

Economic Activities in the Survey are in Georgian. The following dataset is a lookup table with the English names.

```{r}
#| eval: false
#| lst-label: lst-import-economic-activity-codes

# Equivalence table
sectors <- read_excel(
    "data/sam/classifications.xlsx",
    sheet = "SAM-REV2",
    col_names = T,
    col_types = "text",
  )
```

We also have geographical information for level 1 in Shapefile format, which we import with the `sf` package. We rename the column with the name of the administrative region to match our household survey data set conventions to ease mergers. The `dplyr` package from the `tidyverse` meta package allows us to "pipe" or link processing steps using the `|>` pipe. Although there is no geoprocessing in this analysis, this will come in handy for graphical presentations.

```{r}
#| warning: false 
#| message: false
#| lst-label: lst-import-geodata

# Georgia administrative level 1 shapefile
adm1 <- read_sf("data/gis/geo-adm1.shp") |> 
  select(ADM1_PCODE, ADM1_EN, ADM1_KA, geometry) |> 
  arrange(ADM1_PCODE)|> 
  mutate(
    region = case_when(
      ADM1_EN == "Autonomous Republic of Abkhazia" ~
        "AAutonomous\nRepublic of Abkhazia",
      ADM1_EN == "Autonomous Republic of Adjara" ~
        "Autonomous\nRepublic of Adjara",
      ADM1_EN == "Provisional Administration" ~
        "Provisional\nAdministration",
      ADM1_EN == "Racha-Lechkhumi and Kvemo Svaneti" ~
      "Racha-Lechkhumi\nand Kvemo Svaneti",
      ADM1_EN == "Samegrelo-Zemo Svaneti" ~
      "Samegrelo-\nZemo\nSvaneti",
      ADM1_EN == "Mtskheta-Mtianeti" ~
      "Mtskheta-\nMtianeti",
      ADM1_EN == "Samtskhe-Javakheti" ~
      "Samtskhe-\nJavakheti",
      .default = ADM1_EN
    ))

```

# Data preparation, demographic characteristics, income outliers and missings

We start with various renames for standardization. Naming conventions in the guidance code use traditional abbreviations like `nli` for non-lablor income. We are opting for more descriptive variable names like `non_labor_income`, `labor_income`, etc. to have more easily readable code. We make an exception for total consumption (`tc`), because it's a variable that we use in every scenario and it supersedes lenght limits when adding scenario identifiers.

```{r}
# Uncomment the correct total expenditure variable below
ex <- hh_expenditure |> 
  rename(
    tc =
      total_expenditure
      #total_expenditure_aeq06 # Adult equivalent * 0.6
      #total_expenditure_aeq08 # Adult equivalent * 0.8
      )
```

We extract demographic characteristics for each individual.

## Skill level

For skill level, we will use information on schooling from `pp$Education` (`TblShinda02`), which has the following levels:

1.  Illiterate
2.  Do not have primary education but can read and write
3.  Pre-primary education
4.  Primary education
5.  Lower secondary education
6.  Upper secondary education
7.  Vocational education without secondary general education
8.  Vocational education on the base of lower secondary education with secondary general education certificate
9.  Vocational education on the base of secondary general education (except higher professional education)
10. Higher professional program
11. Bachelor or equivalent
12. Master or equivalent
13. Doctor or equivalent

We need three skill levels for our SAM template, so we map these levels to:

Low skill (1 - 5): Illiterate through lower secondary.
Medium skill (6 - 9): Upper secondary through vocational education.
High skill (10 - 13): Higher professional program through Doctor.


```{r}
#| warning: false
#| message: false
#| label: skill-level

pp_factor_descriptors <- pp |>
  select(UID, MemberNo, Gender, Age, Education) |> 
  mutate(
    MemberId = 
      paste0(sprintf("%06d", UID), sprintf("%02d", MemberNo))) |>
  mutate(Gender = factor(
    Gender,
    levels = c(1, 2),
    labels = c("Female", "Male")
  )) |> 
  mutate(
    SkillLevel = case_when(
      Education >= 0 & Education <= 5 ~ 1,
      Education > 5 & Education <= 9 ~ 2,
      Education > 9 & Education <= 13 ~ 3,
      TRUE ~ NA ) ) |> 
  mutate(
    SkillLevel = factor(
      SkillLevel, 
      levels = c( 1, 2, 3),
      labels = c( "Low Skill", "Medium Skill", "High Skill"))
  )
```

Now that we have skill levels, we need to add information on urban/rural (from `hh_basics`) and quintile (from `ind_poverty`), and type of income earner (from `pp_labor`).

```{r}
#| warning: false
#| message: false
#| label: factor-income-descriptors

urb_rur <- hh_basics |> 
  select(UID,QuartNo, UrbanOrRural, RegNo, Weights) |> 
  mutate(
    UrbanOrRural = factor(
      UrbanOrRural,
      levels = c(2,1),
      labels = c("Rural", "Urban")
    )
  )

quintiles <- poverty |> 
  select(UID, quintilc, decilc) |> 
  rename(
    Quintile = quintilc,
    Decile = decilc) |> 
  mutate(
    Quintile = factor(
      Quintile,
      levels = c(1:5),
      labels = c("Q1", "Q2", "Q3", "Q4", "Q5")
    ),
    Decile = factor(
      Decile,
      levels = c(1:10),
      labels = c(
        "D01", "D02", "D03", "D04", "D05",
        "D06", "D07", "D08", "D09", "D10")
  ))

is_employed <- ind_poverty |> 
  mutate(
    MemberId = 
      paste0(sprintf("%06d", UID), sprintf("%02d", MemberNo))) |> 
    mutate(
      employed = case_when(
        empl == 1 ~ T,
        empl == 0 ~ F,
        .default = NA
      )
    ) |> 
    select(
      MemberId, employed
    )

pp_lmarket0 <- pp_labor |> 
  mutate(
    MemberId = 
      paste0(sprintf("%06d", UID), sprintf("%02d", MemberNo))) |> 
  select(-c(UID,MemberNo))

pp_lmarket1 <- pp_factor_descriptors |> 
  left_join(urb_rur, join_by(UID)) |> 
  left_join(quintiles, join_by(UID)) |> 
  left_join(pp_lmarket0, join_by(MemberId)) |> 
  relocate(c(UID, MemberNo, MemberId, QuartNo), .before = 1)
    
```

## Labor status and Economic Activities

We work with labor status from `Shinda05_1`. Since, upon import NACE 2 codes are converted to numbers, we need to convert them back to text, so that we can keep zeros to the left for proper order. We then extract the first two digits and find the correspondence to Rev. 2 from the SAM using the look-up table `sam_activities`. For proper order, we convert the SAM activities columns for job 1 and job 2 to factor, using the order from the dataset `sam_factors`.

```{r}
#| warning: false
#| message: false
#| label: nace-codes

pp_microsim1 <- pp_lmarket1 |> 
  mutate(
    MemberId = 
      paste0(sprintf("%06d", UID), sprintf("%02d", MemberNo))) |>
  mutate(
    # Job 1 NACE Rev 2 code. 
    Q5  = if_else(!is.na(Q5),paste0(sprintf("%04d", Q5)), NA),
    # Job 2 NACE Rev 2 code.
    Q12 = if_else(!is.na(Q12),paste0(sprintf("%04d", Q12)), NA)) |> 
  mutate(
    job1 = if_else(!is.na(Q5),substr(Q5, 1, 2), NA),
    job2 = if_else(!is.na(Q12),substr(Q12, 1, 2), NA)
  ) |> 
  # Is employed?
  left_join(
    is_employed,
    join_by(MemberId)
  ) |> 
  # We match to Rev 2 and SAM classifications (for job 1 and job 2)
  left_join(
    sam_activities[,c(1,5)], 
    join_by(job1 == rev2_2d)) |> 
  left_join(
    sam_activities[,c(1,5)],
    join_by(job2 == rev2_2d),
    suffix = 
      c("_job1", "_job2")) |> 
  # And convert to factors for proper order
  mutate(
    SAM3_job1 = factor(
      SAM3_job1, 
      levels = c(1:3),
      labels = c("Agriculture", "Manufactures", "Services")
      ),
    SAM3_job2 = factor(
      SAM3_job2, 
      levels = c(1:3),
      labels = c("Agriculture", "Manufactures", "Services")
      )
  ) 
```

## Types of income

Before making our multi-dimensional tables, we need to identify different types of income. f-lab (wages) and f-surp (capital income). The instruction is that f-surp needs to be split into wages to entrepreneurs/self employed and capital income.

```{r}
#| warning: false
#| message: false
#| label: identify-incomes

pp_microsim3 <- pp_microsim1 |> 
  mutate(
    # We add accross three months for each source (and coalesce the NAs to 0)
    labor_income_job1 = 
      rowSums(
        across(starts_with("Q8_faqti_"), \(x) coalesce(x, 0))),
    labor_income_job2 = 
      rowSums(
        across(starts_with("Q14_faqti_"), \(x) coalesce(x, 0))),
    surplus_income = 
      rowSums(
        across(starts_with("Q10_faqti_"), \(x) coalesce(x, 0)))
  ) |> 
  # We also add factor labels to Employment Status
  mutate(
    lstatus1 = factor(
      Q7,
      levels = c(1:6),
      labels = c(
        "Employee", "Employer", "Own Account (Non-Ag.)", 
        "Own Account (Ag.)", "Unpaid Worker", "Other"))
    ) |> 
  mutate(
    lstatus2 = factor(
      Q13,
      levels = c(1:6),
      labels = c(
        "Employee", "Employer", "Own Account (Non-Ag.)", 
        "Own Account (Ag.)", "Unpaid Worker", "Other"))
    )
```


## Missing and outliers

In this section we will assign a labor income for job1 holders with `!lstatus1 %in% c(2,5) & labor_income_job1 == 0` based on predicted income from everyone else who doesn't meet the condition. We will estimate annual_labor_total after predictions.

Looking at the data we see that only those that report being an employee or "other" report having labor income 1 or 2; Employer and Own Account non-ag report having surplus; and own account ag and (of course) unpaid worker

We first identify who needs predictions for job1, job2, and surplus. We default to `NA` because we want to preserve the logic of those who don't have an income, because they aren't supposed to have one. However, this introduces an uncertainty element when predicting further down the line, because subsetting does not allow NA's. Even if we want to match just `TRUEs`. So it's a double-edged sword. The fix was using `which()` to find row numbers of those with `TRUE`. 

```{r}
pp_microsim4 <- pp_microsim3 |> 
  mutate(
    fix_job1 = case_when(
      (!is.na(Q7) & Q7 %in% c(2,3,4,5)) ~ F,
      (!is.na(Q7) & Q7 %in% c(1,6) & labor_income_job1 >  0) ~ F,
      (!is.na(Q7) & Q7 %in% c(1,6) & labor_income_job1 == 0) ~ T,
      .default = NA
    ),
    fix_job2 = case_when(
      (!is.na(Q13) & Q13 %in% c(2,3,4,5)) ~ F,
      (!is.na(Q13) & Q13 %in% c(1,6) & labor_income_job2 >  0) ~ F,
      (!is.na(Q13) & Q13 %in% c(1,6) & labor_income_job2 == 0) ~ T,
      .default = NA
    ),
    fix_surplus = case_when(
      (!is.na(Q7) & Q7 %in% c(1,4,5,6)) ~ F,
      (!is.na(Q7) & Q7 %in% c(2,3) & surplus_income >  0) ~ F,
      (!is.na(Q7) & Q7 %in% c(2,3) & surplus_income == 0) ~ T,
      .default = NA
    ))
```

Outliers and need to predict.

```{r}
pp_microsim5 <- pp_microsim4 |> 
  mutate(
    sd_job1    = sd(labor_income_job1, na.rm = T),
    sd_job2    = sd(labor_income_job2, na.rm = T),
    sd_surplus = sd(surplus_income   , na.rm = T),
    d_job1 = labor_income_job1 / sd_job1,
    d_job2 = labor_income_job2 / sd_job2,
    d_job1 = surplus_income / sd_surplus,
  )
```

Assign sector to missings.

```{r}
pp_microsim6 <- pp_microsim5 |>
  group_by(UID) |>
  mutate(
    # Create a temporary variable 'other_sector'
    # which captures the sector of any employed 
    # individual in the household
    other_sector_job1 = 
      if_else(
        !is.na(Q7) & !is.na(SAM3_job1), 
        SAM3_job1, 
        NA_character_)
        ) |>
  # Use 'fill' to propagate 'other_sector' values within the household
  fill(other_sector_job1, .direction = "downup") |>
  mutate(
    other_sector_job1 = if_else(
      is.na(Q7),
      NA_character_,
      other_sector_job1)) |> 
  mutate(
    # Impute missing 'sector' values based on the 'other_sector'
    SAM3_job1 = if_else(
      !is.na(Q7), 
      coalesce(SAM3_job1, other_sector_job1), 
      SAM3_job1),
    SAM3_job2 = if_else(
      !is.na(Q13),
      coalesce(SAM3_job2, other_sector_job1), 
      SAM3_job2)
      ) |> 
  ungroup()
```

## The income simulation regression

Since labor income was a key variable, which we needed to match with the future wage bill by economic activity, we first checked for missing values among employed individuals. We found that almost a third of respondents (28.6%) did not report income for either their primary or secondary job. To overcome this limitation, we used the available information from the remaining respondents to estimate an extended Mincer equation, as shown in @eq-labor-income-regression, and implemented in @lst-regression-model. For the respondents with available information, we also identified outliers as those outside of five standard deviations from the mean labor income.

$$
\begin{equation}
\begin{split}
\ln(lab_i) = \\ \beta_0 + \beta_1 \text{age}_i + \\
\beta_2 \text{gender}_i + \beta_3 \text{education}_i + \\ 
\beta_4 \text{age}^2_i + \beta_5 \text{marz}_i + \\
\beta_6 \text{sector}_i + \epsilon_i
\end{split}
\end{equation}
$$ {#eq-labor-income-regression}

Where:

-   $\ln(lab_i)$ is the natural logarithm of labor income for individual $i$.
-   $\beta_0$ is the intercept term.
-   $\beta_1, \beta_2, \beta_3, \beta_4, \beta_5, \beta_6$ are the coefficients for the respective independent variables.
-   $\text{age}_i$ is the age of individual $i$.
-   $\text{gender}_i$ is a binary variable indicating the gender of individual $i$ (1 for female, 2 for male).
-   $\text{education}_i$ represents the level of education for individual $i$ (ordered: 1) None to General, 2) Secondary to Vocational, 3) Higher education).
-   $\text{age}^2_i$ is the square of the age of individual $i$, included to capture non-linear effects of age on labor income.
-   $\text{marz}_i$ represents the region where individual $i$ resides.
-   $\text{sector}_i$ represents the sector of employment for individual $i$ (i.e., agriculture, manufacturing or services).
-   $\epsilon_i$ is the error term for individual $i$.

We first prepare our variables for the regression.

```{r}
pp_microsim7 <- pp_microsim6 |>
  rename(
    education = Education,
    age = Age,
    gender = Gender,
    region = RegNo) |> 
  mutate(
    education2 = education^2,
    age2 = age^2,
    male = case_when(
      gender == 1 ~ 1,
      gender == 2 ~ 0
    ),
    ln_lab1 = if_else(
      !is.na(labor_income_job1) & labor_income_job1 != 0,
      log(labor_income_job1),
      NA),
    ln_lab2 = if_else(
      !is.na(labor_income_job2) & labor_income_job2 != 0,
      log(labor_income_job2),
      NA),
    ln_surplus = if_else(
      !is.na(surplus_income) & surplus_income != 0,
      log(surplus_income),
      NA),
    sim_job1 = NA_real_,
    sim_job2 = NA_real_,
    sim_surplus = NA_real_
  )|>
  # Labor Market Status 
  mutate(
    lmarket = case_when(
      !is.na(Q7) ~ as.numeric(SAM3_job1),
      is.na(Q7) & age >= 15 ~ 4, # Unemployed
      is.na(Q7) & age < 15 ~ 5,  # OLF
      .default = NA_integer_
  )
)

```

Filter the data for regression conditions.

```{r}
#| eval: true
regression_data_job1 <- pp_microsim7 |>
  filter(Q7 %in% c(1,6) & fix_job1 == F)

regression_data_job2 <- pp_microsim7 |> 
  filter(Q13 %in% c(1,6) & fix_job2 == F)

regression_data_surplus <- pp_microsim7 |> 
  filter(Q7 %in% c(2,3) & fix_surplus == F)
```

Regression model.

```{r}
#| eval: true
#| lst-label: lst-regression-model
#| lst-cap: "Income regression model"

model_job1 <- lm(
  ln_lab1 ~ 
    age + gender + education + 
    age2 + region + SAM3_job1,
    data = regression_data_job1)

model_job2 <- lm(
  ln_lab2 ~ 
    age + gender + education + 
    age2 + region + SAM3_job2,
    data = regression_data_job2)

model_surplus <- lm(
  ln_surplus ~ 
    age + gender + education + 
    age2 + region + SAM3_job1,
    data = regression_data_surplus)
```

Applying predictions to those who need it.

Note: The 'predict' function in R does not directly support conditions within the function call, so we handle this by filtering or subsetting the data as needed.

Note: 'type = "response"' might be needed depending on model type.

```{r}
# rows to predict (this removes uncertainty NAs for predictions)
target_rows_job1    <- which(pp_microsim7$fix_job1    == TRUE)
target_rows_job2    <- which(pp_microsim7$fix_job2    == TRUE)
target_rows_surplus <- which(pp_microsim7$fix_surplus == TRUE)

# predictions
pp_microsim7$sim_job1[target_rows_job1] <- exp(
  predict(
    model_job1, 
    pp_microsim7[target_rows_job1, ], 
    type = "response")
)

pp_microsim7$sim_job2[target_rows_job2] <- exp(
  predict(
    model_job1, 
    pp_microsim7[target_rows_job2, ], 
    type = "response")
)

pp_microsim7$sim_surplus[target_rows_surplus] <- exp(
  predict(
    model_job1, 
    pp_microsim7[target_rows_surplus, ], 
    type = "response")
)
```

At this point, if there were negative predictions, we would have to make them zero. There are none such cases in this exercise.

And now, we replace simulated income for those who lack one.

```{r}
pp_microsim8 <- pp_microsim7 |> 
  mutate(
    labor_income_job1 = if_else(
      fix_job1 == T,
      sim_job1,
      labor_income_job1
    ),
    labor_income_job2 = if_else(
      fix_job2 == T,
      sim_job2,
      labor_income_job2
    ),
    surplus_income = if_else(
      fix_surplus == T,
      sim_surplus,
      surplus_income
    )
  )
```

Finally, we estimate total labor income.

```{r}
pp_microsim9 <- pp_microsim8 |> 
  mutate(
    # Annual income
    annual_labor_income_job1 = labor_income_job1 * 4,
    annual_labor_income_job2 = labor_income_job2 * 4,
    annual_surplus_income = surplus_income * 4,
    # Monthly income
    monthly_labor_income_job1 = labor_income_job1 / 3,
    monthly_labor_income_job2 = labor_income_job2 / 3,
    monthly_surplus_income = surplus_income / 3
  ) |>
  mutate(
    # Annual labor income in GEL
    annual_labor_total = if_else(
      Q7 %in% c(1,2,3,6) | Q13 %in% c(1,2,3,6),
      (coalesce(
        annual_labor_income_job1, 0) +
       coalesce(
        annual_labor_income_job2, 0) +
        coalesce(
        annual_surplus_income, 0)
      ),
      NA_real_
    ),
    # Monthly labor income in GEL
    monthly_labor_total = if_else(
      Q7 %in% c(1,2,3,6) | Q13 %in% c(1,2,3,6),
      (coalesce(
        monthly_labor_income_job1, 0) +
       coalesce(
        monthly_labor_income_job2, 0) +
        coalesce(
        monthly_surplus_income, 0)
      ),
      NA_real_
    ))
```

### Total income and shares

Total labor income at HH level.

```{r}
pp_microsim10 <- pp_microsim9 |>
  group_by(UID) |>
  mutate(
    hh_annual_labor_total  = sum(annual_labor_total,  na.rm = T),
    hh_monthly_labor_total = sum(monthly_labor_total, na.rm = T)
    ) |>
  ungroup()
```

## UN Population Projections

Now we are ready to move to our demographic projections and macroeconomic model information.

First, filtering based on country (our `iso` variable).

```{r}
population_projections <- population_projections  |>  
  filter(country == iso)
```

Collapsing data by summing up variables starting with "yf" and "ym" and reshaping data to long format.

```{r}
#| eval: false
#| warning: false
#| message: false

population_projections <- population_projections |>
  group_by(Variant, country, cohort) |>
  summarize(across(starts_with(c("yf", "ym")), sum)) |>
  ungroup()

population_projections <- pivot_longer(population_projections,
                              cols = starts_with(c("yf", "ym")),
                              names_to = c(".value", "year"),
                              names_pattern = "(yf|ym)(.*)")
```

Creating new variable `total_population` as the sum of `yf` and `ym`. Dropping `country` variables.

```{r}
#| eval: false
population_projections <- population_projections |>
  mutate(total_population = yf + ym) |>
  select( -country) |> 
  mutate(year = as.numeric(year))
```

Summarizing the year to find the range.

```{r}
#| eval: false
minyear <- survey_year # Make sure `survey_year` is correctly defined
maxyear <- max(as.numeric(population_projections$year))
```

We have that the "Min Year" is `minyear` and the "Max Year" is `maxyear`. Now we create a population growth rate by demographic variant dataset. We initialize an empty list to store our data by variant and we loop over variants to create this list.

```{r}
#| eval: false
# With minyear and maxyear defined above
# Initialize a list to store growth data
pop_growth <- list()

# Loop over variants
variants <- unique(population_projections$Variant)
for (variant in variants) {
  for (t in minyear:maxyear) {
    
    # Calculate population for year t
    pop_t <- population_projections |>
      filter(year == t, Variant == variant) |>
      summarize(sum_pop = sum(total_population)) |>
      pull(sum_pop)
    
    # Calculate population for base year
    pop_base <- population_projections |>
      filter(year == minyear, Variant == variant) |>
      summarize(sum_pop = sum(total_population)) |>
      pull(sum_pop)
    
    # Calculate growth rate and store in list with dynamic naming
    growth_rate <- pop_t / pop_base
    pop_growth[[paste0(t, "_", variant)]] <- list(
      growth_rate = growth_rate, pop_t = pop_t
      )
  }
}
```

With the list ready, we convert back to dataframe by stitching the list elements one on top of the other.

```{r}
#| eval: false
# Convert list to dataframe
pop_growth <- do.call(rbind, lapply(names(pop_growth), function(x) {
  # Extract year and variant from the name
  parts <- unlist(strsplit(x, "_"))
  year <- as.integer(parts[1])
  variant <- parts[2]
  
  # Create a tibble for each entry
  tibble(year = year, 
         variant = variant, 
         total_population = pop_growth[[x]]$pop_t,
         pop_growth_rate = pop_growth[[x]]$growth_rate)
}))

# Arrange the dataframe for better readability
pop_growth <- arrange(pop_growth, variant, year)

# Display the first few rows of the dataframe
pop_growth[c(1:09),]
```

